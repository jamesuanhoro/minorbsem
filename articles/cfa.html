<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="minorbsem">
<title>Confirmatory Factor Analysis • minorbsem</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Confirmatory Factor Analysis">
<meta property="og:description" content="minorbsem">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">minorbsem</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.14</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-examples">Examples</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-examples">
    <a class="dropdown-item" href="../articles/cfa.html">Confirmatory Factor Analysis</a>
    <a class="dropdown-item" href="../articles/priors.html">Detailed guide to setting priors</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jamesuanhoro/minorbsem/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Confirmatory Factor Analysis</h1>
                        <h4 data-toc-skip class="author">Xiaolu Fan,
James Uanhoro</h4>
            
      
      
      <div class="d-none name"><code>cfa.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="basic-cfa-model">Basic CFA Model<a class="anchor" aria-label="anchor" href="#basic-cfa-model"></a>
</h2>
<p>We begin with a simple example of confirmatory factor analysis (CFA),
using the<code><a href="../reference/minorbsem.html">minorbsem()</a></code> function to fit the model. The
<code>minorbsem</code> package contains a built-in dataset called
<code>HS</code>, which is a part of classic Holzinger-Swineford dataset.
This dataset is used in many papers and books on CFA. The dataset
consists of mental ability test scores of seventh and eighth grade
children from two different schools (Pasteur and Grant-White). In our
version of the dataset (obtained from <em>lavaan</em>, <span class="citation">Rosseel (2012)</span>), only 9 out of the original 26
tests are included.</p>
<p>We begin by loading the package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jamesuanhoro.github.io/minorbsem/">minorbsem</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span></code></pre>
<pre><code><span><span class="co">## ###############################################################################</span></span></code></pre>
<pre><code><span><span class="co">## This is minorbsem 0.2.14</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## All users of R (or SEM) are invited to report bugs, submit functions or ideas</span></span>
<span><span class="co">## for functions. An efficient way to do this is to open an issue on GitHub</span></span>
<span><span class="co">## https://github.com/jamesuanhoro/minorbsem/issues/.</span></span></code></pre>
<pre><code><span><span class="co">## ###############################################################################</span></span></code></pre>
<p>The first six lines of the dataset:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">HS</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   id sex ageyr agemo  school grade       x1   x2    x3       x4   x5        x6       x7   x8</span></span>
<span><span class="co">## 1  1   1    13     1 Pasteur     7 3.333333 7.75 0.375 2.333333 5.75 1.2857143 3.391304 5.75</span></span>
<span><span class="co">## 2  2   2    13     7 Pasteur     7 5.333333 5.25 2.125 1.666667 3.00 1.2857143 3.782609 6.25</span></span>
<span><span class="co">## 3  3   2    13     1 Pasteur     7 4.500000 5.25 1.875 1.000000 1.75 0.4285714 3.260870 3.90</span></span>
<span><span class="co">## 4  4   1    13     2 Pasteur     7 5.333333 7.75 3.000 2.666667 4.50 2.4285714 3.000000 5.30</span></span>
<span><span class="co">## 5  5   2    12     2 Pasteur     7 4.833333 4.75 0.875 2.666667 4.00 2.5714286 3.695652 6.30</span></span>
<span><span class="co">## 6  6   2    14     1 Pasteur     7 5.333333 5.00 2.250 1.000000 3.00 0.8571429 4.347826 6.65</span></span>
<span><span class="co">##         x9</span></span>
<span><span class="co">## 1 6.361111</span></span>
<span><span class="co">## 2 7.916667</span></span>
<span><span class="co">## 3 4.416667</span></span>
<span><span class="co">## 4 4.861111</span></span>
<span><span class="co">## 5 5.916667</span></span>
<span><span class="co">## 6 7.500000</span></span></code></pre>
<div class="section level3">
<h3 id="data-preparation">Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"></a>
</h3>
<p>The scale of data is important for setting priors on model
parameters. The default priors for models fit with
<code>minorbsem</code> are reasonable when variables have standard
deviations close to 1. For this reason, we first check the standard
deviations of the relevant variables for this analysis:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">item_data</span> <span class="op">&lt;-</span> <span class="va">HS</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span><span class="op">]</span> <span class="co"># select columns x1:x9</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">item_data</span><span class="op">)</span> <span class="co"># show first six rows</span></span></code></pre></div>
<pre><code><span><span class="co">##         x1   x2    x3       x4   x5        x6       x7   x8       x9</span></span>
<span><span class="co">## 1 3.333333 7.75 0.375 2.333333 5.75 1.2857143 3.391304 5.75 6.361111</span></span>
<span><span class="co">## 2 5.333333 5.25 2.125 1.666667 3.00 1.2857143 3.782609 6.25 7.916667</span></span>
<span><span class="co">## 3 4.500000 5.25 1.875 1.000000 1.75 0.4285714 3.260870 3.90 4.416667</span></span>
<span><span class="co">## 4 5.333333 7.75 3.000 2.666667 4.50 2.4285714 3.000000 5.30 4.861111</span></span>
<span><span class="co">## 5 4.833333 4.75 0.875 2.666667 4.00 2.5714286 3.695652 6.30 5.916667</span></span>
<span><span class="co">## 6 5.333333 5.00 2.250 1.000000 3.00 0.8571429 4.347826 6.65 7.500000</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">item_data</span>, <span class="fl">2</span>, <span class="va">sd</span><span class="op">)</span> <span class="co"># compute SD of each variable</span></span></code></pre></div>
<pre><code><span><span class="co">##       x1       x2       x3       x4       x5       x6       x7       x8       x9 </span></span>
<span><span class="co">## 1.167432 1.177451 1.130979 1.164116 1.290472 1.095603 1.089534 1.012615 1.009152</span></span></code></pre>
<p>All variables have standard deviations close to 1, so we can move
forward with the data as they are. Otherwise, we would recommend
re-scaling the variables.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;In the situation where variable scales have no
information value, one can do a correlation-structure analysis instead
using syntax of the form:
&lt;code&gt;minorbsem(..., correlation = TRUE)&lt;/code&gt;.&lt;/p&gt;"><sup>1</sup></a></p>
</div>
<div class="section level3">
<h3 id="model-syntax">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax"></a>
</h3>
<p>The model syntax is lavaan-style:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_basic</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">Visual =~ x1 + x2 + x3</span></span>
<span><span class="st">Verbal =~ x4 + x5 + x6</span></span>
<span><span class="st">Speed =~ x7 + x8 + x9"</span></span></code></pre></div>
<p>This model assumes three latent variables (or factors):
<em>visual</em>, <em>verbal</em>, and <em>speed</em>. The visual factor
has the indicators: x1, x2, and x3; the verbal factor has indicators:
x4, x5, and x6; the speed factor has indicators: x7, x8, and x9.</p>
</div>
<div class="section level3">
<h3 id="fit-the-model">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model"></a>
</h3>
<p>We run the analysis using the <code><a href="../reference/minorbsem.html">minorbsem()</a></code> function. By
default, the function assumes that minor factors influence the
covariance between the variables. <code>minorbsem</code> then prints out
the iterations from Stan – we show these iterations once so the reader
knows what to expect.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_cfa</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">syntax_basic</span>, data <span class="op">=</span> <span class="va">HS</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Processing user input ...</span></span></code></pre>
<pre><code><span><span class="co">## User input fully processed :)</span></span>
<span><span class="co">##  Now to modeling.</span></span></code></pre>
<pre><code><span><span class="co">## Fitting Stan model ...</span></span></code></pre>
<pre><code><span><span class="co">## Init values were only set for a subset of parameters. </span></span>
<span><span class="co">## Missing init values for the following parameters:</span></span>
<span><span class="co">##  - chain 1: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">##  - chain 2: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">##  - chain 3: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span></code></pre>
<pre><code><span><span class="co">## Running MCMC with 3 chains, at most 2 in parallel...</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: A is not symmetric. A[4,7] = inf, but A[7,4] = inf (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = inf, but A[2,1] = inf (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = -inf, but A[2,1] = -inf (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = -inf, but A[2,1] = -inf (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = inf, but A[2,1] = inf (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 finished in 2.8 seconds.</span></span>
<span><span class="co">## Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 finished in 3.0 seconds.</span></span>
<span><span class="co">## Chain 3 Iteration:  200 / 2000 [ 10%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Iteration:  400 / 2000 [ 20%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration:  800 / 2000 [ 40%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpO4Ubya/model-22a964aae8b9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 finished in 3.5 seconds.</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## All 3 chains finished successfully.</span></span>
<span><span class="co">## Mean chain execution time: 3.1 seconds.</span></span>
<span><span class="co">## Total execution time: 6.5 seconds.</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##              <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;"> mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Goodness of fit                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              PPP                    0.417                              1.001       1668  </span></span>
<span><span class="co">##              RMSE                   0.064   0.014    0.043     0.090   1.002        711  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Factor loadings                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Visual   =~   x1       0.931   0.126    0.732     1.146   1.002       1121  </span></span>
<span><span class="co">##              Visual   =~   x2       0.472   0.106    0.300     0.647   1.004       1797  </span></span>
<span><span class="co">##              Visual   =~   x3       0.623   0.104    0.456     0.795   1.003       1500  </span></span>
<span><span class="co">##              Verbal   =~   x4       0.991   0.088    0.846     1.139   1.001       1395  </span></span>
<span><span class="co">##              Verbal   =~   x5       1.066   0.102    0.901     1.238   1.000       1948  </span></span>
<span><span class="co">##              Verbal   =~   x6       0.935   0.090    0.788     1.088   1.001       1588  </span></span>
<span><span class="co">##              Speed    =~   x7       0.560   0.102    0.396     0.728   1.001       1815  </span></span>
<span><span class="co">##              Speed    =~   x8       0.682   0.109    0.510     0.866   1.001       1486  </span></span>
<span><span class="co">##              Speed    =~   x9       0.786   0.116    0.596     0.988   1.001       1246  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Inter-factor correlations                         </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Verbal   ~~   Visual   0.428   0.082    0.295     0.568   1.000       1990  </span></span>
<span><span class="co">##              Speed    ~~   Visual   0.469   0.096    0.307     0.623   1.001       1812  </span></span>
<span><span class="co">##              Speed    ~~   Verbal   0.274   0.078    0.144     0.399   1.000       2406  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Residual variances                                </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              x1       ~~   x1       0.476   0.219    0.050     0.809   1.005       1026  </span></span>
<span><span class="co">##              x2       ~~   x2       1.158   0.124    0.958     1.365   1.001       2456  </span></span>
<span><span class="co">##              x3       ~~   x3       0.881   0.127    0.668     1.086   1.004       1460  </span></span>
<span><span class="co">##              x4       ~~   x4       0.363   0.145    0.105     0.591   1.001       1096  </span></span>
<span><span class="co">##              x5       ~~   x5       0.512   0.180    0.187     0.790   1.000       1462  </span></span>
<span><span class="co">##              x6       ~~   x6       0.322   0.138    0.062     0.534   1.003       1278  </span></span>
<span><span class="co">##              x7       ~~   x7       0.872   0.114    0.687     1.054   1.001       1954  </span></span>
<span><span class="co">##              x8       ~~   x8       0.568   0.141    0.327     0.784   1.001       1352  </span></span>
<span><span class="co">##              x9       ~~   x9       0.407   0.168    0.082     0.660   1.001       1103  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<div class="section level4">
<h4 id="output-structure">Output structure<a class="anchor" aria-label="anchor" href="#output-structure"></a>
</h4>
<p>At the top of the results table, <code>method = normal</code>
indicates the approach of estimating the residual covariances between
all items: the belief is that the standardized residual covariances
(SRCs) which reflect minor factor influences are normally distributed
with zero mean. The table also prints out the sample size of 301 – only
complete rows are retained for analysis.</p>
<p>We describe the column headers. The <code>from</code>,
<code>op</code> and <code>to</code> combination describe the type of
parameter being reported according to lavaan-style syntax. For example,
the <code>Visual =~ x1</code> row describes the loading from the visual
factor to item x1. The <code>mean</code>, <code>sd</code> and percentage
columns are descriptive statistics of posterior distributions. The
<code>mean</code> and <code>sd</code> function like the estimate and
standard error in standard frequentist statistics. The percentage
columns are credible intervals. By default, they are 90% credible
intervals, i.e. given the prior and data, there is a 90% chance the
parameter falls in this interval. <code>rhat</code> (pronounced R-hat)
and <code>ess_bulk</code> columns are the potential scale reduction
factor (<span class="math inline">\(\widehat{R}\)</span>) and effective
sample size (ESS) respectively <span class="citation">(Vehtari et al.
2021)</span> – they are useful for checking parameter convergence. For
<span class="math inline">\(\widehat{R}\)</span>, values very close to 1
are preferable. For ESS, larger values are preferable.
<!-- checks parameter convergence and should not be much larger than 1. In this case, all R values are between 1.000 and 1.006. -->
<!-- The ess_bulk stands for effective sample size (bulk). The larger the value, the better the model. Values in the hundreds are preferable. -->
A final analysis in a manuscript would ideally have all parameters with
<span class="math inline">\(\widehat{R}\)</span> under 1.01 and ESS
above 400 for one to be sure parameter estimates have converged <span class="citation">(Vehtari et al. 2021)</span>. An easy way to meet these
expectations is to increase the number of requested samples when calling
<code><a href="../reference/minorbsem.html">minorbsem()</a></code> via the <code>warmup =</code> and
<code>sampling =</code> arguments, see <code><a href="../reference/minorbsem.html">?minorbsem</a></code>.</p>
<p>The parameter estimates are presented by the type of parameter.</p>
</div>
<div class="section level4">
<h4 id="goodness-of-fit">Goodness of fit<a class="anchor" aria-label="anchor" href="#goodness-of-fit"></a>
</h4>
<p><strong>PPP</strong>. The first section of results contains
parameters that help assess global model fit. “PPP” is the posterior
predictive <em>p</em>-value in the form described by <span class="citation">Muthén and Asparouhov (2012)</span>, and is akin to a
<span class="math inline">\(\chi^2\)</span> test in standard SEMs. It is
conventional to prefer values under .05 or .10. Here, PPP = .382
indicating a good-fitting model. Desirable PPP-values are to be expected
by default in <code>minorbsem</code> as the package accounts for model
misspecification – alternatively stated: PPP-values above .05 do not
imply an absence of misfit and is not all that informative by default.
We report PPP since <code>minorbsem</code> is also able to fit Bayesian
SEMs that do not account for misspecification,
e.g. <code>minorbsem(..., method = "none")</code>.</p>
<p><strong>RMSE</strong>. This the root mean square error of
standardized residual covariances (SRCs) and communicates the typical
size of SRCs. One may also interpret this metric as the standard
deviation of SRCs with 95% of SRCs lying within 2 RMSE values from 0. In
this example, RMSE = 0.063 and we can expect some SRCs to be greater
than 0.10, suggesting some large SRCs <span class="citation">(Maydeu-Olivares 2017)</span>. Large SRCs challenge the
notion that model misspecification is due to the influence of minor
factors – if these influences are large, are these factors “minor”? It
is possible that the hypothesized structure is incorrect, or minor
factors have significant effects.</p>
</div>
<div class="section level4">
<h4 id="substantive-parameters">Substantive parameters<a class="anchor" aria-label="anchor" href="#substantive-parameters"></a>
</h4>
<p>The parameter estimates are reported by type of parameter: factor
loadings, inter-factor correlations, and error variances. For this
model, all items load on their respective factors with intervals that
clearly exclude 0. All factors are assumed standardized in minorbsem, so
only their correlations are reported; and all factors are non-trivially
correlated.</p>
</div>
</div>
<div class="section level3">
<h3 id="residual-plots">Residual plots<a class="anchor" aria-label="anchor" href="#residual-plots"></a>
</h3>
<p>Given that the RMSE suggests large standardized residual covariances
(SRCs), we can request a plot of SRCs using two options: a range-plot
and a heat-map.</p>
<div class="sourceCode" id="cb148"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_residuals.html">plot_residuals</a></span><span class="op">(</span><span class="va">fit_cfa</span>, type <span class="op">=</span> <span class="st">"range"</span><span class="op">)</span></span></code></pre></div>
<p><img src="cfa_files/figure-html/unnamed-chunk-5-1.png" width="700"></p>
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_residuals.html">plot_residuals</a></span><span class="op">(</span><span class="va">fit_cfa</span>, type <span class="op">=</span> <span class="st">"matrix"</span><span class="op">)</span></span></code></pre></div>
<p><img src="cfa_files/figure-html/unnamed-chunk-5-2.png" width="700"></p>
<p>The heat-map is particularly useful for highlighting the largest
SRCs. If these SRCs cluster in a non-random way, one may identify
potential model modifications.</p>
</div>
</div>
<div class="section level2">
<h2 id="bifactor-model-with-orthogonal-factors">Bifactor model with orthogonal factors<a class="anchor" aria-label="anchor" href="#bifactor-model-with-orthogonal-factors"></a>
</h2>
<p>To improve on the basic model, we consider the bifactor structure,
which builds on the basic CFA model by specifying a general factor ‘G’
that is reflected in all nine indicators. All factors are assumed
orthogonal.</p>
<div class="section level3">
<h3 id="model-syntax-1">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax-1"></a>
</h3>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_bifactor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9"</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="va">syntax_basic</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html" class="external-link">writeLines</a></span><span class="op">(</span><span class="va">syntax_bifactor</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Visual =~ x1 + x2 + x3</span></span>
<span><span class="co">## Verbal =~ x4 + x5 + x6</span></span>
<span><span class="co">## Speed =~ x7 + x8 + x9</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="fit-the-model-1">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-1"></a>
</h3>
<p>The call to <code><a href="../reference/minorbsem.html">minorbsem()</a></code> needs to be of the form:
<code>minorbsem(..., orthogonal = TRUE)</code> to ensure the factors are
orthogonal:</p>
<div class="sourceCode" id="cb152"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_bifactor</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span><span class="va">syntax_bifactor</span>, data <span class="op">=</span> <span class="va">HS</span>, orthogonal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##             <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;">  mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Goodness of fit                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             PPP                     0.403                              1.000       1890  </span></span>
<span><span class="co">##             RMSE                    0.027   0.012    0.009     0.049   1.003        604  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Factor loadings                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             G        =~   x1        0.952   0.110    0.765     1.133   1.002       1588  </span></span>
<span><span class="co">##             G        =~   x2        0.494   0.105    0.327     0.668   1.001       2061  </span></span>
<span><span class="co">##             G        =~   x3        0.630   0.095    0.475     0.781   1.000       1842  </span></span>
<span><span class="co">##             G        =~   x4        0.471   0.084    0.340     0.612   1.001       1756  </span></span>
<span><span class="co">##             G        =~   x5        0.425   0.095    0.269     0.583   0.999       1863  </span></span>
<span><span class="co">##             G        =~   x6        0.460   0.080    0.331     0.596   1.002       1716  </span></span>
<span><span class="co">##             G        =~   x7        0.107   0.083   -0.028     0.247   1.001       2525  </span></span>
<span><span class="co">##             G        =~   x8        0.288   0.075    0.168     0.414   1.000       2332  </span></span>
<span><span class="co">##             G        =~   x9        0.509   0.077    0.389     0.642   1.000       2072  </span></span>
<span><span class="co">##             Visual   =~   x1        0.225   0.179    0.018     0.591   1.000        997  </span></span>
<span><span class="co">##             Visual   =~   x2       -0.157   0.516   -0.991     0.773   1.002       1581  </span></span>
<span><span class="co">##             Visual   =~   x3       -0.017   0.454   -0.736     0.876   1.003       1546  </span></span>
<span><span class="co">##             Verbal   =~   x4        0.860   0.075    0.735     0.980   1.001       1923  </span></span>
<span><span class="co">##             Verbal   =~   x5        1.051   0.086    0.907     1.190   1.002       1341  </span></span>
<span><span class="co">##             Verbal   =~   x6        0.788   0.070    0.673     0.903   1.000       2032  </span></span>
<span><span class="co">##             Speed    =~   x7        0.731   0.118    0.545     0.939   1.002       1518  </span></span>
<span><span class="co">##             Speed    =~   x8        0.708   0.105    0.534     0.890   1.002       1434  </span></span>
<span><span class="co">##             Speed    =~   x9        0.435   0.079    0.306     0.562   1.002       2381  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Inter-factor correlations                          </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Visual   ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Verbal   ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Verbal   ~~   Visual    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   Visual    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   Verbal    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Residual variances                                 </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             x1       ~~   x1        0.395   0.219    0.017     0.726   1.001        790  </span></span>
<span><span class="co">##             x2       ~~   x2        0.870   0.357    0.054     1.265   1.002        881  </span></span>
<span><span class="co">##             x3       ~~   x3        0.696   0.264    0.083     0.994   1.002        851  </span></span>
<span><span class="co">##             x4       ~~   x4        0.392   0.085    0.250     0.530   1.001       1892  </span></span>
<span><span class="co">##             x5       ~~   x5        0.385   0.130    0.147     0.584   1.002        921  </span></span>
<span><span class="co">##             x6       ~~   x6        0.376   0.074    0.254     0.494   1.000       2027  </span></span>
<span><span class="co">##             x7       ~~   x7        0.639   0.159    0.347     0.865   1.004       1367  </span></span>
<span><span class="co">##             x8       ~~   x8        0.449   0.131    0.207     0.645   1.003       1368  </span></span>
<span><span class="co">##             x9       ~~   x9        0.577   0.075    0.450     0.700   1.003       2451  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>Compared to the basic CFA model, the RMSE drops from .063 to .028,
suggesting a much better fitting model. All items load with 90%
intervals excluding 0 on the general factor, except for x7.
Additionally, x1 – x3 load confusingly on their specific factor, while
x4 – x9 load strongly on their specific factors especially when compared
to their general factor loadings. This pattern of factor loadings
provide little support for a bifactor structure.</p>
<!-- Regarding the factor loadings on the new factor 'G', items x1 through x6 and x9 all have relatively large loadings greater than 0.4, but items x7 and x8 do not load very well, with factor loadings of .112 and .289, respectively. For the factor F1 (Visual), all three items (x1, x2, and x3) have small loading under .25. For factor F2 (Verbal), all three items (x4, x5, and x6) load pretty well, with loadings of .857, 1.051, and .785, respectively. For factor F3 (Speed), all three factors (x7, x8, and x9) have good loadings greater than .40. In addition, `orthonogal=TRUE` argument set all the inter-factor correlations to be zero. -->
</div>
</div>
<div class="section level2">
<h2 id="bifactor-model-with-parameter-constraints">Bifactor model with parameter constraints<a class="anchor" aria-label="anchor" href="#bifactor-model-with-parameter-constraints"></a>
</h2>
<p>We instead explore a more constrained bifactor structure where
specific factor loadings are forced equal within each specific factor.
Note that minorbsem uses the same parameter constraint syntax as
lavaan:</p>
<div class="section level3">
<h3 id="model-syntax-2">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax-2"></a>
</h3>
<div class="sourceCode" id="cb154"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_bifactor_cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9"</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="st">"Visual =~ a * x1 + a * x2 + a * x3</span></span>
<span><span class="st">  Verbal =~ b * x4 + b * x5 + b * x6</span></span>
<span><span class="st">  Speed =~ c * x7 + c * x8 + c * x9"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<!-- This model is built upon the basic bifactor model by adding constraints. The loadings on the G factor remains unchanged as the basic bifactor model and allow to be freely estimated. However, the loadings of x1, x2, and x3 on F1 are forced to be the same. Similarly, loading of x4, x5, and x6 on F2 are forced to the same, and x7, x8, and x9 on F3 are also constrained to be the same number. -->
</div>
<div class="section level3">
<h3 id="fit-the-model-2">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-2"></a>
</h3>
<div class="sourceCode" id="cb155"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_bifactor_cons</span> <span class="op">&lt;-</span> <span class="va">fit_bifactor_cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span></span>
<span>  <span class="va">syntax_bifactor_cons</span>,</span>
<span>  data <span class="op">=</span> <span class="va">HS</span>, orthogonal <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##              <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;"> mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Goodness of fit                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              PPP                    0.397                              0.999       2216  </span></span>
<span><span class="co">##              RMSE                   0.047   0.012    0.029     0.068   1.003       1038  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Factor loadings                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              G        =~   x1       0.864   0.113    0.674     1.049   1.001       1604  </span></span>
<span><span class="co">##              G        =~   x2       0.433   0.117    0.229     0.617   1.001       1880  </span></span>
<span><span class="co">##              G        =~   x3       0.575   0.114    0.385     0.761   1.000       1615  </span></span>
<span><span class="co">##              G        =~   x4       0.499   0.101    0.338     0.669   1.001       1812  </span></span>
<span><span class="co">##              G        =~   x5       0.496   0.114    0.319     0.687   1.002       1763  </span></span>
<span><span class="co">##              G        =~   x6       0.474   0.095    0.322     0.633   1.001       1657  </span></span>
<span><span class="co">##              G        =~   x7       0.132   0.097   -0.024     0.295   1.000       1943  </span></span>
<span><span class="co">##              G        =~   x8       0.288   0.086    0.151     0.432   1.001       2261  </span></span>
<span><span class="co">##              G        =~   x9       0.517   0.086    0.378     0.660   1.000       2507  </span></span>
<span><span class="co">##              Visual   =~   x1       0.280   0.148    0.032     0.512   1.000       1606  </span></span>
<span><span class="co">##              Visual   =~   x2       0.280   0.148    0.032     0.512   1.000       1606  </span></span>
<span><span class="co">##              Visual   =~   x3       0.280   0.148    0.032     0.512   1.000       1606  </span></span>
<span><span class="co">##              Verbal   =~   x4       0.864   0.061    0.764     0.961   1.002       1534  </span></span>
<span><span class="co">##              Verbal   =~   x5       0.864   0.061    0.764     0.961   1.002       1534  </span></span>
<span><span class="co">##              Verbal   =~   x6       0.864   0.061    0.764     0.961   1.002       1534  </span></span>
<span><span class="co">##              Speed    =~   x7       0.605   0.054    0.515     0.689   1.000       2020  </span></span>
<span><span class="co">##              Speed    =~   x8       0.605   0.054    0.515     0.689   1.000       2020  </span></span>
<span><span class="co">##              Speed    =~   x9       0.605   0.054    0.515     0.689   1.000       2020  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Inter-factor correlations                         </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Visual   ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Verbal   ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Verbal   ~~   Visual   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   Visual   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   Verbal   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Residual variances                                </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              x1       ~~   x1       0.531   0.157    0.262     0.774   1.002       1539  </span></span>
<span><span class="co">##              x2       ~~   x2       1.103   0.117    0.917     1.297   1.001       3244  </span></span>
<span><span class="co">##              x3       ~~   x3       0.849   0.109    0.665     1.026   1.000       2363  </span></span>
<span><span class="co">##              x4       ~~   x4       0.356   0.082    0.226     0.490   1.001       2262  </span></span>
<span><span class="co">##              x5       ~~   x5       0.618   0.091    0.474     0.771   1.001       2220  </span></span>
<span><span class="co">##              x6       ~~   x6       0.255   0.077    0.129     0.383   1.003       1883  </span></span>
<span><span class="co">##              x7       ~~   x7       0.777   0.086    0.645     0.925   1.001       3312  </span></span>
<span><span class="co">##              x8       ~~   x8       0.566   0.073    0.449     0.689   1.001       3029  </span></span>
<span><span class="co">##              x9       ~~   x9       0.427   0.085    0.286     0.563   1.000       2152  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>The RMSE increased since the model is more constrained. The pattern
of results with the parameter constraints imposed suggest the general
factor mostly reflects items x1 – x3, with other items more strongly
reflecting their specific factors. These results suggest limited
applicability of the bifactor model for these data.</p>
<!-- The results reveals that the nine loadings on the G factor vary greatly. x1 and x3 load pretty well on factor G, with loadings of .745 and .471, respectively. All remaining seven loadings are below .4. In addition, the constrained loadings on F1, F2, and F3 are .393, .955, and .693, respectively. -->
</div>
</div>
<div class="section level2">
<h2 id="non-simple-structure-model">Non-Simple Structure Model<a class="anchor" aria-label="anchor" href="#non-simple-structure-model"></a>
</h2>
<p>For our final model, we return to the original basic CFA and relax
simple structure. Unlike <span class="citation">Muthén and Asparouhov
(2012)</span> who do this using small-variance priors, minorbsem does
this using a global-local prior <span class="citation">(Uanhoro
2024)</span>. Precisely, this approach assumes that most cross-loadings
are indeed zero and there are some outlier non-zero cross loadings.</p>
<div class="section level3">
<h3 id="fit-the-model-3">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-3"></a>
</h3>
<p>The call to <code><a href="../reference/minorbsem.html">minorbsem()</a></code> needs to be of the form:
<code>minorbsem(..., simple_struc = FALSE)</code></p>
<div class="sourceCode" id="cb157"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_non_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span><span class="va">syntax_basic</span>, data <span class="op">=</span> <span class="va">HS</span>, simple_struc <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##             <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;">  mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Goodness of fit                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             PPP                     0.452                              1.000       2189  </span></span>
<span><span class="co">##             RMSE                    0.024   0.012    0.006     0.047   1.006        433  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Factor loadings                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Visual   =~   x1        0.761   0.119    0.573     0.963   1.001        826  </span></span>
<span><span class="co">##             Visual   =~   x2        0.559   0.101    0.392     0.726   1.000       1938  </span></span>
<span><span class="co">##             Visual   =~   x3        0.754   0.110    0.580     0.937   1.000       1394  </span></span>
<span><span class="co">##             Visual   =~   x4        0.025   0.070   -0.078     0.154   1.004       1456  </span></span>
<span><span class="co">##             Visual   =~   x5       -0.059   0.087   -0.216     0.062   1.004       1509  </span></span>
<span><span class="co">##             Visual   =~   x6        0.057   0.074   -0.042     0.188   1.003       1184  </span></span>
<span><span class="co">##             Visual   =~   x7       -0.139   0.145   -0.420     0.028   1.002        956  </span></span>
<span><span class="co">##             Visual   =~   x8        0.044   0.108   -0.118     0.247   1.003       1074  </span></span>
<span><span class="co">##             Visual   =~   x9        0.317   0.115    0.125     0.504   1.001       1137  </span></span>
<span><span class="co">##             Verbal   =~   x1        0.139   0.107   -0.013     0.324   1.001        970  </span></span>
<span><span class="co">##             Verbal   =~   x2        0.015   0.066   -0.093     0.131   1.002       1606  </span></span>
<span><span class="co">##             Verbal   =~   x3       -0.070   0.091   -0.238     0.040   1.002       1070  </span></span>
<span><span class="co">##             Verbal   =~   x4        0.986   0.075    0.864     1.111   1.001       1584  </span></span>
<span><span class="co">##             Verbal   =~   x5        1.137   0.090    0.993     1.295   1.002       1219  </span></span>
<span><span class="co">##             Verbal   =~   x6        0.892   0.072    0.775     1.011   1.002       1479  </span></span>
<span><span class="co">##             Verbal   =~   x7        0.023   0.071   -0.080     0.145   1.002       1758  </span></span>
<span><span class="co">##             Verbal   =~   x8       -0.030   0.071   -0.161     0.069   1.002       1626  </span></span>
<span><span class="co">##             Verbal   =~   x9        0.014   0.060   -0.080     0.115   1.001       1965  </span></span>
<span><span class="co">##             Speed    =~   x1        0.034   0.080   -0.080     0.181   1.003       1734  </span></span>
<span><span class="co">##             Speed    =~   x2       -0.052   0.078   -0.199     0.047   1.002       1895  </span></span>
<span><span class="co">##             Speed    =~   x3        0.028   0.078   -0.085     0.163   1.002       1725  </span></span>
<span><span class="co">##             Speed    =~   x4        0.003   0.054   -0.084     0.094   1.000       2407  </span></span>
<span><span class="co">##             Speed    =~   x5        0.003   0.062   -0.096     0.106   1.000       2006  </span></span>
<span><span class="co">##             Speed    =~   x6        0.002   0.053   -0.083     0.086   1.001       2015  </span></span>
<span><span class="co">##             Speed    =~   x7        0.763   0.120    0.577     0.970   1.001        978  </span></span>
<span><span class="co">##             Speed    =~   x8        0.759   0.099    0.601     0.924   1.006        948  </span></span>
<span><span class="co">##             Speed    =~   x9        0.497   0.091    0.353     0.645   1.001       1321  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Inter-factor correlations                          </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Verbal   ~~   Visual    0.356   0.121    0.150     0.541   1.000       1040  </span></span>
<span><span class="co">##             Speed    ~~   Visual    0.284   0.162    0.003     0.533   1.001       1064  </span></span>
<span><span class="co">##             Speed    ~~   Verbal    0.227   0.116    0.031     0.412   1.002       1482  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Residual variances                                 </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             x1       ~~   x1        0.668   0.131    0.439     0.866   1.002        991  </span></span>
<span><span class="co">##             x2       ~~   x2        1.092   0.115    0.908     1.291   1.002       2262  </span></span>
<span><span class="co">##             x3       ~~   x3        0.737   0.127    0.524     0.936   1.000       1246  </span></span>
<span><span class="co">##             x4       ~~   x4        0.372   0.085    0.228     0.502   1.003       1254  </span></span>
<span><span class="co">##             x5       ~~   x5        0.425   0.113    0.243     0.610   1.001        847  </span></span>
<span><span class="co">##             x6       ~~   x6        0.374   0.069    0.261     0.489   1.004       1660  </span></span>
<span><span class="co">##             x7       ~~   x7        0.656   0.136    0.426     0.866   1.003        912  </span></span>
<span><span class="co">##             x8       ~~   x8        0.458   0.119    0.252     0.641   1.003        882  </span></span>
<span><span class="co">##             x9       ~~   x9        0.574   0.074    0.458     0.692   1.001       2281  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>The effect of minor factors is small, RMSE = 0.024. The original
hypothesized loadings maintain their relation to their hypothesized
factors. Of the cross-loadings, only the relation from the visual factor
to x9 is non-trivial, with most being very close to 0. Additionally, the
interfactor correlations have all reduced from the original basic CFA,
suggesting that forcing cross-loadings to zero artificially inflated
interfactor correlations <span class="citation">(Ferrando and
Lorenzo-Seva 2000)</span>.</p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="works-cited">Works Cited<a class="anchor" aria-label="anchor" href="#works-cited"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Ferrando2000" class="csl-entry">
Ferrando, Pere J, and Urbano Lorenzo-Seva. 2000. <span>“Unrestricted
Versus Restricted Factor Analysis of Multidimensional Test Items: Some
Aspects of the Problem and Some Suggestions.”</span>
<em>Psicológica</em> 21 (2): 301–23. <a href="https://www.uv.es/revispsi/articulos3.00/ferran7.pdf" class="external-link">https://www.uv.es/revispsi/articulos3.00/ferran7.pdf</a>.
</div>
<div id="ref-Maydeu-Olivares2017a" class="csl-entry">
Maydeu-Olivares, Alberto. 2017. <span>“Assessing the Size of Model
Misfit in Structural Equation Models.”</span> <em>Psychometrika</em> 82
(3): 533–58. <a href="https://doi.org/10.1007/s11336-016-9552-7" class="external-link">https://doi.org/10.1007/s11336-016-9552-7</a>.
</div>
<div id="ref-Muthen2012" class="csl-entry">
Muthén, Bengt, and Tihomir Asparouhov. 2012. <span>“Bayesian Structural
Equation Modeling: <span>A</span> More Flexible Representation of
Substantive Theory.”</span> <em>Psychological Methods</em> 17 (3):
313–35. <a href="https://doi.org/10.1037/a0026802" class="external-link">https://doi.org/10.1037/a0026802</a>.
</div>
<div id="ref-Rosseel2012" class="csl-entry">
Rosseel, Yves. 2012. <span>“Lavaan: <span>An</span> <span>R</span>
Package for Structural Equation Modeling.”</span> <em>Journal of
Statistical Software</em> 48 (2): 1–20. <a href="https://doi.org/10.18637/jss.v048.i02" class="external-link">https://doi.org/10.18637/jss.v048.i02</a>.
</div>
<div id="ref-uanhoro_comparison_2024" class="csl-entry">
Uanhoro, James O. 2024. <span>“A Comparison of Different Prior Choices
for Estimating the Influence of Minor Factors in <span>Bayesian</span>
Structural Equation Models.”</span> In <em><span>Annual</span>
<span>Meeting</span> of the American <span>Educational</span>
<span>Research</span> <span>Association</span></em>. Philadelphia, PA.
</div>
<div id="ref-vehtari_rank-normalization_2021" class="csl-entry">
Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and
Paul-Christian Bürkner. 2021. <span>“Rank-Normalization, Folding, and
Localization: <span>An</span> Improved <span class="math inline">\(\widehat{R}\)</span> for Assessing Convergence of
MCMC (with <span>Discussion</span>).”</span> <em>Bayesian Analysis</em>
16 (2): 667–718. <a href="https://doi.org/10.1214/20-BA1221" class="external-link">https://doi.org/10.1214/20-BA1221</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by James O. Uanhoro.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
