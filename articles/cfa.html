<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Confirmatory Factor Analysis • minorbsem</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Confirmatory Factor Analysis">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">minorbsem</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.16.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples">
<li><a class="dropdown-item" href="../articles/cfa.html">Confirmatory Factor Analysis</a></li>
    <li><a class="dropdown-item" href="../articles/priors.html">Detailed guide to setting priors</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/jamesuanhoro/minorbsem/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Confirmatory Factor Analysis</h1>
                        <h4 data-toc-skip class="author">Xiaolu Fan,
James Uanhoro</h4>
            
      

      <div class="d-none name"><code>cfa.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="basic-cfa-model">Basic CFA Model<a class="anchor" aria-label="anchor" href="#basic-cfa-model"></a>
</h2>
<p>We begin with a simple example of confirmatory factor analysis (CFA),
using the<code><a href="../reference/minorbsem.html">minorbsem()</a></code> function to fit the model. The
<code>minorbsem</code> package contains a built-in dataset called
<code>HS</code>, which is a part of classic Holzinger-Swineford dataset.
This dataset is used in many papers and books on CFA. The dataset
consists of mental ability test scores of seventh and eighth grade
children from two different schools (Pasteur and Grant-White). In our
version of the dataset (obtained from <em>lavaan</em>, <span class="citation">Rosseel (2012)</span>), only 9 out of the original 26
tests are included.</p>
<p>We begin by loading the package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jamesuanhoro.github.io/minorbsem/">minorbsem</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span></code></pre>
<pre><code><span><span class="co">## ###############################################################################</span></span></code></pre>
<pre><code><span><span class="co">## This is minorbsem 0.2.16.9000</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## All users of R (or SEM) are invited to report bugs, submit functions or ideas</span></span>
<span><span class="co">## for functions. An efficient way to do this is to open an issue on GitHub</span></span>
<span><span class="co">## https://github.com/jamesuanhoro/minorbsem/issues/.</span></span></code></pre>
<pre><code><span><span class="co">## ###############################################################################</span></span></code></pre>
<p>The first six lines of the dataset:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">HS</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   id sex ageyr agemo  school grade       x1   x2    x3       x4   x5        x6       x7   x8</span></span>
<span><span class="co">## 1  1   1    13     1 Pasteur     7 3.333333 7.75 0.375 2.333333 5.75 1.2857143 3.391304 5.75</span></span>
<span><span class="co">## 2  2   2    13     7 Pasteur     7 5.333333 5.25 2.125 1.666667 3.00 1.2857143 3.782609 6.25</span></span>
<span><span class="co">## 3  3   2    13     1 Pasteur     7 4.500000 5.25 1.875 1.000000 1.75 0.4285714 3.260870 3.90</span></span>
<span><span class="co">## 4  4   1    13     2 Pasteur     7 5.333333 7.75 3.000 2.666667 4.50 2.4285714 3.000000 5.30</span></span>
<span><span class="co">## 5  5   2    12     2 Pasteur     7 4.833333 4.75 0.875 2.666667 4.00 2.5714286 3.695652 6.30</span></span>
<span><span class="co">## 6  6   2    14     1 Pasteur     7 5.333333 5.00 2.250 1.000000 3.00 0.8571429 4.347826 6.65</span></span>
<span><span class="co">##         x9</span></span>
<span><span class="co">## 1 6.361111</span></span>
<span><span class="co">## 2 7.916667</span></span>
<span><span class="co">## 3 4.416667</span></span>
<span><span class="co">## 4 4.861111</span></span>
<span><span class="co">## 5 5.916667</span></span>
<span><span class="co">## 6 7.500000</span></span></code></pre>
<div class="section level3">
<h3 id="data-preparation">Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"></a>
</h3>
<p>The scale of data is important for setting priors on model
parameters. The default priors for models fit with
<code>minorbsem</code> are reasonable when variables have standard
deviations close to 1. For this reason, we first check the standard
deviations of the relevant variables for this analysis:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">item_data</span> <span class="op">&lt;-</span> <span class="va">HS</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span><span class="op">]</span> <span class="co"># select columns x1:x9</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">item_data</span><span class="op">)</span> <span class="co"># show first six rows</span></span></code></pre></div>
<pre><code><span><span class="co">##         x1   x2    x3       x4   x5        x6       x7   x8       x9</span></span>
<span><span class="co">## 1 3.333333 7.75 0.375 2.333333 5.75 1.2857143 3.391304 5.75 6.361111</span></span>
<span><span class="co">## 2 5.333333 5.25 2.125 1.666667 3.00 1.2857143 3.782609 6.25 7.916667</span></span>
<span><span class="co">## 3 4.500000 5.25 1.875 1.000000 1.75 0.4285714 3.260870 3.90 4.416667</span></span>
<span><span class="co">## 4 5.333333 7.75 3.000 2.666667 4.50 2.4285714 3.000000 5.30 4.861111</span></span>
<span><span class="co">## 5 4.833333 4.75 0.875 2.666667 4.00 2.5714286 3.695652 6.30 5.916667</span></span>
<span><span class="co">## 6 5.333333 5.00 2.250 1.000000 3.00 0.8571429 4.347826 6.65 7.500000</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">item_data</span>, <span class="fl">2</span>, <span class="va">sd</span><span class="op">)</span> <span class="co"># compute SD of each variable</span></span></code></pre></div>
<pre><code><span><span class="co">##       x1       x2       x3       x4       x5       x6       x7       x8       x9 </span></span>
<span><span class="co">## 1.167432 1.177451 1.130979 1.164116 1.290472 1.095603 1.089534 1.012615 1.009152</span></span></code></pre>
<p>All variables have standard deviations close to 1, so we can move
forward with the data as they are. Otherwise, we would recommend
re-scaling the variables.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;In the situation where variable scales have no
information value, one can do a correlation-structure analysis instead
using syntax of the form:
&lt;code&gt;minorbsem(..., correlation = TRUE)&lt;/code&gt;.&lt;/p&gt;"><sup>1</sup></a></p>
</div>
<div class="section level3">
<h3 id="model-syntax">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax"></a>
</h3>
<p>The model syntax is lavaan-style:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_basic</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">Visual =~ x1 + x2 + x3</span></span>
<span><span class="st">Verbal =~ x4 + x5 + x6</span></span>
<span><span class="st">Speed =~ x7 + x8 + x9"</span></span></code></pre></div>
<p>This model assumes three latent variables (or factors):
<em>visual</em>, <em>verbal</em>, and <em>speed</em>. The visual factor
has the indicators: x1, x2, and x3; the verbal factor has indicators:
x4, x5, and x6; the speed factor has indicators: x7, x8, and x9.</p>
</div>
<div class="section level3">
<h3 id="fit-the-model">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model"></a>
</h3>
<p>We run the analysis using the <code><a href="../reference/minorbsem.html">minorbsem()</a></code> function. By
default, the function assumes that minor factors influence the
covariance between the variables. <code>minorbsem</code> then prints out
the iterations from Stan – we show these iterations once so the reader
knows what to expect.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_cfa</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">syntax_basic</span>, data <span class="op">=</span> <span class="va">HS</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Processing user input ...</span></span></code></pre>
<pre><code><span><span class="co">## User input fully processed :)</span></span>
<span><span class="co">##  Now to modeling.</span></span></code></pre>
<pre><code><span><span class="co">## Fitting Stan model ...</span></span></code></pre>
<pre><code><span><span class="co">## Init values were only set for a subset of parameters. </span></span>
<span><span class="co">## Missing init values for the following parameters:</span></span>
<span><span class="co">##  - chain 1: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">##  - chain 2: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">##  - chain 3: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## To disable this message use options(cmdstanr_warn_inits = FALSE).</span></span></code></pre>
<pre><code><span><span class="co">## Running MCMC with 3 chains, at most 2 in parallel...</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: A is not symmetric. A[1,4] = inf, but A[4,1] = inf (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = inf, but A[2,1] = inf (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = inf, but A[2,1] = inf (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[7,8] = inf, but A[8,7] = inf (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 finished in 3.8 seconds.</span></span>
<span><span class="co">## Chain 2 finished in 3.8 seconds.</span></span>
<span><span class="co">## Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Iteration:  200 / 2000 [ 10%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Iteration:  400 / 2000 [ 20%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpfL4wEJ/model-248a5c6731c9.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 finished in 4.3 seconds.</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## All 3 chains finished successfully.</span></span>
<span><span class="co">## Mean chain execution time: 3.9 seconds.</span></span>
<span><span class="co">## Total execution time: 8.2 seconds.</span></span></code></pre>
<pre><code><span><span class="co">## Warning: 1 of 3000 (0.0%) transitions ended with a divergence.</span></span>
<span><span class="co">## See https://mc-stan.org/misc/warnings for details.</span></span></code></pre>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##              <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;"> mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Goodness of fit                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              PPP                    0.399                              1.002       1846  </span></span>
<span><span class="co">##              RMSE                   0.064   0.015    0.042     0.090   1.004        698  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Factor loadings                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Visual   =~   x1       0.937   0.129    0.736     1.157   1.001       1290  </span></span>
<span><span class="co">##              Visual   =~   x2       0.468   0.106    0.296     0.644   1.001       2438  </span></span>
<span><span class="co">##              Visual   =~   x3       0.625   0.109    0.454     0.803   1.002       1804  </span></span>
<span><span class="co">##              Verbal   =~   x4       1.000   0.091    0.854     1.159   1.002       1425  </span></span>
<span><span class="co">##              Verbal   =~   x5       1.068   0.099    0.910     1.237   1.001       1406  </span></span>
<span><span class="co">##              Verbal   =~   x6       0.932   0.091    0.788     1.087   1.001       1433  </span></span>
<span><span class="co">##              Speed    =~   x7       0.560   0.104    0.391     0.729   1.000       1652  </span></span>
<span><span class="co">##              Speed    =~   x8       0.678   0.105    0.508     0.849   1.003       1157  </span></span>
<span><span class="co">##              Speed    =~   x9       0.788   0.119    0.599     0.996   1.000        985  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Inter-factor correlations                         </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Verbal   ~~   Visual   0.426   0.080    0.291     0.557   1.000       2028  </span></span>
<span><span class="co">##              Speed    ~~   Visual   0.467   0.100    0.301     0.629   1.004       1581  </span></span>
<span><span class="co">##              Speed    ~~   Verbal   0.276   0.080    0.144     0.409   1.004       2863  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Residual variances                                </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              x1       ~~   x1       0.465   0.221    0.039     0.787   1.001       1161  </span></span>
<span><span class="co">##              x2       ~~   x2       1.162   0.126    0.964     1.370   1.002       2473  </span></span>
<span><span class="co">##              x3       ~~   x3       0.879   0.133    0.664     1.092   1.001       1748  </span></span>
<span><span class="co">##              x4       ~~   x4       0.349   0.154    0.065     0.590   1.004       1007  </span></span>
<span><span class="co">##              x5       ~~   x5       0.511   0.180    0.190     0.789   1.001       1271  </span></span>
<span><span class="co">##              x6       ~~   x6       0.329   0.140    0.072     0.544   1.003       1161  </span></span>
<span><span class="co">##              x7       ~~   x7       0.872   0.116    0.681     1.062   1.001       1612  </span></span>
<span><span class="co">##              x8       ~~   x8       0.576   0.132    0.347     0.777   1.001       1249  </span></span>
<span><span class="co">##              x9       ~~   x9       0.402   0.171    0.073     0.652   1.001        837  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<div class="section level4">
<h4 id="output-structure">Output structure<a class="anchor" aria-label="anchor" href="#output-structure"></a>
</h4>
<p>At the top of the results table, <code>method = normal</code>
indicates the approach of estimating the residual covariances between
all items: the belief is that the standardized residual covariances
(SRCs) which reflect minor factor influences are normally distributed
with zero mean. The table also prints out the sample size of 301 – only
complete rows are retained for analysis.</p>
<p>We describe the column headers. The <code>from</code>,
<code>op</code> and <code>to</code> combination describe the type of
parameter being reported according to lavaan-style syntax. For example,
the <code>Visual =~ x1</code> row describes the loading from the visual
factor to item x1. The <code>mean</code>, <code>sd</code> and percentage
columns are descriptive statistics of posterior distributions. The
<code>mean</code> and <code>sd</code> function like the estimate and
standard error in standard frequentist statistics. The percentage
columns are credible intervals. By default, they are 90% credible
intervals, i.e. given the prior and data, there is a 90% chance the
parameter falls in this interval. <code>rhat</code> (pronounced R-hat)
and <code>ess_bulk</code> columns are the potential scale reduction
factor
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>)
and effective sample size (ESS) respectively <span class="citation">(Vehtari et al. 2021)</span> – they are useful for
checking parameter convergence. For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>,
values very close to 1 are preferable. For ESS, larger values are
preferable.
<!-- checks parameter convergence and should not be much larger than 1. In this case, all R values are between 1.000 and 1.006. -->
<!-- The ess_bulk stands for effective sample size (bulk). The larger the value, the better the model. Values in the hundreds are preferable. -->
A final analysis in a manuscript would ideally have all parameters with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>
under 1.01 and ESS above 400 for one to be sure parameter estimates have
converged <span class="citation">(Vehtari et al. 2021)</span>. An easy
way to meet these expectations is to increase the number of requested
samples when calling <code><a href="../reference/minorbsem.html">minorbsem()</a></code> via the
<code>warmup =</code> and <code>sampling =</code> arguments, see
<code><a href="../reference/minorbsem.html">?minorbsem</a></code>.</p>
<p>The parameter estimates are presented by the type of parameter.</p>
</div>
<div class="section level4">
<h4 id="goodness-of-fit">Goodness of fit<a class="anchor" aria-label="anchor" href="#goodness-of-fit"></a>
</h4>
<p><strong>PPP</strong>. The first section of results contains
parameters that help assess global model fit. “PPP” is the posterior
predictive <em>p</em>-value in the form described by <span class="citation">Muthén and Asparouhov (2012)</span>, and is akin to a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
test in standard SEMs. It is conventional to prefer values under .05 or
.10. Here, PPP = .382 indicating a good-fitting model. Desirable
PPP-values are to be expected by default in <code>minorbsem</code> as
the package accounts for model misspecification – alternatively stated:
PPP-values above .05 do not imply an absence of misfit and is not all
that informative by default. We report PPP since <code>minorbsem</code>
is also able to fit Bayesian SEMs that do not account for
misspecification, e.g. <code>minorbsem(..., method = "none")</code>.</p>
<p><strong>RMSE</strong>. This the root mean square error of
standardized residual covariances (SRCs) and communicates the typical
size of SRCs. One may also interpret this metric as the standard
deviation of SRCs with 95% of SRCs lying within 2 RMSE values from 0. In
this example, RMSE = 0.063 and we can expect some SRCs to be greater
than 0.10, suggesting some large SRCs <span class="citation">(Maydeu-Olivares 2017)</span>. Large SRCs challenge the
notion that model misspecification is due to the influence of minor
factors – if these influences are large, are these factors “minor”? It
is possible that the hypothesized structure is incorrect, or minor
factors have significant effects.</p>
</div>
<div class="section level4">
<h4 id="substantive-parameters">Substantive parameters<a class="anchor" aria-label="anchor" href="#substantive-parameters"></a>
</h4>
<p>The parameter estimates are reported by type of parameter: factor
loadings, inter-factor correlations, and error variances. For this
model, all items load on their respective factors with intervals that
clearly exclude 0. All factors are assumed standardized in minorbsem, so
only their correlations are reported; and all factors are non-trivially
correlated.</p>
</div>
</div>
<div class="section level3">
<h3 id="residual-plots">Residual plots<a class="anchor" aria-label="anchor" href="#residual-plots"></a>
</h3>
<p>Given that the RMSE suggests large standardized residual covariances
(SRCs), we can request a plot of SRCs using two options: a range-plot
and a heat-map.</p>
<div class="sourceCode" id="cb149"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_residuals.html">plot_residuals</a></span><span class="op">(</span><span class="va">fit_cfa</span>, type <span class="op">=</span> <span class="st">"range"</span><span class="op">)</span></span></code></pre></div>
<p><img src="cfa_files/figure-html/unnamed-chunk-5-1.png" class="r-plt" alt="" width="700"></p>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_residuals.html">plot_residuals</a></span><span class="op">(</span><span class="va">fit_cfa</span>, type <span class="op">=</span> <span class="st">"matrix"</span><span class="op">)</span></span></code></pre></div>
<p><img src="cfa_files/figure-html/unnamed-chunk-5-2.png" class="r-plt" alt="" width="700"></p>
<p>The heat-map is particularly useful for highlighting the largest
SRCs. If these SRCs cluster in a non-random way, one may identify
potential model modifications.</p>
</div>
</div>
<div class="section level2">
<h2 id="bifactor-model-with-orthogonal-factors">Bifactor model with orthogonal factors<a class="anchor" aria-label="anchor" href="#bifactor-model-with-orthogonal-factors"></a>
</h2>
<p>To improve on the basic model, we consider the bifactor structure,
which builds on the basic CFA model by specifying a general factor ‘G’
that is reflected in all nine indicators. All factors are assumed
orthogonal.</p>
<div class="section level3">
<h3 id="model-syntax-1">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax-1"></a>
</h3>
<div class="sourceCode" id="cb151"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_bifactor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9"</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="va">syntax_basic</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html" class="external-link">writeLines</a></span><span class="op">(</span><span class="va">syntax_bifactor</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Visual =~ x1 + x2 + x3</span></span>
<span><span class="co">## Verbal =~ x4 + x5 + x6</span></span>
<span><span class="co">## Speed =~ x7 + x8 + x9</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="fit-the-model-1">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-1"></a>
</h3>
<p>The call to <code><a href="../reference/minorbsem.html">minorbsem()</a></code> needs to be of the form:
<code>minorbsem(..., orthogonal = TRUE)</code> to ensure the factors are
orthogonal:</p>
<div class="sourceCode" id="cb153"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_bifactor</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span><span class="va">syntax_bifactor</span>, data <span class="op">=</span> <span class="va">HS</span>, orthogonal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##             <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;">  mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Goodness of fit                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             PPP                     0.386                              1.001       1980  </span></span>
<span><span class="co">##             RMSE                    0.027   0.012    0.007     0.048   1.008        531  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Factor loadings                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             G        =~   x1        0.946   0.111    0.759     1.128   1.000       1190  </span></span>
<span><span class="co">##             G        =~   x2        0.485   0.110    0.313     0.667   1.001       2079  </span></span>
<span><span class="co">##             G        =~   x3        0.625   0.100    0.457     0.790   1.000       2145  </span></span>
<span><span class="co">##             G        =~   x4        0.473   0.083    0.345     0.614   1.003       2003  </span></span>
<span><span class="co">##             G        =~   x5        0.428   0.093    0.274     0.583   1.006       1564  </span></span>
<span><span class="co">##             G        =~   x6        0.463   0.079    0.338     0.597   1.004       2046  </span></span>
<span><span class="co">##             G        =~   x7        0.110   0.083   -0.023     0.247   1.001       1920  </span></span>
<span><span class="co">##             G        =~   x8        0.288   0.076    0.169     0.412   1.000       2245  </span></span>
<span><span class="co">##             G        =~   x9        0.511   0.077    0.390     0.639   1.003       1756  </span></span>
<span><span class="co">##             Visual   =~   x1        0.222   0.178    0.016     0.587   1.001       1537  </span></span>
<span><span class="co">##             Visual   =~   x2       -0.117   0.510   -0.957     0.804   1.000       1421  </span></span>
<span><span class="co">##             Visual   =~   x3        0.005   0.491   -0.796     0.903   1.000       1350  </span></span>
<span><span class="co">##             Verbal   =~   x4        0.859   0.076    0.733     0.985   1.002       2186  </span></span>
<span><span class="co">##             Verbal   =~   x5        1.050   0.086    0.911     1.192   1.002       1519  </span></span>
<span><span class="co">##             Verbal   =~   x6        0.785   0.072    0.667     0.905   1.000       2204  </span></span>
<span><span class="co">##             Speed    =~   x7        0.726   0.115    0.539     0.922   1.004       1108  </span></span>
<span><span class="co">##             Speed    =~   x8        0.712   0.110    0.537     0.904   1.004       1038  </span></span>
<span><span class="co">##             Speed    =~   x9        0.432   0.079    0.301     0.562   1.001       2051  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Inter-factor correlations                          </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Visual   ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Verbal   ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Verbal   ~~   Visual    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   Visual    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   Verbal    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Residual variances                                 </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             x1       ~~   x1        0.405   0.217    0.020     0.719   1.002        938  </span></span>
<span><span class="co">##             x2       ~~   x2        0.893   0.341    0.092     1.273   1.000       1197  </span></span>
<span><span class="co">##             x3       ~~   x3        0.662   0.281    0.046     0.994   1.003       1058  </span></span>
<span><span class="co">##             x4       ~~   x4        0.393   0.085    0.248     0.525   1.003       1799  </span></span>
<span><span class="co">##             x5       ~~   x5        0.386   0.126    0.160     0.583   1.004       1248  </span></span>
<span><span class="co">##             x6       ~~   x6        0.378   0.074    0.258     0.500   1.000       1936  </span></span>
<span><span class="co">##             x7       ~~   x7        0.648   0.155    0.367     0.878   1.005       1039  </span></span>
<span><span class="co">##             x8       ~~   x8        0.438   0.141    0.169     0.644   1.004       1020  </span></span>
<span><span class="co">##             x9       ~~   x9        0.579   0.075    0.459     0.702   1.002       2549  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>Compared to the basic CFA model, the RMSE drops from .063 to .028,
suggesting a much better fitting model. All items load with 90%
intervals excluding 0 on the general factor, except for x7.
Additionally, x1 – x3 load confusingly on their specific factor, while
x4 – x9 load strongly on their specific factors especially when compared
to their general factor loadings. This pattern of factor loadings
provide little support for a bifactor structure.</p>
<!-- Regarding the factor loadings on the new factor 'G', items x1 through x6 and x9 all have relatively large loadings greater than 0.4, but items x7 and x8 do not load very well, with factor loadings of .112 and .289, respectively. For the factor F1 (Visual), all three items (x1, x2, and x3) have small loading under .25. For factor F2 (Verbal), all three items (x4, x5, and x6) load pretty well, with loadings of .857, 1.051, and .785, respectively. For factor F3 (Speed), all three factors (x7, x8, and x9) have good loadings greater than .40. In addition, `orthonogal=TRUE` argument set all the inter-factor correlations to be zero. -->
</div>
</div>
<div class="section level2">
<h2 id="bifactor-model-with-parameter-constraints">Bifactor model with parameter constraints<a class="anchor" aria-label="anchor" href="#bifactor-model-with-parameter-constraints"></a>
</h2>
<p>We instead explore a more constrained bifactor structure where
specific factor loadings are forced equal within each specific factor.
Note that minorbsem uses the same parameter constraint syntax as
lavaan:</p>
<div class="section level3">
<h3 id="model-syntax-2">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax-2"></a>
</h3>
<div class="sourceCode" id="cb155"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_bifactor_cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9"</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="st">"Visual =~ a * x1 + a * x2 + a * x3</span></span>
<span><span class="st">  Verbal =~ b * x4 + b * x5 + b * x6</span></span>
<span><span class="st">  Speed =~ c * x7 + c * x8 + c * x9"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<!-- This model is built upon the basic bifactor model by adding constraints. The loadings on the G factor remains unchanged as the basic bifactor model and allow to be freely estimated. However, the loadings of x1, x2, and x3 on F1 are forced to be the same. Similarly, loading of x4, x5, and x6 on F2 are forced to the same, and x7, x8, and x9 on F3 are also constrained to be the same number. -->
</div>
<div class="section level3">
<h3 id="fit-the-model-2">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-2"></a>
</h3>
<div class="sourceCode" id="cb156"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_bifactor_cons</span> <span class="op">&lt;-</span> <span class="va">fit_bifactor_cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span></span>
<span>  <span class="va">syntax_bifactor_cons</span>,</span>
<span>  data <span class="op">=</span> <span class="va">HS</span>, orthogonal <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##              <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;"> mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Goodness of fit                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              PPP                    0.399                              1.000       2217  </span></span>
<span><span class="co">##              RMSE                   0.047   0.012    0.030     0.069   1.001        995  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Factor loadings                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              G        =~   x1       0.863   0.116    0.675     1.056   1.001       2127  </span></span>
<span><span class="co">##              G        =~   x2       0.431   0.113    0.247     0.611   1.000       2512  </span></span>
<span><span class="co">##              G        =~   x3       0.571   0.112    0.383     0.749   1.001       1971  </span></span>
<span><span class="co">##              G        =~   x4       0.500   0.102    0.336     0.670   1.001       2116  </span></span>
<span><span class="co">##              G        =~   x5       0.491   0.115    0.304     0.682   1.000       2004  </span></span>
<span><span class="co">##              G        =~   x6       0.474   0.094    0.324     0.630   1.000       2448  </span></span>
<span><span class="co">##              G        =~   x7       0.132   0.100   -0.030     0.299   1.002       2072  </span></span>
<span><span class="co">##              G        =~   x8       0.285   0.088    0.143     0.428   1.002       2581  </span></span>
<span><span class="co">##              G        =~   x9       0.517   0.084    0.381     0.653   1.001       2704  </span></span>
<span><span class="co">##              Visual   =~   x1       0.286   0.148    0.038     0.516   1.002       1502  </span></span>
<span><span class="co">##              Visual   =~   x2       0.286   0.148    0.038     0.516   1.002       1502  </span></span>
<span><span class="co">##              Visual   =~   x3       0.286   0.148    0.038     0.516   1.002       1502  </span></span>
<span><span class="co">##              Verbal   =~   x4       0.863   0.060    0.765     0.961   1.002       2152  </span></span>
<span><span class="co">##              Verbal   =~   x5       0.863   0.060    0.765     0.961   1.002       2152  </span></span>
<span><span class="co">##              Verbal   =~   x6       0.863   0.060    0.765     0.961   1.002       2152  </span></span>
<span><span class="co">##              Speed    =~   x7       0.605   0.054    0.513     0.689   1.001       2851  </span></span>
<span><span class="co">##              Speed    =~   x8       0.605   0.054    0.513     0.689   1.001       2851  </span></span>
<span><span class="co">##              Speed    =~   x9       0.605   0.054    0.513     0.689   1.001       2851  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Inter-factor correlations                         </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Visual   ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Verbal   ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Verbal   ~~   Visual   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   Visual   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   Verbal   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Residual variances                                </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              x1       ~~   x1       0.531   0.160    0.248     0.776   1.003       2027  </span></span>
<span><span class="co">##              x2       ~~   x2       1.106   0.115    0.924     1.308   1.000       3411  </span></span>
<span><span class="co">##              x3       ~~   x3       0.852   0.108    0.675     1.034   1.001       3128  </span></span>
<span><span class="co">##              x4       ~~   x4       0.353   0.082    0.214     0.484   1.001       2578  </span></span>
<span><span class="co">##              x5       ~~   x5       0.622   0.094    0.470     0.780   1.001       2854  </span></span>
<span><span class="co">##              x6       ~~   x6       0.255   0.077    0.122     0.377   1.000       2681  </span></span>
<span><span class="co">##              x7       ~~   x7       0.776   0.088    0.641     0.931   1.001       3979  </span></span>
<span><span class="co">##              x8       ~~   x8       0.566   0.072    0.455     0.689   1.002       3554  </span></span>
<span><span class="co">##              x9       ~~   x9       0.426   0.086    0.284     0.563   1.004       2542  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>The RMSE increased since the model is more constrained. The pattern
of results with the parameter constraints imposed suggest the general
factor mostly reflects items x1 – x3, with other items more strongly
reflecting their specific factors. These results suggest limited
applicability of the bifactor model for these data.</p>
<!-- The results reveals that the nine loadings on the G factor vary greatly. x1 and x3 load pretty well on factor G, with loadings of .745 and .471, respectively. All remaining seven loadings are below .4. In addition, the constrained loadings on F1, F2, and F3 are .393, .955, and .693, respectively. -->
</div>
</div>
<div class="section level2">
<h2 id="non-simple-structure-model">Non-Simple Structure Model<a class="anchor" aria-label="anchor" href="#non-simple-structure-model"></a>
</h2>
<p>For our final model, we return to the original basic CFA and relax
simple structure. Unlike <span class="citation">Muthén and Asparouhov
(2012)</span> who do this using small-variance priors, minorbsem does
this using a global-local prior <span class="citation">(Uanhoro
2024)</span>. Precisely, this approach assumes that most cross-loadings
are indeed zero and there are some outlier non-zero cross loadings.</p>
<div class="section level3">
<h3 id="fit-the-model-3">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-3"></a>
</h3>
<p>The call to <code><a href="../reference/minorbsem.html">minorbsem()</a></code> needs to be of the form:
<code>minorbsem(..., simple_struc = FALSE)</code></p>
<div class="sourceCode" id="cb158"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_non_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span><span class="va">syntax_basic</span>, data <span class="op">=</span> <span class="va">HS</span>, simple_struc <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##             <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;">  mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Goodness of fit                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             PPP                     0.479                              1.001       1883  </span></span>
<span><span class="co">##             RMSE                    0.025   0.012    0.006     0.047   1.003        470  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Factor loadings                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Visual   =~   x1        0.758   0.118    0.567     0.952   1.000       1155  </span></span>
<span><span class="co">##             Visual   =~   x2        0.565   0.096    0.407     0.722   1.002       1830  </span></span>
<span><span class="co">##             Visual   =~   x3        0.753   0.111    0.581     0.939   1.000       1510  </span></span>
<span><span class="co">##             Visual   =~   x4        0.025   0.071   -0.082     0.152   1.001       1941  </span></span>
<span><span class="co">##             Visual   =~   x5       -0.063   0.091   -0.226     0.061   1.002       1340  </span></span>
<span><span class="co">##             Visual   =~   x6        0.059   0.077   -0.044     0.202   1.002       1719  </span></span>
<span><span class="co">##             Visual   =~   x7       -0.139   0.146   -0.424     0.035   1.000       1058  </span></span>
<span><span class="co">##             Visual   =~   x8        0.046   0.115   -0.124     0.260   1.001       1274  </span></span>
<span><span class="co">##             Visual   =~   x9        0.318   0.120    0.109     0.505   1.000       1300  </span></span>
<span><span class="co">##             Verbal   =~   x1        0.138   0.111   -0.024     0.330   1.000       1087  </span></span>
<span><span class="co">##             Verbal   =~   x2        0.011   0.067   -0.097     0.128   1.004       1672  </span></span>
<span><span class="co">##             Verbal   =~   x3       -0.075   0.095   -0.259     0.046   1.001       1158  </span></span>
<span><span class="co">##             Verbal   =~   x4        0.986   0.075    0.863     1.109   1.002       1322  </span></span>
<span><span class="co">##             Verbal   =~   x5        1.144   0.090    1.004     1.296   1.003        614  </span></span>
<span><span class="co">##             Verbal   =~   x6        0.891   0.073    0.772     1.010   1.002       1680  </span></span>
<span><span class="co">##             Verbal   =~   x7        0.026   0.076   -0.085     0.157   1.001       1964  </span></span>
<span><span class="co">##             Verbal   =~   x8       -0.030   0.074   -0.165     0.076   1.002       1765  </span></span>
<span><span class="co">##             Verbal   =~   x9        0.013   0.061   -0.084     0.118   1.000       2262  </span></span>
<span><span class="co">##             Speed    =~   x1        0.037   0.083   -0.080     0.191   1.000       1691  </span></span>
<span><span class="co">##             Speed    =~   x2       -0.053   0.079   -0.202     0.049   1.006       2176  </span></span>
<span><span class="co">##             Speed    =~   x3        0.031   0.081   -0.082     0.183   1.003       2201  </span></span>
<span><span class="co">##             Speed    =~   x4        0.002   0.058   -0.091     0.096   1.001       2388  </span></span>
<span><span class="co">##             Speed    =~   x5        0.003   0.066   -0.102     0.110   1.000       2574  </span></span>
<span><span class="co">##             Speed    =~   x6        0.000   0.054   -0.088     0.091   1.000       2552  </span></span>
<span><span class="co">##             Speed    =~   x7        0.761   0.122    0.570     0.976   1.004        880  </span></span>
<span><span class="co">##             Speed    =~   x8        0.764   0.105    0.596     0.949   1.002        830  </span></span>
<span><span class="co">##             Speed    =~   x9        0.501   0.094    0.354     0.662   1.001       1182  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Inter-factor correlations                          </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Verbal   ~~   Visual    0.362   0.121    0.150     0.545   1.000       1174  </span></span>
<span><span class="co">##             Speed    ~~   Visual    0.278   0.170   -0.012     0.539   1.004        937  </span></span>
<span><span class="co">##             Speed    ~~   Verbal    0.226   0.124    0.020     0.420   1.003       1215  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Residual variances                                 </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             x1       ~~   x1        0.674   0.124    0.464     0.868   1.002       1560  </span></span>
<span><span class="co">##             x2       ~~   x2        1.084   0.109    0.916     1.271   1.000       2691  </span></span>
<span><span class="co">##             x3       ~~   x3        0.743   0.125    0.535     0.944   1.001       1537  </span></span>
<span><span class="co">##             x4       ~~   x4        0.373   0.085    0.229     0.510   1.004       1040  </span></span>
<span><span class="co">##             x5       ~~   x5        0.417   0.118    0.223     0.594   1.006        466  </span></span>
<span><span class="co">##             x6       ~~   x6        0.375   0.071    0.257     0.492   1.001       1354  </span></span>
<span><span class="co">##             x7       ~~   x7        0.657   0.141    0.420     0.882   1.002        922  </span></span>
<span><span class="co">##             x8       ~~   x8        0.451   0.130    0.201     0.640   1.000        686  </span></span>
<span><span class="co">##             x9       ~~   x9        0.572   0.075    0.453     0.697   1.001       1910  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>The effect of minor factors is small, RMSE = 0.024. The original
hypothesized loadings maintain their relation to their hypothesized
factors. Of the cross-loadings, only the relation from the visual factor
to x9 is non-trivial, with most being very close to 0. Additionally, the
interfactor correlations have all reduced from the original basic CFA,
suggesting that forcing cross-loadings to zero artificially inflated
interfactor correlations <span class="citation">(Ferrando and
Lorenzo-Seva 2000)</span>.</p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="works-cited">Works Cited<a class="anchor" aria-label="anchor" href="#works-cited"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Ferrando2000" class="csl-entry">
Ferrando, Pere J, and Urbano Lorenzo-Seva. 2000. <span>“Unrestricted
Versus Restricted Factor Analysis of Multidimensional Test Items: Some
Aspects of the Problem and Some Suggestions.”</span>
<em>Psicológica</em> 21 (2): 301–23. <a href="https://www.uv.es/revispsi/articulos3.00/ferran7.pdf" class="external-link">https://www.uv.es/revispsi/articulos3.00/ferran7.pdf</a>.
</div>
<div id="ref-Maydeu-Olivares2017a" class="csl-entry">
Maydeu-Olivares, Alberto. 2017. <span>“Assessing the Size of Model
Misfit in Structural Equation Models.”</span> <em>Psychometrika</em> 82
(3): 533–58. <a href="https://doi.org/10.1007/s11336-016-9552-7" class="external-link">https://doi.org/10.1007/s11336-016-9552-7</a>.
</div>
<div id="ref-Muthen2012" class="csl-entry">
Muthén, Bengt, and Tihomir Asparouhov. 2012. <span>“Bayesian Structural
Equation Modeling: <span>A</span> More Flexible Representation of
Substantive Theory.”</span> <em>Psychological Methods</em> 17 (3):
313–35. <a href="https://doi.org/10.1037/a0026802" class="external-link">https://doi.org/10.1037/a0026802</a>.
</div>
<div id="ref-Rosseel2012" class="csl-entry">
Rosseel, Yves. 2012. <span>“Lavaan: <span>An</span> <span>R</span>
Package for Structural Equation Modeling.”</span> <em>Journal of
Statistical Software</em> 48 (2): 1–20. <a href="https://doi.org/10.18637/jss.v048.i02" class="external-link">https://doi.org/10.18637/jss.v048.i02</a>.
</div>
<div id="ref-uanhoro_comparison_2024" class="csl-entry">
Uanhoro, James O. 2024. <span>“A Comparison of Different Prior Choices
for Estimating the Influence of Minor Factors in <span>Bayesian</span>
Structural Equation Models.”</span> In <em><span>Annual</span>
<span>Meeting</span> of the American <span>Educational</span>
<span>Research</span> <span>Association</span></em>. Philadelphia, PA.
</div>
<div id="ref-vehtari_rank-normalization_2021" class="csl-entry">
Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and
Paul-Christian Bürkner. 2021. <span>“Rank-Normalization, Folding, and
Localization: <span>An</span> Improved
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>
for Assessing Convergence of MCMC (with
<span>Discussion</span>).”</span> <em>Bayesian Analysis</em> 16 (2):
667–718. <a href="https://doi.org/10.1214/20-BA1221" class="external-link">https://doi.org/10.1214/20-BA1221</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by James O. Uanhoro.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
