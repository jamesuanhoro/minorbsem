<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Confirmatory Factor Analysis • minorbsem</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Confirmatory Factor Analysis">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">minorbsem</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.15</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples">
<li><a class="dropdown-item" href="../articles/cfa.html">Confirmatory Factor Analysis</a></li>
    <li><a class="dropdown-item" href="../articles/priors.html">Detailed guide to setting priors</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/jamesuanhoro/minorbsem/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Confirmatory Factor Analysis</h1>
                        <h4 data-toc-skip class="author">Xiaolu Fan,
James Uanhoro</h4>
            
      

      <div class="d-none name"><code>cfa.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="basic-cfa-model">Basic CFA Model<a class="anchor" aria-label="anchor" href="#basic-cfa-model"></a>
</h2>
<p>We begin with a simple example of confirmatory factor analysis (CFA),
using the<code><a href="../reference/minorbsem.html">minorbsem()</a></code> function to fit the model. The
<code>minorbsem</code> package contains a built-in dataset called
<code>HS</code>, which is a part of classic Holzinger-Swineford dataset.
This dataset is used in many papers and books on CFA. The dataset
consists of mental ability test scores of seventh and eighth grade
children from two different schools (Pasteur and Grant-White). In our
version of the dataset (obtained from <em>lavaan</em>, <span class="citation">Rosseel (2012)</span>), only 9 out of the original 26
tests are included.</p>
<p>We begin by loading the package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jamesuanhoro.github.io/minorbsem/">minorbsem</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span></code></pre>
<pre><code><span><span class="co">## ###############################################################################</span></span></code></pre>
<pre><code><span><span class="co">## This is minorbsem 0.2.15</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## All users of R (or SEM) are invited to report bugs, submit functions or ideas</span></span>
<span><span class="co">## for functions. An efficient way to do this is to open an issue on GitHub</span></span>
<span><span class="co">## https://github.com/jamesuanhoro/minorbsem/issues/.</span></span></code></pre>
<pre><code><span><span class="co">## ###############################################################################</span></span></code></pre>
<p>The first six lines of the dataset:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">HS</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   id sex ageyr agemo  school grade       x1   x2    x3       x4   x5        x6       x7   x8</span></span>
<span><span class="co">## 1  1   1    13     1 Pasteur     7 3.333333 7.75 0.375 2.333333 5.75 1.2857143 3.391304 5.75</span></span>
<span><span class="co">## 2  2   2    13     7 Pasteur     7 5.333333 5.25 2.125 1.666667 3.00 1.2857143 3.782609 6.25</span></span>
<span><span class="co">## 3  3   2    13     1 Pasteur     7 4.500000 5.25 1.875 1.000000 1.75 0.4285714 3.260870 3.90</span></span>
<span><span class="co">## 4  4   1    13     2 Pasteur     7 5.333333 7.75 3.000 2.666667 4.50 2.4285714 3.000000 5.30</span></span>
<span><span class="co">## 5  5   2    12     2 Pasteur     7 4.833333 4.75 0.875 2.666667 4.00 2.5714286 3.695652 6.30</span></span>
<span><span class="co">## 6  6   2    14     1 Pasteur     7 5.333333 5.00 2.250 1.000000 3.00 0.8571429 4.347826 6.65</span></span>
<span><span class="co">##         x9</span></span>
<span><span class="co">## 1 6.361111</span></span>
<span><span class="co">## 2 7.916667</span></span>
<span><span class="co">## 3 4.416667</span></span>
<span><span class="co">## 4 4.861111</span></span>
<span><span class="co">## 5 5.916667</span></span>
<span><span class="co">## 6 7.500000</span></span></code></pre>
<div class="section level3">
<h3 id="data-preparation">Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"></a>
</h3>
<p>The scale of data is important for setting priors on model
parameters. The default priors for models fit with
<code>minorbsem</code> are reasonable when variables have standard
deviations close to 1. For this reason, we first check the standard
deviations of the relevant variables for this analysis:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">item_data</span> <span class="op">&lt;-</span> <span class="va">HS</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span><span class="op">]</span> <span class="co"># select columns x1:x9</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">item_data</span><span class="op">)</span> <span class="co"># show first six rows</span></span></code></pre></div>
<pre><code><span><span class="co">##         x1   x2    x3       x4   x5        x6       x7   x8       x9</span></span>
<span><span class="co">## 1 3.333333 7.75 0.375 2.333333 5.75 1.2857143 3.391304 5.75 6.361111</span></span>
<span><span class="co">## 2 5.333333 5.25 2.125 1.666667 3.00 1.2857143 3.782609 6.25 7.916667</span></span>
<span><span class="co">## 3 4.500000 5.25 1.875 1.000000 1.75 0.4285714 3.260870 3.90 4.416667</span></span>
<span><span class="co">## 4 5.333333 7.75 3.000 2.666667 4.50 2.4285714 3.000000 5.30 4.861111</span></span>
<span><span class="co">## 5 4.833333 4.75 0.875 2.666667 4.00 2.5714286 3.695652 6.30 5.916667</span></span>
<span><span class="co">## 6 5.333333 5.00 2.250 1.000000 3.00 0.8571429 4.347826 6.65 7.500000</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">item_data</span>, <span class="fl">2</span>, <span class="va">sd</span><span class="op">)</span> <span class="co"># compute SD of each variable</span></span></code></pre></div>
<pre><code><span><span class="co">##       x1       x2       x3       x4       x5       x6       x7       x8       x9 </span></span>
<span><span class="co">## 1.167432 1.177451 1.130979 1.164116 1.290472 1.095603 1.089534 1.012615 1.009152</span></span></code></pre>
<p>All variables have standard deviations close to 1, so we can move
forward with the data as they are. Otherwise, we would recommend
re-scaling the variables.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;In the situation where variable scales have no
information value, one can do a correlation-structure analysis instead
using syntax of the form:
&lt;code&gt;minorbsem(..., correlation = TRUE)&lt;/code&gt;.&lt;/p&gt;"><sup>1</sup></a></p>
</div>
<div class="section level3">
<h3 id="model-syntax">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax"></a>
</h3>
<p>The model syntax is lavaan-style:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_basic</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">Visual =~ x1 + x2 + x3</span></span>
<span><span class="st">Verbal =~ x4 + x5 + x6</span></span>
<span><span class="st">Speed =~ x7 + x8 + x9"</span></span></code></pre></div>
<p>This model assumes three latent variables (or factors):
<em>visual</em>, <em>verbal</em>, and <em>speed</em>. The visual factor
has the indicators: x1, x2, and x3; the verbal factor has indicators:
x4, x5, and x6; the speed factor has indicators: x7, x8, and x9.</p>
</div>
<div class="section level3">
<h3 id="fit-the-model">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model"></a>
</h3>
<p>We run the analysis using the <code><a href="../reference/minorbsem.html">minorbsem()</a></code> function. By
default, the function assumes that minor factors influence the
covariance between the variables. <code>minorbsem</code> then prints out
the iterations from Stan – we show these iterations once so the reader
knows what to expect.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_cfa</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">syntax_basic</span>, data <span class="op">=</span> <span class="va">HS</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Processing user input ...</span></span></code></pre>
<pre><code><span><span class="co">## User input fully processed :)</span></span>
<span><span class="co">##  Now to modeling.</span></span></code></pre>
<pre><code><span><span class="co">## Error in get(paste0(generic, ".", class), envir = get_method_env()) : </span></span>
<span><span class="co">##   object 'type_sum.accel' not found</span></span></code></pre>
<pre><code><span><span class="co">## Fitting Stan model ...</span></span></code></pre>
<pre><code><span><span class="co">## Init values were only set for a subset of parameters. </span></span>
<span><span class="co">## Missing init values for the following parameters:</span></span>
<span><span class="co">##  - chain 1: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">##  - chain 2: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">##  - chain 3: gdp_alpha, loadings, res_sds_u, phi_mat_chol, res_cor_01, coefs, sigma_loadings_complex, gdp_loadings_complex, Sigma</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## To disable this message use options(cmdstanr_warn_inits = FALSE).</span></span></code></pre>
<pre><code><span><span class="co">## Running MCMC with 3 chains, at most 2 in parallel...</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: A is not symmetric. A[1,4] = inf, but A[4,1] = inf (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = inf, but A[2,1] = inf (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[1,2] = inf, but A[2,1] = inf (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 Exception: cholesky_decompose: A is not symmetric. A[7,8] = inf, but A[8,7] = inf (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 2</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 2 finished in 3.2 seconds.</span></span>
<span><span class="co">## Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: lkj_corr_cholesky_lpdf: Random variable[2] is 0, but must be positive! (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 324, column 2 to column 48)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 Exception: cholesky_decompose: Matrix m is not positive definite (in '/tmp/RtmpFjMc1R/model-217273132646.stan', line 432, column 6 to column 81)</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span></span></code></pre>
<pre><code><span><span class="co">## Chain 3</span></span></code></pre>
<pre><code><span><span class="co">## Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) </span></span>
<span><span class="co">## Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 1 finished in 4.4 seconds.</span></span>
<span><span class="co">## Chain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) </span></span>
<span><span class="co">## Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) </span></span>
<span><span class="co">## Chain 3 finished in 4.1 seconds.</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## All 3 chains finished successfully.</span></span>
<span><span class="co">## Mean chain execution time: 3.9 seconds.</span></span>
<span><span class="co">## Total execution time: 7.4 seconds.</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##              <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;"> mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Goodness of fit                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              PPP                    0.415                              1.002       1796  </span></span>
<span><span class="co">##              RMSE                   0.064   0.015    0.042     0.090   1.005        750  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Factor loadings                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Visual   =~   x1       0.939   0.127    0.733     1.153   1.003       1024  </span></span>
<span><span class="co">##              Visual   =~   x2       0.470   0.105    0.303     0.644   1.001       1708  </span></span>
<span><span class="co">##              Visual   =~   x3       0.624   0.105    0.452     0.795   1.001       1868  </span></span>
<span><span class="co">##              Verbal   =~   x4       1.000   0.094    0.848     1.158   1.002       1092  </span></span>
<span><span class="co">##              Verbal   =~   x5       1.064   0.101    0.900     1.233   1.002       1892  </span></span>
<span><span class="co">##              Verbal   =~   x6       0.932   0.088    0.791     1.080   1.003       1034  </span></span>
<span><span class="co">##              Speed    =~   x7       0.561   0.104    0.392     0.731   1.004       1776  </span></span>
<span><span class="co">##              Speed    =~   x8       0.677   0.108    0.504     0.861   1.001       1535  </span></span>
<span><span class="co">##              Speed    =~   x9       0.785   0.118    0.595     0.999   1.002        877  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Inter-factor correlations                         </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Verbal   ~~   Visual   0.424   0.079    0.293     0.552   1.001       2253  </span></span>
<span><span class="co">##              Speed    ~~   Visual   0.468   0.098    0.310     0.625   1.002       1650  </span></span>
<span><span class="co">##              Speed    ~~   Verbal   0.277   0.078    0.147     0.403   1.001       3310  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Residual variances                                </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              x1       ~~   x1       0.465   0.219    0.043     0.796   1.003        920  </span></span>
<span><span class="co">##              x2       ~~   x2       1.157   0.125    0.959     1.365   1.001       2395  </span></span>
<span><span class="co">##              x3       ~~   x3       0.883   0.131    0.666     1.092   1.002       1634  </span></span>
<span><span class="co">##              x4       ~~   x4       0.347   0.157    0.056     0.596   1.001        846  </span></span>
<span><span class="co">##              x5       ~~   x5       0.520   0.178    0.209     0.806   1.002       1592  </span></span>
<span><span class="co">##              x6       ~~   x6       0.328   0.137    0.069     0.539   1.003        786  </span></span>
<span><span class="co">##              x7       ~~   x7       0.871   0.119    0.680     1.065   1.000       1775  </span></span>
<span><span class="co">##              x8       ~~   x8       0.575   0.134    0.343     0.779   1.002       1506  </span></span>
<span><span class="co">##              x9       ~~   x9       0.407   0.171    0.074     0.660   1.003        772  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<div class="section level4">
<h4 id="output-structure">Output structure<a class="anchor" aria-label="anchor" href="#output-structure"></a>
</h4>
<p>At the top of the results table, <code>method = normal</code>
indicates the approach of estimating the residual covariances between
all items: the belief is that the standardized residual covariances
(SRCs) which reflect minor factor influences are normally distributed
with zero mean. The table also prints out the sample size of 301 – only
complete rows are retained for analysis.</p>
<p>We describe the column headers. The <code>from</code>,
<code>op</code> and <code>to</code> combination describe the type of
parameter being reported according to lavaan-style syntax. For example,
the <code>Visual =~ x1</code> row describes the loading from the visual
factor to item x1. The <code>mean</code>, <code>sd</code> and percentage
columns are descriptive statistics of posterior distributions. The
<code>mean</code> and <code>sd</code> function like the estimate and
standard error in standard frequentist statistics. The percentage
columns are credible intervals. By default, they are 90% credible
intervals, i.e. given the prior and data, there is a 90% chance the
parameter falls in this interval. <code>rhat</code> (pronounced R-hat)
and <code>ess_bulk</code> columns are the potential scale reduction
factor
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>)
and effective sample size (ESS) respectively <span class="citation">(Vehtari et al. 2021)</span> – they are useful for
checking parameter convergence. For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>,
values very close to 1 are preferable. For ESS, larger values are
preferable.
<!-- checks parameter convergence and should not be much larger than 1. In this case, all R values are between 1.000 and 1.006. -->
<!-- The ess_bulk stands for effective sample size (bulk). The larger the value, the better the model. Values in the hundreds are preferable. -->
A final analysis in a manuscript would ideally have all parameters with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>
under 1.01 and ESS above 400 for one to be sure parameter estimates have
converged <span class="citation">(Vehtari et al. 2021)</span>. An easy
way to meet these expectations is to increase the number of requested
samples when calling <code><a href="../reference/minorbsem.html">minorbsem()</a></code> via the
<code>warmup =</code> and <code>sampling =</code> arguments, see
<code><a href="../reference/minorbsem.html">?minorbsem</a></code>.</p>
<p>The parameter estimates are presented by the type of parameter.</p>
</div>
<div class="section level4">
<h4 id="goodness-of-fit">Goodness of fit<a class="anchor" aria-label="anchor" href="#goodness-of-fit"></a>
</h4>
<p><strong>PPP</strong>. The first section of results contains
parameters that help assess global model fit. “PPP” is the posterior
predictive <em>p</em>-value in the form described by <span class="citation">Muthén and Asparouhov (2012)</span>, and is akin to a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
test in standard SEMs. It is conventional to prefer values under .05 or
.10. Here, PPP = .382 indicating a good-fitting model. Desirable
PPP-values are to be expected by default in <code>minorbsem</code> as
the package accounts for model misspecification – alternatively stated:
PPP-values above .05 do not imply an absence of misfit and is not all
that informative by default. We report PPP since <code>minorbsem</code>
is also able to fit Bayesian SEMs that do not account for
misspecification, e.g. <code>minorbsem(..., method = "none")</code>.</p>
<p><strong>RMSE</strong>. This the root mean square error of
standardized residual covariances (SRCs) and communicates the typical
size of SRCs. One may also interpret this metric as the standard
deviation of SRCs with 95% of SRCs lying within 2 RMSE values from 0. In
this example, RMSE = 0.063 and we can expect some SRCs to be greater
than 0.10, suggesting some large SRCs <span class="citation">(Maydeu-Olivares 2017)</span>. Large SRCs challenge the
notion that model misspecification is due to the influence of minor
factors – if these influences are large, are these factors “minor”? It
is possible that the hypothesized structure is incorrect, or minor
factors have significant effects.</p>
</div>
<div class="section level4">
<h4 id="substantive-parameters">Substantive parameters<a class="anchor" aria-label="anchor" href="#substantive-parameters"></a>
</h4>
<p>The parameter estimates are reported by type of parameter: factor
loadings, inter-factor correlations, and error variances. For this
model, all items load on their respective factors with intervals that
clearly exclude 0. All factors are assumed standardized in minorbsem, so
only their correlations are reported; and all factors are non-trivially
correlated.</p>
</div>
</div>
<div class="section level3">
<h3 id="residual-plots">Residual plots<a class="anchor" aria-label="anchor" href="#residual-plots"></a>
</h3>
<p>Given that the RMSE suggests large standardized residual covariances
(SRCs), we can request a plot of SRCs using two options: a range-plot
and a heat-map.</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_residuals.html">plot_residuals</a></span><span class="op">(</span><span class="va">fit_cfa</span>, type <span class="op">=</span> <span class="st">"range"</span><span class="op">)</span></span></code></pre></div>
<p><img src="cfa_files/figure-html/unnamed-chunk-5-1.png" width="700"></p>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_residuals.html">plot_residuals</a></span><span class="op">(</span><span class="va">fit_cfa</span>, type <span class="op">=</span> <span class="st">"matrix"</span><span class="op">)</span></span></code></pre></div>
<p><img src="cfa_files/figure-html/unnamed-chunk-5-2.png" width="700"></p>
<p>The heat-map is particularly useful for highlighting the largest
SRCs. If these SRCs cluster in a non-random way, one may identify
potential model modifications.</p>
</div>
</div>
<div class="section level2">
<h2 id="bifactor-model-with-orthogonal-factors">Bifactor model with orthogonal factors<a class="anchor" aria-label="anchor" href="#bifactor-model-with-orthogonal-factors"></a>
</h2>
<p>To improve on the basic model, we consider the bifactor structure,
which builds on the basic CFA model by specifying a general factor ‘G’
that is reflected in all nine indicators. All factors are assumed
orthogonal.</p>
<div class="section level3">
<h3 id="model-syntax-1">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax-1"></a>
</h3>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_bifactor</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9"</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="va">syntax_basic</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/writeLines.html" class="external-link">writeLines</a></span><span class="op">(</span><span class="va">syntax_bifactor</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Visual =~ x1 + x2 + x3</span></span>
<span><span class="co">## Verbal =~ x4 + x5 + x6</span></span>
<span><span class="co">## Speed =~ x7 + x8 + x9</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="fit-the-model-1">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-1"></a>
</h3>
<p>The call to <code><a href="../reference/minorbsem.html">minorbsem()</a></code> needs to be of the form:
<code>minorbsem(..., orthogonal = TRUE)</code> to ensure the factors are
orthogonal:</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_bifactor</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span><span class="va">syntax_bifactor</span>, data <span class="op">=</span> <span class="va">HS</span>, orthogonal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##             <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;">  mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Goodness of fit                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             PPP                     0.389                              1.002       1484  </span></span>
<span><span class="co">##             RMSE                    0.028   0.013    0.008     0.052   1.019        464  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Factor loadings                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             G        =~   x1        0.944   0.110    0.761     1.124   1.000       1630  </span></span>
<span><span class="co">##             G        =~   x2        0.487   0.109    0.313     0.667   1.001       2056  </span></span>
<span><span class="co">##             G        =~   x3        0.623   0.100    0.451     0.787   1.000       2230  </span></span>
<span><span class="co">##             G        =~   x4        0.473   0.091    0.329     0.627   1.001       1880  </span></span>
<span><span class="co">##             G        =~   x5        0.427   0.099    0.273     0.595   1.002       2155  </span></span>
<span><span class="co">##             G        =~   x6        0.463   0.084    0.330     0.601   1.001       2237  </span></span>
<span><span class="co">##             G        =~   x7        0.109   0.088   -0.029     0.258   1.001       2357  </span></span>
<span><span class="co">##             G        =~   x8        0.287   0.078    0.165     0.417   1.000       2633  </span></span>
<span><span class="co">##             G        =~   x9        0.510   0.080    0.384     0.644   1.004       2057  </span></span>
<span><span class="co">##             Visual   =~   x1        0.223   0.178    0.015     0.591   1.000       1284  </span></span>
<span><span class="co">##             Visual   =~   x2       -0.126   0.518   -0.977     0.799   1.002       1252  </span></span>
<span><span class="co">##             Visual   =~   x3        0.013   0.473   -0.732     0.896   1.005       1451  </span></span>
<span><span class="co">##             Verbal   =~   x4        0.860   0.076    0.735     0.981   1.001       1426  </span></span>
<span><span class="co">##             Verbal   =~   x5        1.047   0.090    0.897     1.192   1.001       1627  </span></span>
<span><span class="co">##             Verbal   =~   x6        0.785   0.072    0.669     0.905   1.001       1922  </span></span>
<span><span class="co">##             Speed    =~   x7        0.725   0.118    0.538     0.925   1.000        942  </span></span>
<span><span class="co">##             Speed    =~   x8        0.714   0.113    0.534     0.924   1.002        975  </span></span>
<span><span class="co">##             Speed    =~   x9        0.431   0.082    0.293     0.561   1.001       1930  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Inter-factor correlations                          </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Visual   ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Verbal   ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Verbal   ~~   Visual    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   G         0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   Visual    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##             Speed    ~~   Verbal    0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Residual variances                                 </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             x1       ~~   x1        0.408   0.216    0.019     0.732   1.000        905  </span></span>
<span><span class="co">##             x2       ~~   x2        0.879   0.344    0.093     1.272   1.003        731  </span></span>
<span><span class="co">##             x3       ~~   x3        0.685   0.270    0.082     1.003   1.003        879  </span></span>
<span><span class="co">##             x4       ~~   x4        0.388   0.093    0.237     0.535   1.002        975  </span></span>
<span><span class="co">##             x5       ~~   x5        0.391   0.132    0.154     0.596   1.001       1117  </span></span>
<span><span class="co">##             x6       ~~   x6        0.376   0.075    0.254     0.499   1.000       2049  </span></span>
<span><span class="co">##             x7       ~~   x7        0.648   0.161    0.365     0.893   1.001        889  </span></span>
<span><span class="co">##             x8       ~~   x8        0.439   0.147    0.148     0.640   1.006        960  </span></span>
<span><span class="co">##             x9       ~~   x9        0.579   0.077    0.453     0.701   1.001       2638  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>Compared to the basic CFA model, the RMSE drops from .063 to .028,
suggesting a much better fitting model. All items load with 90%
intervals excluding 0 on the general factor, except for x7.
Additionally, x1 – x3 load confusingly on their specific factor, while
x4 – x9 load strongly on their specific factors especially when compared
to their general factor loadings. This pattern of factor loadings
provide little support for a bifactor structure.</p>
<!-- Regarding the factor loadings on the new factor 'G', items x1 through x6 and x9 all have relatively large loadings greater than 0.4, but items x7 and x8 do not load very well, with factor loadings of .112 and .289, respectively. For the factor F1 (Visual), all three items (x1, x2, and x3) have small loading under .25. For factor F2 (Verbal), all three items (x4, x5, and x6) load pretty well, with loadings of .857, 1.051, and .785, respectively. For factor F3 (Speed), all three factors (x7, x8, and x9) have good loadings greater than .40. In addition, `orthonogal=TRUE` argument set all the inter-factor correlations to be zero. -->
</div>
</div>
<div class="section level2">
<h2 id="bifactor-model-with-parameter-constraints">Bifactor model with parameter constraints<a class="anchor" aria-label="anchor" href="#bifactor-model-with-parameter-constraints"></a>
</h2>
<p>We instead explore a more constrained bifactor structure where
specific factor loadings are forced equal within each specific factor.
Note that minorbsem uses the same parameter constraint syntax as
lavaan:</p>
<div class="section level3">
<h3 id="model-syntax-2">Model syntax<a class="anchor" aria-label="anchor" href="#model-syntax-2"></a>
</h3>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">syntax_bifactor_cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span></span>
<span>  <span class="st">"G =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9"</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="st">"Visual =~ a * x1 + a * x2 + a * x3</span></span>
<span><span class="st">  Verbal =~ b * x4 + b * x5 + b * x6</span></span>
<span><span class="st">  Speed =~ c * x7 + c * x8 + c * x9"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<!-- This model is built upon the basic bifactor model by adding constraints. The loadings on the G factor remains unchanged as the basic bifactor model and allow to be freely estimated. However, the loadings of x1, x2, and x3 on F1 are forced to be the same. Similarly, loading of x4, x5, and x6 on F2 are forced to the same, and x7, x8, and x9 on F3 are also constrained to be the same number. -->
</div>
<div class="section level3">
<h3 id="fit-the-model-2">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-2"></a>
</h3>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_bifactor_cons</span> <span class="op">&lt;-</span> <span class="va">fit_bifactor_cons</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span></span>
<span>  <span class="va">syntax_bifactor_cons</span>,</span>
<span>  data <span class="op">=</span> <span class="va">HS</span>, orthogonal <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##              <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;"> mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Goodness of fit                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              PPP                    0.427                              1.000       1987  </span></span>
<span><span class="co">##              RMSE                   0.048   0.012    0.030     0.071   1.003        772  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Factor loadings                                   </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              G        =~   x1       0.867   0.116    0.669     1.056   1.003       1831  </span></span>
<span><span class="co">##              G        =~   x2       0.432   0.115    0.241     0.613   1.002       2537  </span></span>
<span><span class="co">##              G        =~   x3       0.572   0.113    0.383     0.756   1.002       1708  </span></span>
<span><span class="co">##              G        =~   x4       0.497   0.098    0.339     0.662   1.000       2116  </span></span>
<span><span class="co">##              G        =~   x5       0.489   0.113    0.308     0.684   1.000       1927  </span></span>
<span><span class="co">##              G        =~   x6       0.472   0.091    0.332     0.629   0.999       2131  </span></span>
<span><span class="co">##              G        =~   x7       0.133   0.095   -0.019     0.293   1.002       2530  </span></span>
<span><span class="co">##              G        =~   x8       0.287   0.086    0.149     0.428   1.001       2642  </span></span>
<span><span class="co">##              G        =~   x9       0.520   0.085    0.377     0.660   1.000       2555  </span></span>
<span><span class="co">##              Visual   =~   x1       0.280   0.149    0.032     0.511   1.002       1985  </span></span>
<span><span class="co">##              Visual   =~   x2       0.280   0.149    0.032     0.511   1.002       1985  </span></span>
<span><span class="co">##              Visual   =~   x3       0.280   0.149    0.032     0.511   1.002       1985  </span></span>
<span><span class="co">##              Verbal   =~   x4       0.864   0.060    0.765     0.962   1.002       1825  </span></span>
<span><span class="co">##              Verbal   =~   x5       0.864   0.060    0.765     0.962   1.002       1825  </span></span>
<span><span class="co">##              Verbal   =~   x6       0.864   0.060    0.765     0.962   1.002       1825  </span></span>
<span><span class="co">##              Speed    =~   x7       0.604   0.054    0.515     0.693   1.001       2586  </span></span>
<span><span class="co">##              Speed    =~   x8       0.604   0.054    0.515     0.693   1.001       2586  </span></span>
<span><span class="co">##              Speed    =~   x9       0.604   0.054    0.515     0.693   1.001       2586  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Inter-factor correlations                         </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              Visual   ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Verbal   ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Verbal   ~~   Visual   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   G        0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   Visual   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##              Speed    ~~   Verbal   0.000   0.000    0.000     0.000                     </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              <span style="font-weight: bold;">Residual variances                                </span>                          </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##              x1       ~~   x1       0.525   0.160    0.237     0.771   1.001       1511  </span></span>
<span><span class="co">##              x2       ~~   x2       1.106   0.120    0.917     1.307   1.000       3682  </span></span>
<span><span class="co">##              x3       ~~   x3       0.849   0.110    0.673     1.033   1.002       2568  </span></span>
<span><span class="co">##              x4       ~~   x4       0.352   0.081    0.216     0.485   1.000       2302  </span></span>
<span><span class="co">##              x5       ~~   x5       0.623   0.092    0.477     0.775   1.001       2435  </span></span>
<span><span class="co">##              x6       ~~   x6       0.250   0.082    0.108     0.382   1.004       1395  </span></span>
<span><span class="co">##              x7       ~~   x7       0.777   0.086    0.644     0.925   1.000       4108  </span></span>
<span><span class="co">##              x8       ~~   x8       0.568   0.072    0.452     0.691   1.001       3538  </span></span>
<span><span class="co">##              x9       ~~   x9       0.423   0.091    0.269     0.567   1.000       2419  </span></span>
<span><span class="co">##            ──────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>The RMSE increased since the model is more constrained. The pattern
of results with the parameter constraints imposed suggest the general
factor mostly reflects items x1 – x3, with other items more strongly
reflecting their specific factors. These results suggest limited
applicability of the bifactor model for these data.</p>
<!-- The results reveals that the nine loadings on the G factor vary greatly. x1 and x3 load pretty well on factor G, with loadings of .745 and .471, respectively. All remaining seven loadings are below .4. In addition, the constrained loadings on F1, F2, and F3 are .393, .955, and .693, respectively. -->
</div>
</div>
<div class="section level2">
<h2 id="non-simple-structure-model">Non-Simple Structure Model<a class="anchor" aria-label="anchor" href="#non-simple-structure-model"></a>
</h2>
<p>For our final model, we return to the original basic CFA and relax
simple structure. Unlike <span class="citation">Muthén and Asparouhov
(2012)</span> who do this using small-variance priors, minorbsem does
this using a global-local prior <span class="citation">(Uanhoro
2024)</span>. Precisely, this approach assumes that most cross-loadings
are indeed zero and there are some outlier non-zero cross loadings.</p>
<div class="section level3">
<h3 id="fit-the-model-3">Fit the model<a class="anchor" aria-label="anchor" href="#fit-the-model-3"></a>
</h3>
<p>The call to <code><a href="../reference/minorbsem.html">minorbsem()</a></code> needs to be of the form:
<code>minorbsem(..., simple_struc = FALSE)</code></p>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_non_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/minorbsem.html">minorbsem</a></span><span class="op">(</span><span class="va">syntax_basic</span>, data <span class="op">=</span> <span class="va">HS</span>, simple_struc <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                     Parameter estimates (method = normal, sample size(s) = 301)                     </span></span>
<span><span class="co">##             <span style="font-weight: bold;">from  </span>   <span style="font-weight: bold;">op</span>   <span style="font-weight: bold;">to    </span>   <span style="font-weight: bold;">  mean</span>   <span style="font-weight: bold;">   sd</span>   <span style="font-weight: bold;">5.000%</span>   <span style="font-weight: bold;">95.000%</span>   <span style="font-weight: bold;"> rhat</span>   <span style="font-weight: bold;">ess_bulk</span>  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Goodness of fit                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             PPP                     0.470                              1.003       1786  </span></span>
<span><span class="co">##             RMSE                    0.025   0.012    0.006     0.047   1.004        513  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Factor loadings                                    </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Visual   =~   x1        0.762   0.120    0.571     0.965   1.002       1106  </span></span>
<span><span class="co">##             Visual   =~   x2        0.559   0.105    0.395     0.731   1.001       2093  </span></span>
<span><span class="co">##             Visual   =~   x3        0.756   0.117    0.572     0.957   1.001       1166  </span></span>
<span><span class="co">##             Visual   =~   x4        0.023   0.071   -0.083     0.151   1.001       1704  </span></span>
<span><span class="co">##             Visual   =~   x5       -0.061   0.086   -0.217     0.051   1.002       1698  </span></span>
<span><span class="co">##             Visual   =~   x6        0.055   0.073   -0.043     0.190   1.001       1661  </span></span>
<span><span class="co">##             Visual   =~   x7       -0.140   0.149   -0.427     0.032   1.001       1174  </span></span>
<span><span class="co">##             Visual   =~   x8        0.041   0.115   -0.131     0.251   1.003       1245  </span></span>
<span><span class="co">##             Visual   =~   x9        0.314   0.124    0.095     0.509   1.002       1290  </span></span>
<span><span class="co">##             Verbal   =~   x1        0.136   0.110   -0.016     0.330   1.002       1028  </span></span>
<span><span class="co">##             Verbal   =~   x2        0.013   0.068   -0.093     0.130   1.001       1861  </span></span>
<span><span class="co">##             Verbal   =~   x3       -0.078   0.098   -0.267     0.045   1.001       1268  </span></span>
<span><span class="co">##             Verbal   =~   x4        0.987   0.076    0.866     1.112   1.003       2036  </span></span>
<span><span class="co">##             Verbal   =~   x5        1.137   0.085    1.007     1.286   1.003       1675  </span></span>
<span><span class="co">##             Verbal   =~   x6        0.896   0.074    0.774     1.019   1.001       1427  </span></span>
<span><span class="co">##             Verbal   =~   x7        0.025   0.073   -0.079     0.152   1.001       2025  </span></span>
<span><span class="co">##             Verbal   =~   x8       -0.028   0.069   -0.150     0.069   1.000       1921  </span></span>
<span><span class="co">##             Verbal   =~   x9        0.013   0.060   -0.081     0.114   1.003       2150  </span></span>
<span><span class="co">##             Speed    =~   x1        0.036   0.083   -0.076     0.190   1.002       1757  </span></span>
<span><span class="co">##             Speed    =~   x2       -0.051   0.079   -0.198     0.055   1.002       2051  </span></span>
<span><span class="co">##             Speed    =~   x3        0.030   0.077   -0.077     0.167   1.002       2124  </span></span>
<span><span class="co">##             Speed    =~   x4        0.004   0.057   -0.089     0.101   1.001       2195  </span></span>
<span><span class="co">##             Speed    =~   x5        0.004   0.065   -0.097     0.108   1.001       1826  </span></span>
<span><span class="co">##             Speed    =~   x6        0.002   0.054   -0.087     0.092   1.001       2033  </span></span>
<span><span class="co">##             Speed    =~   x7        0.760   0.120    0.579     0.966   1.001       1186  </span></span>
<span><span class="co">##             Speed    =~   x8        0.762   0.104    0.593     0.941   1.000       1498  </span></span>
<span><span class="co">##             Speed    =~   x9        0.507   0.095    0.355     0.672   1.003       1558  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Inter-factor correlations                          </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             Verbal   ~~   Visual    0.362   0.123    0.151     0.552   1.003       1126  </span></span>
<span><span class="co">##             Speed    ~~   Visual    0.284   0.168   -0.010     0.550   1.003       1251  </span></span>
<span><span class="co">##             Speed    ~~   Verbal    0.224   0.118    0.033     0.409   1.001       1563  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             <span style="font-weight: bold;">Residual variances                                 </span>                          </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##             x1       ~~   x1        0.668   0.128    0.452     0.860   1.002       1217  </span></span>
<span><span class="co">##             x2       ~~   x2        1.090   0.115    0.901     1.281   1.000       2791  </span></span>
<span><span class="co">##             x3       ~~   x3        0.737   0.133    0.514     0.945   1.000       1326  </span></span>
<span><span class="co">##             x4       ~~   x4        0.375   0.086    0.228     0.509   1.004       1373  </span></span>
<span><span class="co">##             x5       ~~   x5        0.431   0.110    0.248     0.609   1.004       1459  </span></span>
<span><span class="co">##             x6       ~~   x6        0.370   0.076    0.253     0.492   1.002       1090  </span></span>
<span><span class="co">##             x7       ~~   x7        0.660   0.134    0.434     0.870   1.002       1110  </span></span>
<span><span class="co">##             x8       ~~   x8        0.457   0.125    0.237     0.640   1.001       1308  </span></span>
<span><span class="co">##             x9       ~~   x9        0.570   0.075    0.450     0.692   1.000       2046  </span></span>
<span><span class="co">##           ───────────────────────────────────────────────────────────────────────────────</span></span>
<span><span class="co">##                                                                                          </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Column names: from, op, to, mean, sd, 5%, 95%, rhat, ess_bulk</span></span></code></pre>
<p>The effect of minor factors is small, RMSE = 0.024. The original
hypothesized loadings maintain their relation to their hypothesized
factors. Of the cross-loadings, only the relation from the visual factor
to x9 is non-trivial, with most being very close to 0. Additionally, the
interfactor correlations have all reduced from the original basic CFA,
suggesting that forcing cross-loadings to zero artificially inflated
interfactor correlations <span class="citation">(Ferrando and
Lorenzo-Seva 2000)</span>.</p>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="works-cited">Works Cited<a class="anchor" aria-label="anchor" href="#works-cited"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Ferrando2000" class="csl-entry">
Ferrando, Pere J, and Urbano Lorenzo-Seva. 2000. <span>“Unrestricted
Versus Restricted Factor Analysis of Multidimensional Test Items: Some
Aspects of the Problem and Some Suggestions.”</span>
<em>Psicológica</em> 21 (2): 301–23. <a href="https://www.uv.es/revispsi/articulos3.00/ferran7.pdf" class="external-link">https://www.uv.es/revispsi/articulos3.00/ferran7.pdf</a>.
</div>
<div id="ref-Maydeu-Olivares2017a" class="csl-entry">
Maydeu-Olivares, Alberto. 2017. <span>“Assessing the Size of Model
Misfit in Structural Equation Models.”</span> <em>Psychometrika</em> 82
(3): 533–58. <a href="https://doi.org/10.1007/s11336-016-9552-7" class="external-link">https://doi.org/10.1007/s11336-016-9552-7</a>.
</div>
<div id="ref-Muthen2012" class="csl-entry">
Muthén, Bengt, and Tihomir Asparouhov. 2012. <span>“Bayesian Structural
Equation Modeling: <span>A</span> More Flexible Representation of
Substantive Theory.”</span> <em>Psychological Methods</em> 17 (3):
313–35. <a href="https://doi.org/10.1037/a0026802" class="external-link">https://doi.org/10.1037/a0026802</a>.
</div>
<div id="ref-Rosseel2012" class="csl-entry">
Rosseel, Yves. 2012. <span>“Lavaan: <span>An</span> <span>R</span>
Package for Structural Equation Modeling.”</span> <em>Journal of
Statistical Software</em> 48 (2): 1–20. <a href="https://doi.org/10.18637/jss.v048.i02" class="external-link">https://doi.org/10.18637/jss.v048.i02</a>.
</div>
<div id="ref-uanhoro_comparison_2024" class="csl-entry">
Uanhoro, James O. 2024. <span>“A Comparison of Different Prior Choices
for Estimating the Influence of Minor Factors in <span>Bayesian</span>
Structural Equation Models.”</span> In <em><span>Annual</span>
<span>Meeting</span> of the American <span>Educational</span>
<span>Research</span> <span>Association</span></em>. Philadelphia, PA.
</div>
<div id="ref-vehtari_rank-normalization_2021" class="csl-entry">
Vehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and
Paul-Christian Bürkner. 2021. <span>“Rank-Normalization, Folding, and
Localization: <span>An</span> Improved
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>R</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\widehat{R}</annotation></semantics></math>
for Assessing Convergence of MCMC (with
<span>Discussion</span>).”</span> <em>Bayesian Analysis</em> 16 (2):
667–718. <a href="https://doi.org/10.1214/20-BA1221" class="external-link">https://doi.org/10.1214/20-BA1221</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by James O. Uanhoro.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
