@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2022},
  url = {https://www.R-project.org/},
}
@Manual{R-papaja,
  title = {{papaja}: {Prepare} reproducible {APA} journal articles with {R Markdown}},
  author = {Frederik Aust and Marius Barth},
  year = {2022},
  note = {R package version 0.1.1},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-tinylabels,
  title = {{tinylabels}: Lightweight Variable Labels},
  author = {Marius Barth},
  year = {2022},
  note = {R package version 0.2.3},
  url = {https://cran.r-project.org/package=tinylabels},
}

@article{Alvarez2014,
  title         = {Bayesian Inference for a Covariance Matrix},
  author        = {Alvarez, Ignacio and Niemi, Jarad and Simpson, Matt},
  year          = {2014},
  month         = apr,
  journal       = {Conference on Applied Statistics in Agriculture},
  volume        = {26},
  eprint        = {1408.4050},
  eprinttype    = {arxiv},
  pages         = {71--82},
  doi           = {10.4148/2475-7772.1004},
  archiveprefix = {arXiv},
  arxivid       = {1408.4050},
  file          = {/home/james/Dropbox/zotero-library/AUTH/Alvarez et al/alvarez_et_al_2014_bayesian_inference_for_a_covariance_matrix.pdf}
}

@article{Barnard2000a,
  title   = {Modeling Covariance Matrices in Terms of Standard Deviations and Correlations, with Application to Shrinkage},
  author  = {Barnard, John and McCulloch, Robert and Meng, Xiao-Li},
  year    = {2000},
  journal = {Statistica Sinica},
  volume  = {10},
  number  = {4},
  pages   = {1281--1311},
  file    = {/home/james/Dropbox/zotero-library/AUTH/Barnard et al/barnard_et_al_2000_modeling_covariance_matrices_in_terms_of_standard_deviations_and_correlations,.pdf}
}

@article{becker1992joes,
  title     = {Using Results From Replicated Studies to Estimate Linear Models},
  author    = {Becker, Betsy Jane},
  year      = {1992},
  month     = dec,
  journal   = {Journal of Educational Statistics},
  volume    = {17},
  number    = {4},
  pages     = {341--362},
  publisher = {{American Educational Research Association}},
  issn      = {0362-9791},
  doi       = {10.3102/10769986017004341},
  abstract  = {This article outlines analyses for the results of a series of studies examining intercorrelations among a set of p + 1 variables. A test of whether a common population correlation matrix underlies the set of empirical results is given. Methods are presented for estimating either a pooled or average correlation matrix, depending on whether the studies appear to arise from a single population. A random effects model provides the basis for estimation and testing when the series of correlation matrices may not share a common population matrix. Finally, I show how a pooled correlation matrix (or average matrix) can be used to estimate the standardized coefficients of a regression model for variables measured in the series of studies. Data from a synthesis of relationships among mathematical, verbal, and spatial ability measures illustrate the procedures.},
  langid    = {english},
  keywords  = {correlations,meta-analysis,standardized regression},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Becker/becker_1992_using_results_from_replicated_studies_to_estimate_linear_models.pdf}
}

@article{chen1979jrsssbm,
  title      = {Bayesian {{Inference}} for a {{Normal Dispersion Matrix}} and Its {{Application}} to {{Stochastic Multiple Regression Analysis}}},
  author     = {Chen, Chan-Fu},
  year       = {1979},
  journal    = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume     = {41},
  number     = {2},
  pages      = {235--248},
  issn       = {2517-6161},
  doi        = {10.1111/j.2517-6161.1979.tb01078.x},
  abstract   = {This paper discusses Bayesian inference procedures for a normal dispersion matrix. Structural information for the prior mean of the dispersion matrix is incorporated into the analysis through a Normal-Wishart prior distribution. Many of the resulting Bayes estimates are invariant, consistent and asymptotically efficient. Using this procedure, a coherent Bayesian argument for stochastic multiple regression analysis is developed, where dependent and independent variables are jointly random, without experimental control. It is shown that ordinary least squares, a general form of ridge regression, and factor analysis regression methods can be represented as special cases within this general framework. The preliminary report of a simulation study indicates that the Bayesian regression techniques demonstrate substantial improvements over least squares, even using frequentist criteria. Finally, the related problem of joint estimation of the normal population mean and dispersion matrix is briefly discussed in Section 5. The resulting Bayes estimate for the population mean is shown to be closely related to Stein estimates.},
  langid     = {english},
  keywords   = {bayes estimate,dispersion matrix,em algorithm,exchangeability,factor analysis model,factor analysis regression,intraclass correlation matrix,least squares,m-group regression,natural conjugate priors,ridge regression,social science applications,stein estimates,stochastic multiple regression analysis},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1979.tb01078.x},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Chen/chen_1979_bayesian_inference_for_a_normal_dispersion_matrix_and_its_application_to.pdf}
}

@misc{cheung[aut2021,
  title      = {{{metaSEM}}: Meta-Analysis Using Structural Equation Modeling},
  shorttitle = {{{metaSEM}}},
  author     = {Cheung, Mike W.-L.},
  year       = {2021},
  month      = may,
  abstract   = {A collection of functions for conducting meta-analysis using a structural equation modeling (SEM) approach via the 'OpenMx' and 'lavaan' packages. It also implements various procedures to perform meta-analytic structural equation modeling on the correlation and covariance matrices, see Cheung (2015) {$<$}doi:10.3389/fpsyg.2014.01521{$>$}.},
  copyright  = {GPL-2 | GPL-3 [expanded from: GPL ({$\geq$} 2)]},
  keywords   = {MetaAnalysis,Psychometrics},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Cheung  [aut_cre/cheung_[aut_cre_2021_metasem_-_meta-analysis_using_structural_equation_modeling.pdf}
}

@article{cheung2005pm,
  title      = {Meta-Analytic Structural Equation Modeling: A Two-Stage Approach},
  shorttitle = {Meta-Analytic Structural Equation Modeling},
  author     = {Cheung, Mike W.-L. and Chan, Wai},
  year       = {2005},
  month      = mar,
  journal    = {Psychological Methods},
  volume     = {10},
  number     = {1},
  pages      = {40--64},
  issn       = {1082-989X},
  doi        = {10.1037/1082-989X.10.1.40},
  abstract   = {To synthesize studies that use structural equation modeling (SEM), researchers usually use Pearson correlations (univariate r), Fisher z scores (univariate z), or generalized least squares (GLS) to combine the correlation matrices. The pooled correlation matrix is then analyzed by the use of SEM. Questionable inferences may occur for these ad hoc procedures. A 2-stage structural equation modeling (TSSEM) method is proposed to incorporate meta-analytic techniques and SEM into a unified framework. Simulation results reveal that the univariate-r, univariate-z, and TSSEM methods perform well in testing the homogeneity of correlation matrices and estimating the pooled correlation matrix. When fitting SEM, only TSSEM works well. The GLS method performed poorly in small to medium samples.},
  langid     = {english},
  pmid       = {15810868},
  keywords   = {Humans,Meta-Analysis as Topic,Psychology},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Cheung_Chan/cheung_chan_2005_meta-analytic_structural_equation_modeling_-_a_two-stage_approach.pdf}
}

@article{cheung2014,
  title    = {Fixed- and Random-Effects Meta-Analytic Structural Equation Modeling: Examples and Analyses in {{R}}.},
  author   = {Cheung, Mike W.-L.},
  year     = {2014},
  journal  = {Behavior Research Methods},
  volume   = {46},
  number   = {1},
  doi      = {10.3758/s13428-013-0361-y}
}

@article{cheung2015fp,
  title      = {{{metaSEM}}: An {{R}} Package for Meta-Analysis Using Structural Equation Modeling},
  shorttitle = {{{metaSEM}}},
  author     = {Cheung, Mike W.-L.},
  year       = {2015},
  month      = jan,
  journal    = {Frontiers in Psychology},
  volume     = {5},
  issn       = {1664-1078},
  doi        = {10.3389/fpsyg.2014.01521},
  langid     = {english},
  file       = {/home/james/zotero-system/storage/T5S6AKCI/Cheung - 2015 - metaSEM an R package for meta-analysis using stru.pdf}
}

@article{Cheung2016,
  title    = {A Guide to Conducting a Meta-Analysis},
  author   = {Cheung, Mike W.-L. and Vijayakumar, Ranjith},
  year     = {2016},
  journal  = {Neuropsychology Review},
  volume   = {26},
  number   = {2},
  issn     = {15736660},
  doi      = {10.1007/s11065-016-9319-z},
  abstract = {Meta-analysis is widely accepted as the preferred method to synthesize research findings in various disciplines. This paper provides an introduction to when and how to conduct a meta- analysis. Several practical questions, such as advantages of meta-analysis over conventional narrative review and the number of studies required for a meta-analysis, are addressed. Common meta-analytic models are then introduced. An artificial dataset is used to illustrate how a meta-analysis is conducted in several software packages. The paper concludes with some common pitfalls of meta-analysis and their solutions. The primary goal of this paper is to provide a summary background to readers who would like to conduct their first meta- analytic study.},
  isbn     = {1573-6660 (Electronic) 1040-7308 (Linking)},
  pmid     = {27209412},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Cheung_Vijayakumar/cheung_vijayakumar_2016_a_guide_to_conducting_a_meta-analysis.pdf}
}

@article{cheung2017hpr,
  title      = {Applications of Meta-Analytic Structural Equation Modelling in Health Psychology: Examples, Issues, and Recommendations},
  shorttitle = {Applications of Meta-Analytic Structural Equation Modelling in Health Psychology},
  author     = {Cheung, Mike W.-L. and Hong, Ryan Y.},
  year       = {2017},
  month      = jul,
  journal    = {Health Psychology Review},
  volume     = {11},
  number     = {3},
  pages      = {265--279},
  publisher  = {{Routledge}},
  issn       = {1743-7199},
  doi        = {10.1080/17437199.2017.1343678},
  abstract   = {Statistical methods play an important role in behavioural, medical, and social sciences. Two recent statistical advances are structural equation modelling (SEM) and meta-analysis. SEM is used to test hypothesised models based on substantive theories, which can be path, confirmatory factor analytic, or full structural equation models. Meta-analysis is used to synthesise research findings in a particular topic. This article demonstrates another recent statistical advance \textendash{} meta-analytic structural equation modelling (MASEM) \textendash{} that combines meta-analysis and SEM to synthesise research findings for the purpose of testing hypothesised models. Using the theory of planned behaviour as an example, we show how MASEM can be used to address important research questions that cannot be answered by univariate meta-analyses on Pearson correlations. Specifically, MASEM allows researchers to: (1) test whether the proposed models are consistent with the data; (2) estimate partial effects after controlling for other variables; (3) estimate functions of parameter estimates such as indirect effects; and (4) include latent variables in the models. We illustrate the procedures with an example on the theory of planned behaviour. Practical issues in MASEM and suggested solutions are discussed.},
  pmid       = {28625100},
  keywords   = {health psychology,meta-analysis,meta-analytic structural equation modelling,Structural equation modelling,theory of planned behaviour},
  annotation = {\_eprint: https://doi.org/10.1080/17437199.2017.1343678},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Cheung_Hong/cheung_hong_2017_applications_of_meta-analytic_structural_equation_modelling_in_health.pdf;/home/james/zotero-system/storage/XC394HSS/Cheung and Hong - 2017 - Applications of meta-analytic structural equation .pdf}
}

@article{daniels1999jasa,
  title      = {Nonconjugate {{Bayesian Estimation}} of {{Covariance Matrices}} and Its {{Use}} in {{Hierarchical Models}}},
  author     = {Daniels, Michael J. and Kass, Robert E.},
  year       = {1999},
  month      = dec,
  journal    = {Journal of the American Statistical Association},
  volume     = {94},
  number     = {448},
  pages      = {1254--1263},
  publisher  = {{Taylor \& Francis}},
  issn       = {0162-1459},
  doi        = {10.1080/01621459.1999.10473878},
  abstract   = {The problem of estimating a covariance matrix in small samples has been considered by several authors following early work by Stein. This problem can be especially important in hierarchical models where the standard errors of fixed and random effects depend on estimation of the covariance matrix of the distribution of the random effects. We propose a set of hierarchical priors (HPs) for the covariance matrix that produce posterior shrinkage toward a specified structure\textemdash here we examine shrinkage toward diagonality. We then address the computational difficulties raised by incorporating these priors, and nonconjugate priors in general, into hierarchical models. We apply a combination of approximation, Gibbs sampling (possibly with a Metropolis step), and importance reweighting to fit the models, and compare this hybrid approach to alternative Markov Chain Monte Carlo methods. Our investigation involves three alternative HPs. The first works with the spectral decomposition of the covariance matrix and produces both shrinkage of the eigenvalues toward each other and shrinkage of the rotation matrix toward the identity. The second produces shrinkage of the correlations toward 0, and the third uses a conjugate Wishart distribution to shrink toward diagonality. A simulation study shows that the first two HPs can be very effective in reducing small-sample risk, whereas the conjugate Wishart version sometimes performs very poorly. We evaluate the computational algorithm in the context of a normal nonlinear random-effects model and illustrate the methodology with a logistic random-effects model.},
  keywords   = {Givens angles,Hierarchical prior,Random effects,Shrinkage,Variance matrix.},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1999.10473878},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Daniels_Kass/daniels_kass_1999_nonconjugate_bayesian_estimation_of_covariance_matrices_and_its_use_in.pdf}
}

@article{dejonge2020zfp,
  title     = {Dealing {{With Artificially Dichotomized Variables}} in {{Meta-Analytic Structural Equation Modeling}}},
  author    = {{de Jonge}, Hannelies and Jak, Suzanne and Kan, Kees-Jan},
  year      = {2020},
  month     = mar,
  journal   = {Zeitschrift f\"ur Psychologie},
  volume    = {228},
  number    = {1},
  pages     = {25--35},
  publisher = {{Hogrefe Publishing}},
  issn      = {2190-8370},
  doi       = {10.1027/2151-2604/a000395},
  abstract  = {. Meta-analytic structural equation modeling (MASEM) is a relatively new method in which effect sizes of different independent studies between multiple variables are typically first pooled into a matrix and next analyzed using structural equation modeling. While its popularity is increasing, there are issues still to be resolved, such as how to deal with primary studies in which variables have been artificially dichotomized. To be able to advise researchers who apply MASEM and need to deal with this issue, we performed two simulation studies using random-effects two stage structural equation modeling. We simulated data according to a full and partial mediation model and systematically varied the size of one (standardized) path coefficient ({$\beta$}MX~=~.16, {$\beta$}MX~=~.23, {$\beta$}MX~=~.33), the percentage of dichotomization (25\%, 75\%, 100\%), and the cut-off point of dichotomization (.5, .1). We analyzed the simulated datasets in two different ways, namely, by using (1) the point-biserial and (2) the biserial correlation as effect size between the artificially dichotomized predictor and continuous variables. The results of these simulation studies indicate that the biserial correlation is the most appropriate effect size to use, as it provides unbiased estimates of the path coefficients in the population.},
  keywords  = {artificially dichotomized variables,biserial correlation,meta-analytic structural equation modeling,point-biserial correlation},
  file      = {/home/james/Dropbox/zotero-library/AUTH/de Jonge et al/de_jonge_et_al_2020_dealing_with_artificially_dichotomized_variables_in_meta-analytic_structural.pdf}
}

@article{gaskins2016jocags,
  title      = {Covariance {{Partition Priors}}: {{A Bayesian Approach}} to {{Simultaneous Covariance Estimation}} for {{Longitudinal Data}}},
  shorttitle = {Covariance {{Partition Priors}}},
  author     = {Gaskins, J. T. and Daniels, M. J.},
  year       = {2016},
  month      = jan,
  journal    = {Journal of Computational and Graphical Statistics},
  volume     = {25},
  number     = {1},
  pages      = {167--186},
  issn       = {1061-8600, 1537-2715},
  doi        = {10.1080/10618600.2015.1028549},
  langid     = {english},
  file       = {/home/james/zotero-system/storage/MSZZ9B99/gaskins2016.pdf.pdf;/home/james/zotero-system/storage/WEK9RNG4/Gaskins and Daniels - 2016 - Covariance Partition Priors A Bayesian Approach t.pdf}
}

@book{gupta1999,
  title       = {Matrix Variate Distributions},
  author      = {Gupta, A. K. and Nagar, D. K.},
  year        = {1999},
  month       = oct,
  publisher   = {{CRC Press}},
  abstract    = {Useful in physics, economics, psychology, and other fields, random matrices play an important role in the study of multivariate statistical methods. Until now, however, most of the material on random matrices could only be found scattered in various statistical journals. Matrix Variate Distributions gathers and systematically presents most of the recent developments in continuous matrix variate distribution theory and includes new results.After a review of the essential background material, the authors investigate the range of matrix variate distributions, including:matrix variate normal distributionWishart distributionMatrix variate t-distributionMatrix variate beta distributionF-distributionMatrix variate Dirichlet distributionMatrix quadratic formsWith its inclusion of new results, Matrix Variate Distributions promises to stimulate further research and help advance the field of multivariate statistical analysis.},
  googlebooks = {PQOYnT7P1loC},
  isbn        = {978-1-58488-046-2},
  langid      = {english},
  keywords    = {Mathematics / Applied,Mathematics / Probability \& Statistics / General},
  file        = {/home/james/Dropbox/zotero-library/AUTH/Gupta_Nagar/gupta_nagar_1999_matrix_variate_distributions.djvu}
}

@article{huang2006b,
  title   = {Covariance Matrix Selection and Estimation via Penalised Normal Likelihood},
  author  = {Huang, Jianhua Z. and Liu, Naiping and Pourahmadi, Mohsen and Liu, Linxu},
  year    = {2006},
  month   = mar,
  journal = {Biometrika},
  volume  = {93},
  number  = {1},
  pages   = {85--98},
  issn    = {1464-3510, 0006-3444},
  doi     = {10.1093/biomet/93.1.85},
  langid  = {english},
  file    = {/home/james/Dropbox/zotero-library/AUTH/Huang et al/huang_et_al_2006_covariance_matrix_selection_and_estimation_via_penalised_normal_likelihood.pdf}
}

@article{jak2018mbr,
  title      = {Accounting for {{Missing Correlation Coefficients}} in {{Fixed-Effects MASEM}}},
  author     = {Jak, Suzanne and Cheung, Mike W.-L.},
  year       = {2018},
  month      = jan,
  journal    = {Multivariate Behavioral Research},
  volume     = {53},
  number     = {1},
  pages      = {1--14},
  publisher  = {{Routledge}},
  issn       = {0027-3171},
  doi        = {10.1080/00273171.2017.1375886},
  abstract   = {Meta-analytic structural equation modeling (MASEM) is increasingly applied to advance theories by synthesizing existing findings. MASEM essentially consists of two stages. In Stage 1, a pooled correlation matrix is estimated based on the reported correlation coefficients in the individual studies. In Stage 2, a structural model (such as a path model) is fitted to explain the pooled correlations. Frequently, the individual studies do not provide all the correlation coefficients between the research variables. In this study, we modify the currently optimal MASEM-method to deal with missing correlation coefficients, and compare its performance with existing methods. This study is the first to evaluate the performance of fixed-effects MASEM methods under different levels of missing correlation coefficients. We found that the often used univariate methods performed very poorly, while the multivariate methods performed well overall.},
  pmid       = {29220593},
  keywords   = {meta-analysis,Meta-analytic structural equation modeling,missing data,TSSEM},
  annotation = {\_eprint: https://doi.org/10.1080/00273171.2017.1375886},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Jak_Cheung/jak_cheung_2018_accounting_for_missing_correlation_coefficients_in_fixed-effects_masem.pdf;/home/james/Dropbox/zotero-library/AUTH/Jak_Cheung/jak_cheung_2018_accounting_for_missing_correlation_coefficients_in_fixed-effects_masem2.pdf}
}

@article{jennrich1970jasa,
  title      = {An {{Asymptotic}} {$X$}2 {{Test}} for the {{Equality}} of {{Two Correlation Matrices}}},
  author     = {Jennrich, Robert I.},
  year       = {1970},
  month      = jun,
  journal    = {Journal of the American Statistical Association},
  volume     = {65},
  number     = {330},
  pages      = {904--912},
  publisher  = {{Taylor \& Francis}},
  issn       = {0162-1459},
  doi        = {10.1080/01621459.1970.10481133},
  abstract   = {An asymptotic {$\chi$}2 test for the equality of two correlation matrices is derived. The key result is a simple representation for the inverse of the asymptotic covariance matrix of a sample correlation matrix. The test statistic has the form of a standard normal theory statistic for testing the equality of two covariance matrices with a correction term added. The applicability of asymptotic theory is demonstrated by two simulation studies and the statistic is used to test the difference in the factor patterns resulting from a set of tests given to retarded and non-retarded children. Two related tests are presented: a test for a specified correlation matrix and a test for equality of correlation matrices in two or more populations.},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.1970.10481133},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Jennrich/jennrich_1970_an_asymptotic_Ï‡2_test_for_the_equality_of_two_correlation_matrices.pdf}
}

@article{ke2019semmj,
  title      = {Bayesian Meta-Analytic {{SEM}}: A One-Stage Approach to Modeling Between-Studies Heterogeneity in Structural Parameters},
  shorttitle = {Bayesian {{Meta-Analytic SEM}}},
  author     = {Ke, Zijun and Zhang, Qian and Tong, Xin},
  year       = {2019},
  month      = may,
  journal    = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume     = {26},
  number     = {3},
  pages      = {348--370},
  publisher  = {{Routledge}},
  issn       = {1070-5511},
  doi        = {10.1080/10705511.2018.1530059},
  abstract   = {Meta-analytic structural equation modeling (MASEM) refers to a set of meta-analysis techniques for combining and comparing structural equation modeling (SEM) results from multiple studies. Existing approaches to MASEM cannot appropriately model between-studies heterogeneity in structural parameters because of missing correlations, lack model fit assessment, and suffer from several theoretical limitations. In this study, we address the major shortcomings of existing approaches by proposing a novel Bayesian multilevel SEM approach. Simulation results showed that the proposed approach performed satisfactorily in terms of parameter estimation and model fit evaluation when the number of studies and the within-study sample size were sufficiently large and when correlations were missing completely at random. An empirical example about the structure of personality based on a subset of data was provided. Results favored the third factor structure over the hierarchical structure. We end the article with discussions and future directions.},
  keywords   = {Bayesian approach,MASEM,meta-analysis,multilevel SEM,structural equation modeling},
  annotation = {\_eprint: https://doi.org/10.1080/10705511.2018.1530059},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Ke et al/ke_et_al_2019_bayesian_meta-analytic_sem_-_a_one-stage_approach_to_modeling_between-studies.pdf}
}

@article{lan2020ba,
  title    = {Flexible {{Bayesian Dynamic Modeling}} of {{Correlation}} and {{Covariance Matrices}}},
  author   = {Lan, Shiwei and Holbrook, Andrew and Elias, Gabriel A. and Fortin, Norbert J. and Ombao, Hernando and Shahbaba, Babak},
  year     = {2020},
  month    = dec,
  journal  = {Bayesian analysis},
  volume   = {15},
  number   = {4},
  pages    = {1199--1228},
  issn     = {1936-0975},
  doi      = {10.1214/19-ba1173},
  abstract = {Modeling correlation (and covariance) matrices can be challenging due to the positive-definiteness constraint and potential high-dimensionality. Our approach is to decompose the covariance matrix into the correlation and variance matrices and propose a novel Bayesian framework based on modeling the correlations as products of unit vectors. By specifying a wide range of distributions on a sphere (e.g. the squared-Dirichlet distribution), the proposed approach induces flexible prior distributions for covariance matrices (that go beyond the commonly used inverse-Wishart prior). For modeling real-life spatio-temporal processes with complex dependence structures, we extend our method to dynamic cases and introduce unit-vector Gaussian process priors in order to capture the evolution of correlation among components of a multivariate time series. To handle the intractability of the resulting posterior, we introduce the adaptive {$\Delta$}-Spherical Hamiltonian Monte Carlo. We demonstrate the validity and flexibility of our proposed framework in a simulation study of periodic processes and an analysis of rat's local field potential activity in a complex sequence memory task.},
  pmcid    = {PMC8048134},
  pmid     = {33868547},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Lan et al/lan_et_al_2020_flexible_bayesian_dynamic_modeling_of_correlation_and_covariance_matrices.pdf}
}

@article{ledoit2003joef,
  title    = {Improved Estimation of the Covariance Matrix of Stock Returns with an Application to Portfolio Selection},
  author   = {Ledoit, Olivier and Wolf, Michael},
  year     = {2003},
  month    = dec,
  journal  = {Journal of Empirical Finance},
  volume   = {10},
  number   = {5},
  pages    = {603--621},
  issn     = {0927-5398},
  doi      = {10.1016/S0927-5398(03)00007-0},
  abstract = {This paper proposes to estimate the covariance matrix of stock returns by an optimally weighted average of two existing estimators: the sample covariance matrix and single-index covariance matrix. This method is generally known as shrinkage, and it is standard in decision theory and in empirical Bayesian statistics. Our shrinkage estimator can be seen as a way to account for extra-market covariance without having to specify an arbitrary multifactor structure. For NYSE and AMEX stock returns from 1972 to 1995, it can be used to select portfolios with significantly lower out-of-sample variance than a set of existing estimators, including multifactor models.},
  langid   = {english},
  keywords = {Covariance matrix estimation,Factor models,Portfolio selection,Shrinkage method},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Ledoit_Wolf/ledoit_wolf_2003_improved_estimation_of_the_covariance_matrix_of_stock_returns_with_an.pdf;/home/james/zotero-system/storage/S4UWLMUA/Ledoit and Wolf - 2003 - Improved estimation of the covariance matrix of st.pdf}
}

@article{ledoit2004joma,
  title    = {A Well-Conditioned Estimator for Large-Dimensional Covariance Matrices},
  author   = {Ledoit, Olivier and Wolf, Michael},
  year     = {2004},
  month    = feb,
  journal  = {Journal of Multivariate Analysis},
  volume   = {88},
  number   = {2},
  pages    = {365--411},
  issn     = {0047-259X},
  doi      = {10.1016/S0047-259X(03)00096-4},
  abstract = {Many applied problems require a covariance matrix estimator that is not only invertible, but also well-conditioned (that is, inverting it does not amplify estimation error). For large-dimensional covariance matrices, the usual estimator\textemdash the sample covariance matrix\textemdash is typically not well-conditioned and may not even be invertible. This paper introduces an estimator that is both well-conditioned and more accurate than the sample covariance matrix asymptotically. This estimator is distribution-free and has a simple explicit formula that is easy to compute and interpret. It is the asymptotically optimal convex linear combination of the sample covariance matrix with the identity matrix. Optimality is meant with respect to a quadratic loss function, asymptotically as the number of observations and the number of variables go to infinity together. Extensive Monte Carlo confirm that the asymptotic results tend to hold well in finite sample.},
  langid   = {english},
  keywords = {Condition number,Covariance matrix estimation,Empirical Bayes,General asymptotics,Shrinkage},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Ledoit_Wolf/ledoit_wolf_2004_a_well-conditioned_estimator_for_large-dimensional_covariance_matrices.pdf;/home/james/Dropbox/zotero-library/AUTH/Ledoit_Wolf/ledoit_wolf_2004_a_well-conditioned_estimator_for_large-dimensional_covariance_matrices2.pdf}
}

@article{pourahmadi1999b,
  title      = {Joint {{Mean-Covariance Models}} with {{Applications}} to {{Longitudinal Data}}: {{Unconstrained Parameterisation}}},
  shorttitle = {Joint {{Mean-Covariance Models}} with {{Applications}} to {{Longitudinal Data}}},
  author     = {Pourahmadi, Mohsen},
  year       = {1999},
  journal    = {Biometrika},
  volume     = {86},
  number     = {3},
  pages      = {677--690},
  publisher  = {{[Oxford University Press, Biometrika Trust]}},
  issn       = {0006-3444},
  abstract   = {We provide unconstrained parameterisation for and model a covariance using covariates. The Cholesky decomposition of the inverse of a covariance matrix is used to associate a unique unit lower triangular and a unique diagonal matrix with each covariance matrix. The entries of the lower triangular and the log of the diagonal matrix are unconstrained and have meaning as regression coefficients and prediction variances when regressing a measurement on its predecessors. An extended generalised linear model is introduced for joint modelling of the vectors of predictors for the mean and covariance subsuming the joint modelling strategy for mean and variance heterogeneity, Gabriel's antedependence models, Dempster's covariance selection models and the class of graphical models. The likelihood function and maximum likelihood estimators of the covariance and the mean parameters are studied when the observations are normally distributed. Applications to modelling nonstationary dependence structures and multivariate data are discussed and illustrated using real data. A graphical method, similar to that based on the correlogram in time series, is developed and used to identify parametric models for nonstationary covariances.},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Pourahmadi/pourahmadi_1999_joint_mean-covariance_models_with_applications_to_longitudinal_data_-.pdf}
}

@article{pourahmadi2000b,
  title   = {Maximum Likelihood Estimation of Generalised Linear Models for Multivariate Normal Covariance Matrix},
  author  = {Pourahmadi, M},
  year    = {2000},
  month   = jun,
  journal = {Biometrika},
  volume  = {87},
  number  = {2},
  pages   = {425--435},
  issn    = {0006-3444, 1464-3510},
  doi     = {10.1093/biomet/87.2.425},
  langid  = {english},
  file    = {/home/james/Dropbox/zotero-library/AUTH/Pourahmadi/pourahmadi_2000_maximum_likelihood_estimation_of_generalised_linear_models_for_multivariate.pdf}
}

@article{steiger1982bjmsp,
  title      = {The Asymptotic Distribution of Elements of a Correlation Matrix: {{Theory}} and Application},
  shorttitle = {The Asymptotic Distribution of Elements of a Correlation Matrix},
  author     = {Steiger, James H. and Hakstian, A. Ralph},
  year       = {1982},
  journal    = {British Journal of Mathematical and Statistical Psychology},
  volume     = {35},
  number     = {2},
  pages      = {208--215},
  issn       = {2044-8317},
  doi        = {10.1111/j.2044-8317.1982.tb00653.x},
  abstract   = {The general asymptotic distribution of elements of a correlation matrix is derived. Applications of the result in robust correlational testing are discussed and illustrated with a numerical example.},
  langid     = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8317.1982.tb00653.x},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Steiger_Hakstian/steiger_hakstian_1982_the_asymptotic_distribution_of_elements_of_a_correlation_matrix_-_theory_and.pdf}
}

@article{touloumis2015cs&da,
  title    = {Nonparametric {{Stein-type}} Shrinkage Covariance Matrix Estimators in High-Dimensional Settings},
  author   = {Touloumis, Anestis},
  year     = {2015},
  month    = mar,
  journal  = {Computational Statistics \& Data Analysis},
  volume   = {83},
  pages    = {251--261},
  issn     = {0167-9473},
  doi      = {10.1016/j.csda.2014.10.018},
  abstract = {Estimating a covariance matrix is an important task in applications where the number of variables is larger than the number of observations. Shrinkage approaches for estimating a high-dimensional covariance matrix are often employed to circumvent the limitations of the sample covariance matrix. A new family of nonparametric Stein-type shrinkage covariance estimators is proposed whose members are written as a convex linear combination of the sample covariance matrix and of a predefined invertible target matrix. Under the Frobenius norm criterion, the optimal shrinkage intensity that defines the best convex linear combination depends on the unobserved covariance matrix and it must be estimated from the data. A simple but effective estimation process that produces nonparametric and consistent estimators of the optimal shrinkage intensity for three popular target matrices is introduced. In simulations, the proposed Stein-type shrinkage covariance matrix estimator based on a scaled identity matrix appeared to be up to 80\% more efficient than existing ones in extreme high-dimensional settings. A colon cancer dataset was analyzed to demonstrate the utility of the proposed estimators. A rule of thumb for adhoc selection among the three commonly used target matrices is recommended.},
  langid   = {english},
  keywords = {Covariance matrix,High-dimensional settings,Nonparametric estimation,Shrinkage estimation},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Touloumis/touloumis_2015_nonparametric_stein-type_shrinkage_covariance_matrix_estimators_in.pdf;/home/james/zotero-system/storage/WFNBHBCB/Touloumis - 2015 - Nonparametric Stein-type shrinkage covariance matr.pdf}
}

@phdthesis{wu2010,
  title  = {An {{Empirical Bayesian Approach}} to {{Misspecified Covariance Structures}}},
  author = {Wu, Hao},
  year   = {2010},
  langid = {english},
  school = {The Ohio State University},
  file   = {/home/james/Dropbox/zotero-library/AUTH/Wu/wu_2010_an_empirical_bayesian_approach_to_misspecified_covariance_structures.pdf}
}

@article{wu2015p,
  title    = {Quantifying Adventitious Error in a Covariance Structure as a Random Effect},
  author   = {Wu, Hao and Browne, Michael W.},
  year     = {2015},
  month    = sep,
  journal  = {Psychometrika},
  volume   = {80},
  number   = {3},
  pages    = {571--600},
  issn     = {1860-0980},
  doi      = {10.1007/s11336-015-9451-3},
  abstract = {We present an approach to quantifying errors in covariance structures in which adventitious error, identified as the process underlying the discrepancy between the population and the structured model, is explicitly modeled as a random effect with a distribution, and the dispersion parameter of this distribution to be estimated gives a measure of misspecification. Analytical properties of the resultant procedure are investigated and the measure of misspecification is found to be related to the root mean square error of approximation. An algorithm is developed for numerical implementation of the procedure. The consistency and asymptotic sampling distributions of the estimators are established under a new asymptotic paradigm and an assumption weaker than the standard Pitman drift assumption. Simulations validate the asymptotic sampling distributions and demonstrate the importance of accounting for the variations in the parameter estimates due to adventitious error. Two examples are also given as illustrations.},
  langid   = {english},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Wu_Browne/wu_browne_2015_quantifying_adventitious_error_in_a_covariance_structure_as_a_random_effect.pdf}
}

@book{Hedges1985,
  title     = {Statistical Methods for Meta-Analysis},
  author    = {Hedges, Larry V and Olkin, Ingram},
  year      = {1985},
  publisher = {{Academic Press}},
  address   = {{San Diego, CA}}
}



@article{cheung2018jap,
  title      = {Issues in Solving the Problem of Effect Size Heterogeneity in Meta-Analytic Structural Equation Modeling: {{A}} Commentary and Simulation Study on {{Yu}}, {{Downes}}, {{Carter}}, and {{O}}'{{Boyle}} (2016)},
  shorttitle = {Issues in Solving the Problem of Effect Size Heterogeneity in Meta-Analytic Structural Equation Modeling},
  author     = {Cheung, Mike W.-L.},
  year       = {2018},
  month      = jul,
  journal    = {The Journal of Applied Psychology},
  volume     = {103},
  number     = {7},
  pages      = {787--803},
  issn       = {1939-1854},
  doi        = {10.1037/apl0000284},
  abstract   = {Meta-analytic structural equation modeling (MASEM) is becoming increasingly popular for testing theoretical models from a pool of correlation matrices in management and organizational studies. One limitation of the conventional MASEM approaches is that the proposed structural equation models are only tested on the average correlation matrix. It remains unclear how far the proposed models can be generalized to other populations when the correlation matrices are heterogeneous. Recently, Yu, Downes, Carter, and O'Boyle (2016) proposed a full-information MASEM approach to address this limitation by fitting structural equation models from the correlation matrices generated from a parametric bootstrap. However, their approach suffers from several conceptual issues and technical errors. In this study, we reran some of the simulations in Yu et al. by correcting all of the errors in their original studies. The findings showed that bootstrap credible intervals (CVs) work reasonably well, whereas test statistics and goodness-of-fit indices do not. We advise researchers on what they can and cannot achieve by applying the full-information MASEM approach. We recommend fitting MASEM with the two-stage structural equation modeling approach, which works well for the simulation studies. If researchers want to inspect the heterogeneity of the parameters, they may use the bootstrap CVs from the full-information MASEM approach. All of these analyses were implemented in the open-source R statistical platform; researchers can easily apply and verify the findings. This article concludes with several future directions to address the issue of heterogeneity in MASEM. (PsycINFO Database Record},
  langid     = {english},
  pmid       = {29985024},
  keywords   = {Humans,Latent Class Analysis,Models; Statistical,Models; Theoretical},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Cheung/cheung_2018_issues_in_solving_the_problem_of_effect_size_heterogeneity_in_meta-analytic.pdf}
}

@article{yu2016joap,
  title   = {The Problem of Effect Size Heterogeneity in Meta-Analytic Structural Equation Modeling.},
  author  = {Yu, Jia (Joya) and Downes, Patrick E. and Carter, Kameron M. and O'Boyle, Ernest H.},
  year    = {2016},
  month   = oct,
  journal = {Journal of Applied Psychology},
  volume  = {101},
  number  = {10},
  pages   = {1457--1473},
  issn    = {1939-1854, 0021-9010},
  doi     = {10.1037/apl0000141},
  langid  = {english},
  file    = {/home/james/Dropbox/zotero-library/AUTH/Yu et al/yu_et_al_2016_the_problem_of_effect_size_heterogeneity_in_meta-analytic_structural_equation.pdf}
}

@article{yu2018jap,
  title      = {The Heterogeneity Problem in Meta-Analytic Structural Equation Modeling ({{MASEM}}) Revisited: {{A}} Reply to {{Cheung}}},
  shorttitle = {The Heterogeneity Problem in Meta-Analytic Structural Equation Modeling ({{MASEM}}) Revisited},
  author     = {Yu, Jia Joya and Downes, Patrick E. and Carter, Kameron M. and O'Boyle, Ernest},
  year       = {2018},
  month      = jul,
  journal    = {The Journal of Applied Psychology},
  volume     = {103},
  number     = {7},
  pages      = {804--811},
  issn       = {1939-1854},
  doi        = {10.1037/apl0000328},
  abstract   = {Yu, Downes, Carter, and O'Boyle (2016) introduce a new technique to incorporate effect size heterogeneity into meta-analytic structural equation modeling (MASEM) labeled full information meta-analytical structural equation modeling (FIMASEM). Cheung's (2018) commentary raises concerns about the viability of FIMASEM and provides its initial validation. In this reply, we briefly respond to those concerns noting how they relate to Yu et al.'s original conclusions, general MASEM practices, and operational decisions within the FIMASEM procedure. We synthesize Cheung's criticisms and build on his findings to lay out a research agenda for the future of MASEM and the role that our technique might play in it. In doing so, we clarify the conceptual nature of FIMASEM, identity inferential mistakes that current MASEM studies are likely to make, and offer specific and actionable recommendations in terms of the types of research questions FIMASEM is best suited to address and how FIMASEM results can best be interpreted and reported. (PsycINFO Database Record},
  langid     = {english},
  pmid       = {29985025},
  keywords   = {Humans,Latent Class Analysis,Models; Statistical}
}



@article{viswesvaran1995pp,
  title      = {Theory Testing: {{Combining}} Psychometric Meta-Analysis and Structural Equations Modeling},
  shorttitle = {Theory {{Testing}}},
  author     = {Viswesvaran, Chockalingam and Ones, Deniz S.},
  year       = {1995},
  journal    = {Personnel Psychology},
  volume     = {48},
  number     = {4},
  pages      = {865--885},
  issn       = {1744-6570},
  doi        = {10.1111/j.1744-6570.1995.tb01784.x},
  abstract   = {This paper presents an overview of a useful approach for theory testing in the social sciences that combines the principles of psychometric meta-analysis and structural equations modeling. In this approach to theory testing, the estimated true score correlations between the constructs of interest are established through the application of meta-analysis (Hunter \& Schmidt, 1990), and structural equations modeling is then applied to the matrix of estimated true score correlations. The potential advantages and limitations of this approach are presented. The approach enables researchers to test complex theories involving several constructs that cannot all be measured in a single study. Decision points are identified, the options available to a researcher are enumerated, and the potential problems as well as the prospects of each are discussed.},
  langid     = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1744-6570.1995.tb01784.x},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Viswesvaran_Ones/viswesvaran_ones_1995_theory_testing_-_combining_psychometric_meta-analysis_and_structural_equations.pdf}
}



@article{cheung2009semmj,
  title      = {A Two-Stage Approach to Synthesizing Covariance Matrices in Meta-Analytic Structural Equation Modeling},
  author     = {Cheung, Mike W.-L. and Chan, Wai},
  year       = {2009},
  month      = jan,
  journal    = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume     = {16},
  number     = {1},
  pages      = {28--53},
  publisher  = {{Routledge}},
  issn       = {1070-5511},
  doi        = {10.1080/10705510802561295},
  abstract   = {Structural equation modeling (SEM) is widely used as a statistical framework to test complex models in behavioral and social sciences. When the number of publications increases, there is a need to systematically synthesize them. Methodology of synthesizing findings in the context of SEM is known as meta-analytic SEM (MASEM). Although correlation matrices are usually preferred in MASEM, there are cases in which synthesizing covariance matrices is useful, especially when the scales of the measurement are comparable. This study extends the 2-stage SEM (TSSEM) approach proposed by M. W. L. Cheung and Chan (2005b) to synthesizing covariance matrices in MASEM. A simulation study was conducted to compare the TSSEM approach with several approximate methods. An empirical example is used to illustrate the procedures and future directions for MASEM are discussed.},
  annotation = {\_eprint: https://doi.org/10.1080/10705510802561295}
}



@article{oort2016rsm,
  title      = {Maximum Likelihood Estimation in Meta-Analytic Structural Equation Modeling},
  author     = {Oort, Frans J. and Jak, Suzanne},
  year       = {2016},
  journal    = {Research Synthesis Methods},
  volume     = {7},
  number     = {2},
  pages      = {156--167},
  issn       = {1759-2887},
  doi        = {10.1002/jrsm.1203},
  abstract   = {Meta-analytic structural equation modeling (MASEM) involves fitting models to a common population correlation matrix that is estimated on the basis of correlation coefficients that are reported by a number of independent studies. MASEM typically consist of two stages. The method that has been found to perform best in terms of statistical properties is the two-stage structural equation modeling, in which maximum likelihood analysis is used to estimate the common correlation matrix in the first stage, and weighted least squares analysis is used to fit structural equation models to the common correlation matrix in the second stage. In the present paper, we propose an alternative method, ML MASEM, that uses ML estimation throughout. In a simulation study, we use both methods and compare chi-square distributions, bias in parameter estimates, false positive rates, and true positive rates. Both methods appear to yield unbiased parameter estimates and false and true positive rates that are close to the expected values. ML MASEM parameter estimates are found to be significantly less bias than two-stage structural equation modeling estimates, but the differences are very small. The choice between the two methods may therefore be based on other fundamental or practical arguments. Copyright \textcopyright{} 2016 John Wiley \& Sons, Ltd.},
  langid     = {english},
  keywords   = {maximum likelihood,meta-analysis,simulation study,structural equation modeling,weighted least squares},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1203},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Oort_Jak/oort_jak_2016_maximum_likelihood_estimation_in_meta-analytic_structural_equation_modeling.pdf}
}

@article{yuan2018joeabs,
  title      = {Meta-Analytical {{SEM}}: Equivalence Between Maximum Likelihood and Generalized Least Squares},
  shorttitle = {Meta-Analytical {{SEM}}},
  author     = {Yuan, Ke-Hai and Kano, Yutaka},
  year       = {2018},
  month      = dec,
  journal    = {Journal of Educational and Behavioral Statistics},
  volume     = {43},
  number     = {6},
  pages      = {693--720},
  issn       = {1076-9986, 1935-1054},
  doi        = {10.3102/1076998618787799},
  abstract   = {Meta-analysis plays a key role in combining studies to obtain more reliable results. In social, behavioral, and health sciences, measurement units are typically not well defined. More meaningful results can be obtained by standardizing the variables and via the analysis of the correlation matrix. Structural equation modeling (SEM) with the combined correlations, called meta-analytical SEM (MASEM), is a powerful tool for examining the relationship among latent constructs as well as those between the latent constructs and the manifest variables. Three classes of methods have been proposed for MASEM: (1) generalized least squares (GLS) in combining correlations and in estimating the structural model, (2) normal-distribution-based maximum likelihood (ML) in combining the correlations and then GLS in estimating the structural model (ML-GLS), and (3) ML in combining correlations and in estimating the structural model (ML). The current article shows that these three methods are equivalent. In particular, (a) the GLS method for combining correlation matrices in meta-analysis is asymptotically equivalent to ML, (b) the three methods (GLS, ML-GLS, ML) for MASEM with correlation matrices are asymptotically equivalent, (c) they also perform equally well empirically, and (d) the GLS method for SEM with the sample correlation matrix in a single study is asymptotically equivalent to ML, which has being discussed extensively in the SEM literature regarding whether the analysis of a correlation matrix yields consistent standard errors and asymptotically valid test statistics. The results and analysis suggest that a sample-size weighted GLS method is preferred for combining correlations and for MASEM.},
  langid     = {english},
  file       = {/home/james/zotero-system/storage/CHGILNK7/Yuan and Kano - 2018 - Meta-Analytical SEM Equivalence Between Maximum L.pdf}
}



@article{olkin1995pb,
  title     = {Correlations Redux},
  author    = {Olkin, Ingram and Finn, Jeremy D.},
  year      = {1995},
  month     = jul,
  journal   = {Psychological Bulletin},
  volume    = {118},
  number    = {1},
  pages     = {155--164},
  publisher = {{American Psychological Association}},
  issn      = {0033-2909},
  doi       = {10.1037/0033-2909.118.1.155},
  abstract  = {Correlational analysis is a cornerstone method of statistical analysis, yet most presentations of correlational techniques deal primarily with tests of significance. The focus of this article is obtaining explicit expressions for confidence intervals for functions of simple, partial, and multiple correlations. Not only do these permit tests of hypotheses about differences but they also allow a clear statement about the degree to which correlations differ. Several important differences of correlations for which tests and confidence intervals are not widely known are included among the procedures discussed. Among these is the comparison of 2 multiple correlations based on independent samples. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords  = {explicit expressions for confidence intervals for functions of simple \& partial \& multiple correlations,Statistical Correlation},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Olkin_Finn/olkin_finn_1995_correlations_redux.pdf;/home/james/zotero-system/storage/MMKLFYSU/Olkin and Finn - 1995 - Correlations redux.pdf}
}



@article{Meredith1993,
  title    = {Measurement Invariance, Factor Analysis and Factorial Invariance},
  author   = {Meredith, William},
  year     = {1993},
  journal  = {Psychometrika},
  volume   = {58},
  number   = {4},
  pages    = {525--543},
  issn     = {0033-3123},
  doi      = {10.1007/BF02294825},
  abstract = {Several concepts are introduced and defined: measurement invariance, structural bias, weak measurement invariance, strong factorial invariance, and strict factorial invariance. It is shown that factorial invariance has implications for (weak) measurement invariance. Definitions of fairness in employment/admissions testing and salary equity are provided and it is argued that strict factorial invariance is required for fairness/equity to exist. Implications for item and test bias are developed and it is argued that item or test bias probably depends on the existence of latent variables that are irrelevant to the primary goal of test constructers.},
  keywords = {equity,factor analysis,factorial invariance,fairness,group differences,item bias,measurement invariance,selection,test bias},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Meredith/meredith_1993_measurement_invariance,_factor_analysis_and_factorial_invariance.pdf}
}


@techreport{roux1984prior,
  title       = {On prior inverted {{Wishart}} distribution.},
  author      = {Roux, J J J and Becker, P J},
  year        = {1984},
  institution = {Department of Statistics and Operations Research, University of South Africa},
  address     = {Pretoria, South Africa}
}


@article{browne1974sasj,
  title     = {Generalized Least Squares Estimators in the Analysis of Covariance Structures},
  author    = {Browne, M. W.},
  year      = {1974},
  month     = jan,
  journal   = {South African Statistical Journal},
  volume    = {8},
  number    = {1},
  pages     = {1--24},
  publisher = {{South African Statistical Association (SASA)}},
  doi       = {10.10520/AJA0038271X_175},
  abstract  = {Let S represent the usual unbiased estimator of a covariance matrix. ?o, whose elements are functions of a parameter vector ?o:?o = ?(?o). A generalized least squares (G.L.S.) estimate, ?. of ?o may be obtained by minimizing tr[ \{S - ?(?) \}V]2 where V is some positive definite matrix.},
  keywords  = {Covariance structures,Least squares estimators},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Browne/browne_1974_generalized_least_squares_estimators_in_the_analysis_of_covariance_structures.pdf}
}



@book{muthen8,
  title     = {Mplus User's Guide},
  author    = {Muth{\'e}n, Linda K and Muth{\'e}n, Bengt O},
  edition   = {Eighth},
  year      = {1998--2017},
  pages     = {950},
  publisher = {{Muth\'en \& Muth\'en}},
  address   = {{Los Angeles, CA}},
  file      = {/home/james/Dropbox/zotero-library/AUTH/MuthÃ©n_MuthÃ©n/muthen_muthen_mplus_user's_guide.pdf}
}



@article{Rosseel2012,
  title    = {lavaan: {{An R}} Package for Structural Equation Modeling},
  author   = {Rosseel, Yves},
  year     = {2012},
  journal  = {Journal of Statistical Software},
  volume   = {48},
  number   = {2},
  pages    = {1--20},
  doi      = {10.18637/jss.v048.i02},
  abstract = {Structural equation modeling (SEM) is a vast field and widely used by many applied researchers in the social and behavioral sciences. Over the years, many software pack-ages for structural equation modeling have been developed, both free and commercial. However, perhaps the best state-of-the-art software packages in this field are still closed-source and/or commercial. The R package lavaan has been developed to provide applied researchers, teachers, and statisticians, a free, fully open-source, but commercial-quality package for latent variable modeling. This paper explains the aims behind the develop-ment of the package, gives an overview of its most important features, and provides some examples to illustrate how lavaan works in practice.},
  keywords = {factor analysis,latent variables,path analysis,structural equation modeling},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Rosseel/rosseel_2012_lavaan_-_an_r_package_for_structural_equation_modeling.pdf}
}



@article{Lewandowski2009,
  title     = {Generating Random Correlation Matrices Based on Vines and Extended Onion Method},
  author    = {Lewandowski, Daniel and Kurowicka, Dorota and Joe, Harry},
  year      = {2009},
  month     = oct,
  journal   = {Journal of Multivariate Analysis},
  volume    = {100},
  number    = {9},
  pages     = {1989--2001},
  publisher = {{Academic Press}},
  issn      = {0047-259X},
  doi       = {10.1016/J.JMVA.2009.04.008},
  abstract  = {We extend and improve two existing methods of generating random correlation matrices, the onion method of Ghosh and Henderson [S. Ghosh, S.G. Henderson, Behavior of the norta method for correlated random vector generation as the dimension increases, ACM Transactions on Modeling and Computer Simulation (TOMACS) 13 (3) (2003) 276\textendash 294] and the recently proposed method of Joe [H. Joe, Generating random correlation matrices based on partial correlations, Journal of Multivariate Analysis 97 (2006) 2177\textendash 2189] based on partial correlations. The latter is based on the so-called D-vine. We extend the methodology to any regular vine and study the relationship between the multiple correlation and partial correlations on a regular vine. We explain the onion method in terms of elliptical distributions and extend it to allow generating random correlation matrices from the same joint distribution as the vine method. The methods are compared in terms of time necessary to generate 5000 random correlation matrices of given dimensions.}
}



@unpublished{muthen1997,
  title  = {Robust Inference Using Weighted Least Squares and Quadratic Estimating Equations in Latent Variable Modeling with Categorical and Continuous Outcomes},
  author = {Muth{\'e}n, Bengt O and {du Toit}, Stephen H. C. and Spisic, Damir},
  year   = {1997},
  month  = nov,
  url    = {https://www.statmodel.com/download/Article_075.pdf}
}



@article{Carpenter2017,
  title   = {Stan: {{A}} Probabilistic Programming Language},
  author  = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus A and Li, Peter and Riddell, Allen},
  year    = {2017},
  journal = {Journal of Statistical Software},
  volume  = {76},
  number  = {1},
  issn    = {1548-7660},
  doi     = {10.18637/jss.v076.i01},
  file    = {/home/james/Dropbox/zotero-library/AUTH/Carpenter et al/carpenter_et_al_2017_stan_-_a_probabilistic_programming_language.pdf}
}



@article{Maydeu-Olivares2017a,
  title    = {Assessing the Size of Model Misfit in Structural Equation Models},
  author   = {{Maydeu-Olivares}, Alberto},
  year     = {2017},
  journal  = {Psychometrika},
  volume   = {82},
  number   = {3},
  pages    = {533--558},
  issn     = {00333123},
  doi      = {10.1007/s11336-016-9552-7},
  abstract = {When a statistically significant mean difference is found, the magnitude of the difference is judged qualitatively using an effect size such as Cohen's d. In contrast, in a structural equation model (SEM), the result of the statistical test of model fit is often disregarded if significant, and inferences are drawn using " close " models retained based on point estimates of sample statistics (goodness-of-fit indices). However, when a SEM cannot be retained using a test of exact fit, all substantive inferences drawn from it are suspect. It is therefore important to determine the size of the model misfit. Standardized residual covariances and residual correlations provide standardized effect sizes of the misfit of SEM models. They can be summarized using the Standardized Root Mean Squared Residual (SRMSR) and the Correlation Root Mean Squared Residual (CRMSR) which can be used as overall effect sizes of the misfit. Statistical theory is provided that allows the construction of confidence intervals and tests of close fit based on the SRMSR and CRMSR. It is hoped that the use of standardized effect sizes of misfit will help reconcile current practices in SEM and elsewhere in statistics. Goodness-of-fit assessment refers to how well our model reproduces the data-generating process. When fitting a regression model, researchers assess the goodness-of-fit of their model by inspecting a plot of the standardized residuals versus standardized fitted values in order to check the linearity and homoscedasticity assumption of the model. Failure to meet the model assumptions will likely result in incorrect parameter estimates. Simply put, when the fitted model is incorrectly specified, all inferences based on it are suspect. In structural equation modeling (SEM), we fit a system of regression-like equations to our data (possibly involving latent variables), and procedures similar to those used in regression can be used to assess each of the equations in the model (Bollen \& Arminger, 1991; Coffman \& Millsap, 2006; Hildreth, 2013; Yuan \& Hayashi, 2010). However, they hardly seem to be used in applications. Rather, for historical reasons, the assessment of model fit in structural equation models has relied on the use of grouped data (residual means, covariances, and correlations) as opposed to individual residual observations. There is evidence that residual covariances (i.e., the differences between observed and fitted covariances) are sensitive to linear mis-specifications (Raykov, 2000) but I am not aware of any research that has examined whether they are sensitive to the presence of heteroscedasticity. Residual summary statistics such as residual covariances can be summarized into a single test statistic to assess the overall goodness-of-fit of a struc-tural equations model. Although overall test statistics are invariably reported in applications, they are most often ignored as they usually suggest that the model is incorrectly specified. Rather, Presidential Address to the Psychometric Society, delivered at the annual meeting in Madison (WI), July 2014. Rosseel for their helpful comments. I am also most thankful to Yves Rosseel for implementing these methods in the Lavaan package in R.},
  keywords = {effect size,goodness-of-fit,RMSEA},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Maydeu-Olivares/maydeu-olivares_2017_assessing_the_size_of_model_misfit_in_structural_equation_models.pdf}
}



@article{Saris2009,
  title    = {Testing Structural Equation Models or Detection of Misspecifications?},
  author   = {Saris, Willem E and Satorra, Albert and {van der Veld}, William M.},
  year     = {2009},
  journal  = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume   = {16},
  number   = {4},
  pages    = {561--582},
  issn     = {1070-5511},
  doi      = {10.1080/10705510903203433},
  abstract = {Assessing the correctness of a structural equation model is essential to avoid drawing incorrect conclusions from empirical research. In the past, the chi-square test was recommended for assessing the correctness of the model but this test has been criticized because of its sensitivity to sample size. As a reaction, an abundance of fit indexes have been developed. The result of these developments is that structural equation modeling packages are now producing a large list of fit measures. One would think that this progression has led to a clear understanding of evaluating models with respect to model misspecifications. In this article we question the validity of approaches for model evaluation based on overall goodness-of-fit indexes. The argument against such usage is that they do not provide an adequate indication of the ``size'' of the model's misspecification. That is, they vary dramatically with the values of incidental parameters that are unrelated with the misspecification in the model. This is illustrated using simple but fundamental models. As an alternative method of model evaluation, we suggest using the expected parameter change in combination with the modification index (MI) and the power of the MI test. (PsycINFO Database Record (c) 2010 APA, all rights reserved) (journal abstract)},
  isbn     = {1070551090},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Saris et al/saris_et_al_2009_testing_structural_equation_models_or_detection_of_misspecifications.pdf}
}



@article{merkle2021jss,
  title     = {Efficient {{Bayesian}} Structural Equation Modeling in {{Stan}}},
  author    = {Merkle, Edgar C. and Fitzsimmons, Ellen and Uanhoro, James Ohisei and Goodrich, Ben},
  year      = {2021},
  month     = nov,
  journal   = {Journal of Statistical Software},
  volume    = {100},
  number    = {6},
  pages     = {1--22},
  issn      = {1548-7660},
  doi       = {10.18637/jss.v100.i06},
  abstract  = {Structural equation models comprise a large class of popular statistical models, including factor analysis models, certain mixed models, and extensions thereof. Model estimation is complicated by the fact that we typically have multiple interdependent response variables and multiple latent variables (which may also be called random effects or hidden variables), often leading to slow and inefficient posterior sampling. In this paper, we describe and illustrate a general, efficient approach to Bayesian SEM estimation in Stan, contrasting it with previous implementations in R package blavaan (Merkle and Rosseel 2018). After describing the approaches in detail, we conduct a practical comparison under multiple scenarios. The comparisons show that the new approach is clearly better. We also discuss ways that the approach may be extended to other models that are of interest to psychometricians.},
  copyright = {Copyright (c) 2021 Edgar C. Merkle, Ellen Fitzsimmons, James Uanhoro, Ben Goodrich},
  langid    = {english},
  keywords  = {blavaan},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Merkle et al/merkle_et_al_2021_efficient_bayesian_structural_equation_modeling_in_stan.pdf}
}



@misc{Talts2018,
  title         = {Validating {{Bayesian}} Inference Algorithms with Simulation-Based Calibration},
  author        = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
  year          = {2018},
  month         = apr,
  journal       = {arXiv},
  eprint        = {1804.06788},
  eprinttype    = {arxiv},
  publisher     = {{arXiv}},
  abstract      = {Verifying the correctness of Bayesian computation is challenging. This is especially true for complex models that are common in practice, as these require sophisticated model implementations and algorithms. In this paper we introduce \emph{simulation-based calibration} (SBC), a general procedure for validating inferences from Bayesian algorithms capable of generating posterior samples. This procedure not only identifies inaccurate computation and inconsistencies in model implementations but also provides graphical summaries that can indicate the nature of the problems that arise. We argue that SBC is a critical part of a robust Bayesian workflow, as well as being a useful tool for those developing computational algorithms and statistical software.},
  archiveprefix = {arXiv},
  arxivid       = {1804.06788},
  note          = {arXiv: 1804.06788},
  file          = {/home/james/Dropbox/zotero-library/AUTH/Talts et al/talts_et_al_2018_validating_bayesian_inference_algorithms_with_simulation-based_calibration.pdf}
}



@article{cooke2016hpr,
  title      = {How Well Does the Theory of Planned Behaviour Predict Alcohol Consumption? {{A}} Systematic Review and Meta-Analysis},
  shorttitle = {How Well Does the Theory of Planned Behaviour Predict Alcohol Consumption?},
  author     = {Cooke, Richard and Dahdah, Mary and Norman, Paul and French, David P.},
  year       = {2016},
  month      = apr,
  journal    = {Health Psychology Review},
  volume     = {10},
  number     = {2},
  pages      = {148--167},
  issn       = {1743-7199, 1743-7202},
  doi        = {10.1080/17437199.2014.947547},
  langid     = {english},
  file       = {/home/james/zotero-system/storage/WEZTR27Y/Cooke et al. - 2016 - How well does the theory of planned behaviour pred.pdf}
}

@article{digman1997jopasp,
  title     = {Higher-Order Factors of the {{Big Five}}},
  author    = {Digman, John M.},
  year      = {1997},
  month     = dec,
  journal   = {Journal of Personality and Social Psychology},
  volume    = {73},
  number    = {6},
  pages     = {1246--1256},
  publisher = {{American Psychological Association}},
  issn      = {0022-3514},
  doi       = {10.1037/0022-3514.73.6.1246},
  abstract  = {Estimated factor correlations from 14 studies supporting the 5 factor, Big Five model of personality trait organization\textemdash 5 studies based on children and adolescents, 9 on adults\textemdash were factor analyzed. Two higher-order factors were clearly evident in all studies. One was principally related to the Big Five trait dimensions Agreeableness, Conscientiousness, and Emotional Stability; the other, the dimensions Extraversion and Intellect. Two models, one for children and adolescents, the other for adults, were tested by confirmatory factor analysis with generally excellent results. Many personality theorists appear to have considered one or both of these 2 metatraits, provisionally labeled {$\alpha$} and {$\beta$}. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords  = {Adolescent,Adult,Child,children \& adolescents \& adults,Factor Analysis,factor analysis of estimated factor correlations from studies supporting Big 5 model of personality,Factor Analysis; Statistical,Female,Five Factor Personality Model,Humans,Male,meta analysis,Meta Analysis,Models; Psychological,Personality Assessment,Psychometrics,Reproducibility of Results,Temperament},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Digman/digman_1997_higher-order_factors_of_the_big_five.pdf}
}



@article{vehtari2020ba,
  title     = {Rank-Normalization, Folding, and Localization: {{An}} Improved $\widehat{R}$ for Assessing Convergence of {{MCMC}}},
  author    = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year      = {2020},
  journal   = {Bayesian Analysis},
  pages     = {1--28},
  publisher = {{International Society for Bayesian Analysis}},
  doi       = {10.1214/20-BA1221},
  abstract  = {Markov chain Monte Carlo is a key computational tool in Bayesian statistics, but it can be challenging to monitor the convergence of an iterative stochastic algorithm. In this paper we show that the convergence diagnostic R of Gelman and Rubin (1992) has serious flaws. Traditional R will fail to correctly diagnose convergence failures when the chain has a heavy tail or when the variance varies across the chains. In this paper we propose an alternative rank-based diagnostic that fixes these problems. We also introduce a collection of quantile-based local efficiency measures, along with a practical approach for computing Monte Carlo error estimates for quantiles. We suggest that common trace plots should be replaced with rank plots from multiple chains. Finally, we give recommendations for how these methods should be used in practice.},
  isbn      = {1936-0975},
  langid    = {english},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Vehtari et al/vehtari_et_al_2020_rank-normalization,_folding,_and_localization_-_an_improved_r_for_assessing.pdf}
}

@misc{Betancourt2017,
  title         = {A Conceptual Introduction to {{Hamiltonian Monte Carlo}}},
  author        = {Betancourt, Michael},
  year          = {2017},
  month         = jan,
  eprint        = {1701.02434},
  eprinttype    = {arxiv},
  pages         = {60},
  issn          = {00093920},
  abstract      = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
  archiveprefix = {arXiv},
  arxivid       = {1701.02434},
  isbn          = {9788578110796},
  note          = {arXiv: 1701.02434}
}


@article{craft2003jsaep,
  title      = {The Relationship between the Competitive State Anxiety Inventory-2 and Sport Performance: A Meta-Analysis.},
  shorttitle = {The Relationship between the Competitive State Anxiety Inventory-2 and Sport Performance},
  author     = {Craft, L. L. and Magyar, T. M. and Becker, Betsy Jane and Feltz, D. L.},
  year       = {2003},
  journal    = {Journal of Sport \& Exercise Psychology},
  volume     = {25},
  number     = {1},
  pages      = {44--65},
  publisher  = {{Human Kinetics Publishers}},
  issn       = {0895-2779},
  abstract   = {The multidimensional approach to the study of anxiety by R. Martens, R.S. Vealey, and D. Burton [Competitive anxiety in sport (1990)] considers subcomponents of anxiety, specifically cognitive anxiety, somatic anxiety, and self-confidence. Much of the research based on this theory has utilized the Competitive State Anxiety Inventory (CSAI-2) by R. Martens, D. Burton, R.S. Vealey, L.A. Bump, and...},
  langid     = {english},
  file       = {/home/james/Dropbox/zotero-library/AUTH/Craft et al/craft_et_al_2003_the_relationship_between_the_competitive_state_anxiety_inventory-2_and_sport.pdf}
}



@incollection{becker2019thorsam,
  title     = {Model-Based Meta-Analysis and Related Approaches},
  booktitle = {The Handbook of Research Synthesis and Meta-Analysis},
  author    = {Becker, Betsy Jane and Aloe, Ariel M.},
  editor    = {Cooper, Harris and Hedges, Larry V. and Valentine, Jeffrey C.},
  year      = {2019},
  edition   = {Third},
  pages     = {339--363},
  publisher = {{Russell Sage Foundation}},
  address   = {{New York}}
}



@article{huang2018spq,
  title     = {Multilevel Modeling Myths},
  author    = {Huang, Francis L.},
  year      = {2018},
  journal   = {School Psychology Quarterly},
  volume    = {33},
  number    = {3},
  pages     = {492--499},
  publisher = {{Educational Publishing Foundation}},
  address   = {{US}},
  issn      = {1939-1560},
  doi       = {10.1037/spq0000272},
  abstract  = {The use of multilevel modeling (MLM) to analyze nested data has grown in popularity over the years in the study of school psychology. However, with the increase in use, several statistical misconceptions about the technique have also proliferated. We discuss some commonly cited myths and golden rules related to the use of MLM, explain their origin, and suggest approaches to dealing with certain issues. Misunderstandings related to the use of the intraclass correlation, design effects, minimum sample size, multilevel factor structures, model R{$^2$}, and the misestimation of standard errors are reviewed. Many of the cited myths have much truth in them\textemdash though at times, researchers may not be aware of the exceptions to the rules that prevent their overall generalization. Although nesting should be accounted for, researchers should realize that MLM, which is a powerful and flexible technique, is not the only method that can be used to account for the clustering effect. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords  = {Errors,Experimental Design,Factor Structure,Sample Size,School Psychology,Simulation,Statistics}
}



@techreport{granstrom2011,
  type        = {{{LiTH-ISY-R-3042}}},
  title       = {Properties and Approximations of Some Matrix Variate Probability Density Functions},
  author      = {Granstr{\"o}m, Karl and Orguner, Umut},
  year        = {2011},
  address     = {{Link\"oping, Sweden}},
  institution = {{Division of Automatic Control, Link\"oping University}},
  abstract    = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
  langid      = {english},
  url         = {http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-88735},
  file        = {/home/james/Dropbox/zotero-library/AUTH/GranstrÃ¶m_Orguner/granstrom_orguner_2011_properties_and_approximations_of_some_matrix_variate_probability_density.pdf}
}



@article{Muthen2012,
  title         = {Bayesian Structural Equation Modeling: {{A}} More Flexible Representation of Substantive Theory},
  author        = {Muth{\'e}n, Bengt O and Asparouhov, Tihomir},
  year          = {2012},
  journal       = {Psychological Methods},
  volume        = {17},
  number        = {3},
  eprint        = {1511.05604},
  eprinttype    = {arxiv},
  pages         = {313--335},
  publisher     = {{US: American Psychological Association}},
  issn          = {1082989X},
  doi           = {10.1037/a0026802},
  abstract      = {This article proposes a new approach to factor analysis and structural equation modeling using Bayesian analysis. The new approach replaces parameter specifications of exact zeros with approximate zeros based on informative, small-variance priors. It is argued that this produces an analysis that better reflects substantive theories. The proposed Bayesian approach is particularly beneficial in applications where parameters tu-e added to a conventional model such that a nonidentified model is obtained if maximum-likelihood estimation is applied. This approach is useful for measurement aspects of latent variable modeling, such as with confirmatory factor analysis, and the measurement part of structural equation modeling. Two application areas are studied, cross-loadings and residual correlations in confirmatory factor analysis. An example using a full structural equation model is also presented, showing an efficient way to find model misspecification. The approach encompasses 3 elements: model testing using posterior predictive checking, model estimation, and model modification. Monte Carlo simulations and real data are analyzed using Mplus. The real-data analyses use data from Holzinger and Swineford's (1939) classic mental abilities study, Big Five personality factor data from a British survey, and science achievement data from the National Educational Longitudinal Study of 1988.},
  archiveprefix = {arXiv},
  arxivid       = {1511.05604},
  isbn          = {1082-989X},
  pmid          = {22962886},
  keywords      = {Confirmatory factor analysis,Informative priors,Markov chain Monte Carlo method,Posterior predictive checking},
  file          = {/home/james/Dropbox/zotero-library/AUTH/MuthÃ©n_Asparouhov/muthen_asparouhov_2012_bayesian_structural_equation_modeling_-_a_more_flexible_representation_of.pdf}
}



@article{Merkle2018,
  title    = {{{blavaan}}: {{Bayesian}} Structural Equation Models via Parameter Expansion},
  author   = {Merkle, Edgar C. and Rosseel, Yves},
  year     = {2018},
  month    = jun,
  journal  = {Journal of Statistical Software},
  volume   = {85},
  number   = {4},
  pages    = {1--30},
  doi      = {10.18637/jss.v085.i04},
  abstract = {This article describes blavaan, an R package for estimating Bayesian structural equation models (SEMs) via JAGS and for summarizing the results. It also describes a novel parameter expansion approach for estimating specific types of models with residual covariances, which facilitates estimation of these models in JAGS. The methodology and software are intended to provide users with a general means of estimating Bayesian SEMs, both classical and novel, in a straightforward fashion. Users can estimate Bayesian versions of classical SEMs with lavaan syntax, they can obtain state-of-the-art Bayesian fit measures associated with the models, and they can export JAGS code to modify the SEMs as desired. These features and more are illustrated by example, and the parameter expansion approach is explained in detail.},
  file     = {/home/james/Dropbox/zotero-library/AUTH/Merkle_Rosseel/merkle_rosseel_2018_blavaan_-_bayesian_structural_equation_models_via_parameter_expansion.pdf}
}



@article{boer2016ejwop,
  title      = {Revisiting the Mediating Role of Leader\textendash Member Exchange in Transformational Leadership: The Differential Impact Model},
  shorttitle = {Revisiting the Mediating Role of Leader\textendash Member Exchange in Transformational Leadership},
  author     = {Boer, Diana and Deinert, Anika and Homan, Astrid C. and Voelpel, Sven C.},
  year       = {2016},
  month      = nov,
  journal    = {European Journal of Work and Organizational Psychology},
  volume     = {25},
  number     = {6},
  pages      = {883--899},
  publisher  = {{Routledge}},
  issn       = {1359-432X},
  doi        = {10.1080/1359432X.2016.1170007},
  abstract   = {Transformational leadership (TFL) has been proposed as an essential antecedent of leader\textendash member exchange (LMX), which in turn affects outcomes in organizations. We extend this mediation hypothesis in two ways by proposing a differential impact model, which we test on three organizational outcomes: employee job satisfaction, employee organizational commitment, and leader effectiveness. First, we extend LMX's mediational impact\textemdash which has previously only been tested for employee outcomes\textemdash to leader effectiveness. Second, we argue that this mediation will be stronger for outcomes that are more proximal rather than distal to dyadic relations between leader and followers (high proximity: job satisfaction; medium proximity: organizational commitment; low proximity: leader effectiveness). Meta-analytic structural equation modelling based on 132 studies revealed that LMX mediates TFL's relationships with employee outcomes (more strongly for job satisfaction than for commitment), but not with leader effectiveness, whereas TFL showed a stronger direct link to leader effectiveness. The findings suggest that TLF and LMX contribute differentially to organizational outcomes depending on their proximity to dyadic relations between leaders and followers. The differential impact model uncovers leadership effectiveness processes, integrates influential leadership theories, and highlights the importance of distinguishing between different outcome measures and the processes facilitating them.},
  keywords   = {leader effectiveness,leader-member exchange,meta-analysis,transformational leadership},
  annotation = {\_eprint: https://doi.org/10.1080/1359432X.2016.1170007}
}



@article{sobel1982sm,
  title     = {Asymptotic Confidence Intervals for Indirect Effects in Structural Equation Models},
  author    = {Sobel, Michael E.},
  year      = {1982},
  journal   = {Sociological Methodology},
  volume    = {13},
  pages     = {290--312},
  publisher = {{[American Sociological Association, Wiley, Sage Publications, Inc.]}},
  issn      = {0081-1750},
  doi       = {10.2307/270723},
  file      = {/home/james/Dropbox/zotero-library/AUTH/Sobel/sobel_1982_asymptotic_confidence_intervals_for_indirect_effects_in_structural_equation.pdf}
}



@article{wilson_fitting_2016,
  title   = {Fitting Meta-Analytic Structural Equation Models with Complex Datasets},
  volume  = {7},
  issn    = {1759-2879},
  doi     = {10.1002/jrsm.1199},
  number  = {2},
  urldate = {2022-03-31},
  journal = {Research Synthesis Methods},
  author  = {Wilson, Sandra Jo and Polanin, Joshua R. and Lipsey, Mark W.},
  month   = jun,
  year    = {2016},
  pmid    = {27286899},
  pmcid   = {PMC4905597},
  pages   = {121--139},
  file    = {wilson_et_al_2016_fitting_meta-analytic_structural_equation_models_with_complex_datasets.pdf:/home/james/Dropbox/zotero-library/AUTH/Wilson et al/wilson_et_al_2016_fitting_meta-analytic_structural_equation_models_with_complex_datasets.pdf:application/pdf}
}

@article{hafdahl_combining_2007,
  title      = {Combining Correlation matrices: Simulation Analysis of Improved Fixed-Effects Methods},
  volume     = {32},
  issn       = {1076-9986},
  shorttitle = {Combining {Correlation} {Matrices}},
  url        = {https://doi.org/10.3102/1076998606298041},
  doi        = {10.3102/1076998606298041},
  abstract   = {The originally proposed multivariate meta-analysis approach for correlation matricesâ€”analyze Pearson correlations, with each studyâ€™s observed correlations replacing their population counterparts in its conditional-covariance matrixâ€”performs poorly. Two refinements are considered: Analyze Fisher Z-transformed correlations, and substitute better estimates of correlations in the conditional covariances. Fixed-effects methods with and without each refinement were examined in a Monte Carlo study; number of studies and the distribution of within-study sample sizes were varied. Both refinements improved element-wise point and interval estimates, as well as Type I error control for homogeneity tests, especially with many small studies. Practical recommendations and suggestions for future methodological work are offered. An appendix describes how to transform Fisher-Z (co)variances to the Pearson-r metric.},
  language   = {en},
  number     = {2},
  urldate    = {2022-04-03},
  journal    = {Journal of Educational and Behavioral Statistics},
  author     = {Hafdahl, Adam R.},
  month      = jun,
  year       = {2007},
  note       = {Publisher: American Educational Research Association},
  keywords   = {meta-analysis; correlation; generalized least squares; Monte Carlo study},
  pages      = {180--205},
  file       = {hafdahl_2007_combining_correlation_matrices_-_simulation_analysis_of_improved_fixed-effects.pdf:/home/james/Dropbox/zotero-library/AUTH/Hafdahl/hafdahl_2007_combining_correlation_matrices_-_simulation_analysis_of_improved_fixed-effects.pdf:application/pdf;SAGE PDF Full Text:/home/james/zotero-system/storage/SKJC3JPB/Hafdahl - 2007 - Combining Correlation Matrices Simulation Analysi.pdf:application/pdf}
}

@article{jak_meta-analytic_2020,
  title    = {Meta-analytic structural equation modeling with moderating effects on {SEM} parameters},
  volume   = {25},
  issn     = {1939-1463},
  doi      = {10.1037/met0000245},
  abstract = {Meta-analytic structural equation modeling (MASEM) is an increasingly popular meta-analytic technique that combines the strengths of meta-analysis and structural equation modeling. MASEM facilitates the evaluation of complete theoretical models (e.g., path models or factor analytic models), accounts for sampling covariance between effect sizes, and provides measures of overall fit of the hypothesized model on meta-analytic data. We propose a novel MASEM method, one-stage MASEM, which is better suitable to explain study-level heterogeneity than existing methods. One-stage MASEM allows researchers to incorporate continuous or categorical moderators into the MASEM, in which any parameter in the structural equation model (e.g., path coefficients and factor loadings) can be modeled by the moderator variable, while the method does not require complete data for the primary studies included in the meta-analysis. We illustrate the new method on two real data sets, evaluate its empirical performance via a computer simulation study, and provide user-friendly R-functions and annotated syntax to assist researchers in applying one-stage MASEM. We close the article by presenting several future research directions. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  number   = {4},
  journal  = {Psychological Methods},
  author   = {Jak, Suzanne and Cheung, Mike W. -L.},
  year     = {2020},
  keywords = {Structural Equation Modeling, Syntax, Computer Simulation, Factor Analysis, Meta Analysis, Path Analysis, Data Sets},
  pages    = {430--455},
  file     = {jak_cheung_2020_meta-analytic_structural_equation_modeling_with_moderating_effects_on_sem.pdf:/home/james/Dropbox/zotero-library/AUTH/Jak_Cheung/jak_cheung_2020_meta-analytic_structural_equation_modeling_with_moderating_effects_on_sem.pdf:application/pdf}
}


@article{norton_hospital_2013,
  title      = {The Hospital Anxiety and Depression Scale: {A} meta confirmatory factor analysis},
  volume     = {74},
  issn       = {0022-3999},
  shorttitle = {The {Hospital} {Anxiety} and {Depression} {Scale}},
  doi        = {10.1016/j.jpsychores.2012.10.010},
  abstract   = {Objective
                To systematically evaluate the latent structure of the Hospital Anxiety and Depression Scale (HADS) through reanalysis of previous studies and meta confirmatory factor analysis (CFA).
                Method
                Data from 28 samples were obtained from published studies concerning the latent structure of the HADS. Ten models were considered, including eight previously identified models and two bifactor models. The fit of each model was assessed separately in each sample and by meta CFA. Meta CFA was conducted using all samples and using subgroups consisting of community samples, cardiovascular disease samples and samples from studies administering the English language version of the HADS.
                Results
                A bifactor model including all items loading onto a general distress factor and two orthogonal anxiety and depression group factors provided the best fit for the majority of samples. Meta CFA provided further support for the bifactor model with two group factors. This was the case using all samples, as well as all subgroup analyses. The general distress factor explained 73\% of the covariance between items, with the (autonomic) anxiety and (anhedonic) depression factors explaining 11\% and 16\%, respectively.
                Conclusion
                A bifactor structure provides the most acceptable empirical explanation for the HADS correlation structure. Due to the presence of a strong general factor, the HADS does not provide good separation between symptoms of anxiety and depression. We recommend it is best used as a measure of general distress.},
  language   = {en},
  number     = {1},
  urldate    = {2022-04-23},
  journal    = {Journal of Psychosomatic Research},
  author     = {Norton, Sam and Cosco, Theodore and Doyle, Frank and Done, John and Sacker, Amanda},
  month      = jan,
  year       = {2013},
  keywords   = {Factor analysis, Meta-analysis, Anxiety, Depression, Hospital Anxiety and Depression Scale},
  pages      = {74--81},
  file       = {norton_et_al_2013_the_hospital_anxiety_and_depression_scale_-_a_meta_confirmatory_factor_analysis.pdf:/home/james/Dropbox/zotero-library/AUTH/Norton et al/norton_et_al_2013_the_hospital_anxiety_and_depression_scale_-_a_meta_confirmatory_factor_analysis.pdf:application/pdf;Submitted Version:/home/james/zotero-system/storage/CIUGLYMN/Norton et al. - 2013 - The Hospital Anxiety and Depression Scale A meta .pdf:application/pdf;norton_et_al_2013_the_hospital_anxiety_and_depression_scale_-_a_meta_confirmatory_factor_analysis2.pdf:/home/james/Dropbox/zotero-library/AUTH/Norton et al/norton_et_al_2013_the_hospital_anxiety_and_depression_scale_-_a_meta_confirmatory_factor_analysis2.pdf:application/pdf}
}

@article{zigmond1983hospital,
  title     = {The hospital anxiety and depression scale},
  author    = {Zigmond, Anthony S and Snaith, R Philip},
  journal   = {Acta Psychiatrica Scandinavica},
  volume    = {67},
  number    = {6},
  pages     = {361--370},
  year      = {1983},
  publisher = {Wiley Online Library}
}

@incollection{widaman_creating_2011,
  address   = {Washington, DC, US},
  title     = {On creating and using short forms of scales in secondary research},
  isbn      = {978-1-4338-0876-0 978-1-4338-0877-7},
  abstract  = {In this chapter, we provide an overview of issues related to reliability and validity, and provide explicit recommendations for creating and using short forms in behavioral science research, particularly as they apply to existing data sets. In this regard, we focus primarily on the typical secondary data setâ€”an existing data set collected by other researchers to pursue their goals, yet a data set that can be mined to answer current theoretical questions. In most secondary data sets, many constructs are assessed using self-report questionnaire formats, although these data sets often include constructs assessed using other measurement methods, such as observer ratings, informant reports, and objective tests. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  booktitle = {Secondary data analysis: {An} introduction for psychologists},
  publisher = {American Psychological Association},
  author    = {Widaman, Keith F. and Little, Todd D. and Preacher, Kristopher J. and Sawalani, Gita M.},
  year      = {2011},
  doi       = {10.1037/12350-003},
  keywords  = {Data Collection, Statistical Analysis, Statistical Data, Statistical Reliability, Statistical Validity},
  pages     = {39--61},
  file      = {widaman_et_al_2011_on_creating_and_using_short_forms_of_scales_in_secondary_research.pdf:/home/james/Dropbox/zotero-library/AUTH/Widaman et al/widaman_et_al_2011_on_creating_and_using_short_forms_of_scales_in_secondary_research.pdf:application/pdf}
}

@book{noauthor_international_1992,
  title      = {International {Social} {Science} {Program}: {Work} orientations, 1989},
  shorttitle = {International {Social} {Science} {Program}},
  abstract   = {This collection contains data from Austria, Great Britain (Northern Ireland), Hungary, Ireland, Italy, Israel, Netherlands, Norway, United States, and West Germany. Respondents were asked about their general attitudes to work and leisure, work organization, work content, collective interests, and second jobs},
  language   = {en},
  publisher  = {Inter-university Consortium for Political and Social Research},
  year       = {1992}
}

@article{Davis-Stober2018,
  title    = {Estimation accuracy in the psychological sciences},
  volume   = {13},
  issn     = {1932-6203},
  url      = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0207239},
  doi      = {10.1371/JOURNAL.PONE.0207239},
  abstract = {Sample means comparisons are a fundamental and ubiquitous approach to interpreting experimental psychological data. Yet, we argue that the sample and effect sizes in published psychological research are frequently so small that sample means are insufficiently accurate to determine whether treatment effects have occurred. Generally, an estimator should be more accurate than any benchmark that systematically ignores information about the relations among experimental conditions. We consider two such benchmark estimators: one that randomizes the relations among conditions and another that always assumes no treatment effects. We show conditions under which these benchmark estimators estimate the true parameters more accurately than sample means. This perverse situation can occur even when effects are statistically significant at traditional levels. Our argument motivates the need for regularized estimates, such as those used in lasso, ridge, and hierarchical Bayes techniques.},
  number   = {11},
  journal  = {PLOS ONE},
  author   = {Davis-Stober, Clintin P. and Dana, Jason and Rouder, Jeffrey N.},
  month    = nov,
  year     = {2018},
  keywords = {Behavior, African American people, Clinical psychology, Cognitive psychology, Experimental psychology, Measurement, Normal distribution, Psychologists},
  pages    = {e0207239},
  file     = {davis-stober_et_al_2018_estimation_accuracy_in_the_psychological_sciences.pdf:/home/james/Dropbox/zotero-library/AUTH/Davis-Stober et al/davis-stober_et_al_2018_estimation_accuracy_in_the_psychological_sciences.pdf:application/pdf}
}


@article{Peeters2012,
  title    = {Rotational uniqueness conditions under oblique factor correlation metric},
  volume   = {77},
  issn     = {1860-0980},
  url      = {https://doi.org/10.1007/s11336-012-9259-3},
  doi      = {10.1007/s11336-012-9259-3},
  abstract = {In an addendum to his seminal 1969 article JÃ¶reskog stated two sets of conditions for rotational identification of the oblique factor solution under utilization of fixed zero elements in the factor loadings matrix (JÃ¶reskog in Advances in factor analysis and structural equation models, pp. 40â€“43, 1979). These condition sets, formulated under factor correlation and factor covariance metrics, respectively, were claimed to be equivalent and to lead to global rotational uniqueness of the factor solution. It is shown here that the conditions for the oblique factor correlation structure need to be amended for global rotational uniqueness, and, hence, that the condition sets are not equivalent in terms of unicity of the solution.},
  number   = {2},
  journal  = {Psychometrika},
  author   = {Peeters, Carel F W},
  year     = {2012},
  pages    = {288--292}
}

@book{Song2012,
  series    = {Wiley series in probability and statistics},
  title     = {{Basic and advanced Bayesian structural equation modeling}},
  isbn      = {978-0-470-66952-5},
  publisher = {Wiley},
  author    = {Song, Xin Yuan and Lee, Sik Yum},
  month     = aug,
  year      = {2012},
  doi       = {10.1002/9781118358887},
  note      = {Pages: 396}
}

@book{Levy2016,
  address   = {Boca Raton, FL},
  title     = {Bayesian psychometric modeling},
  isbn      = {978-1-4398-8467-6},
  publisher = {Chapman and Hall/CRC},
  author    = {Levy, Roy and Mislevy, Robert J.},
  year      = {2016},
  note      = {Pages: 466}
}

@article{Cain2019,
  title    = {Fit for a {Bayesian}: {An} evaluation of {PPP} and {DIC} for structural equation modeling},
  volume   = {26},
  issn     = {15328007},
  doi      = {10.1080/10705511.2018.1490648},
  abstract = {Despite its importance to structural equation modeling, model evaluation remains underdeveloped in the Bayesian SEM framework. Posterior predictive p-values (PPP) and deviance information criteria (DIC) are now available in popular software for Bayesian model evaluation, but they remain underutilized. This is largely due to the lack of recommendations for their use. To address this problem, PPP and DIC were evaluated in a series of Monte Carlo simulation studies. The results show that both PPP and DIC are influenced by severity of model misspecification, sample size, model size, and choice of prior. The cutoffs PPP Â¡ 0.10 and âˆ†DIC Â¿ 7 work best in the conditions and models tested here to maintain low false detection rates and misspecified model selection rates, respectively. The recommendations provided in this study will help researchers evaluate their models in a Bayesian SEM analysis and set the stage for future development and evaluation of Bayesian SEM fit indices.},
  number   = {1},
  journal  = {Structural Equation Modeling},
  author   = {Cain, Meghan K. and Zhang, Zhiyong},
  year     = {2019},
  pages    = {39--50},
  file     = {cain_zhang_2019_fit_for_a_bayesian_-_an_evaluation_of_ppp_and_dic_for_structural_equation.pdf:/home/james/Dropbox/zotero-library/AUTH/Cain_Zhang/cain_zhang_2019_fit_for_a_bayesian_-_an_evaluation_of_ppp_and_dic_for_structural_equation.pdf:application/pdf}
}

@article{hoofs_evaluating_2018,
  title      = {Evaluating Model Fit in {Bayesian} Confirmatory Factor Analysis With Large Samples: Simulation Study Introducing the {BRMSEA}},
  volume     = {78},
  issn       = {0013-1644, 1552-3888},
  doi        = {10.1177/0013164417709314},
  abstract   = {Bayesian confirmatory factor analysis (CFA) offers an alternative to frequentist CFA based on, for example, maximum likelihood estimation for the assessment of reliability and validity of educational and psychological measures. For increasing sample sizes, however, the applicability of current fit statistics evaluating model fit within Bayesian CFA is limited. We propose, therefore, a Bayesian variant of the root mean square error of approximation (RMSEA), the BRMSEA. A simulation study was performed with variations in model misspecification, factor loading magnitude, number of indicators, number of factors, and sample size. This showed that the 90\% posterior probability interval of the BRMSEA is valid for evaluating model fit in large samples (N ! 1,000), using cutoff values for the lower ({\textbackslash}.05) and upper limit ({\textbackslash}.08) as guideline. An empirical illustration further shows the advantage of the BRMSEA in large sample Bayesian CFA models. In conclusion, it can be stated that the BRMSEA is well suited to evaluate model fit in large sample Bayesian CFA models by taking sample size and model complexity into account.},
  language   = {en},
  number     = {4},
  urldate    = {2022-04-17},
  journal    = {Educational and Psychological Measurement},
  author     = {Hoofs, Huub and van de Schoot, Rens and Jansen, Nicole W. H. and Kant, IJmert},
  month      = aug,
  year       = {2018},
  pages      = {537--568},
  file       = {Hoofs et al. - 2018 - Evaluating Model Fit in Bayesian Confirmatory Fact.pdf:/home/james/zotero-system/storage/R8H8VUAR/Hoofs et al. - 2018 - Evaluating Model Fit in Bayesian Confirmatory Fact.pdf:application/pdf;Evaluating Model Fit in Bayesian Confirmatory Factor Analysis With Large Samples\: Simulation Study Introducing the BRMSEA:/home/james/zotero-system/storage/ZRSIZPKS/hoofs2017.pdf.pdf:application/pdf}
}

@article{garnier-villarreal_adapting_2020,
  title      = {Adapting fit indices for {Bayesian} structural equation modeling: {Comparison} to maximum likelihood},
  volume     = {25},
  issn       = {1939-1463},
  shorttitle = {Adapting fit indices for {Bayesian} structural equation modeling},
  doi        = {10.1037/met0000224},
  abstract   = {In a frequentist framework, the exact fit of a structural equation model (SEM) is typically evaluated with the chi-square test and at least one index of approximate fit. Current Bayesian SEM (BSEM) software provides one measure of overall fit: the posterior predictive p value (PPP Ï‡2 ). Because of the noted limitations of PPP Ï‡2 , common practice for evaluating Bayesian model fit instead focuses on model comparison, using information criteria or Bayes factors. Fit indices developed under maximum-likelihood estimation have not been incorporated into software for BSEM. We propose adapting 7 chi-square-based approximate fit indices for BSEM, using a Bayesian analog of the chi-square model-fit statistic. Simulation results show that the sampling distributions of the posterior means of these fit indices are similar to their frequentist counterparts across sample sizes, model types, and levels of misspecification when BSEMs are estimated with noninformative priors. The proposed fit indices therefore allow overall model-fit evaluation using familiar metrics of the original indices, with an accompanying interval to quantify their uncertainty. Illustrative examples with real data raise some important issues about the proposed fit indices' application to models specified with informative priors, when Bayesian and frequentist estimation methods might not yield similar results. (PsycINFO Database Record (c) 2020 APA, all rights reserved).},
  language   = {eng},
  number     = {1},
  journal    = {Psychological Methods},
  author     = {Garnier-Villarreal, Mauricio and Jorgensen, Terrence D.},
  month      = feb,
  year       = {2020},
  pmid       = {31180693},
  keywords   = {Humans, Bayes Theorem, Psychology, Data Interpretation, Statistical, Likelihood Functions, Research Design, Latent Class Analysis},
  pages      = {46--70},
  file       = {garnier-villarreal_jorgensen_2020_adapting_fit_indices_for_bayesian_structural_equation_modeling_-_comparison_to.pdf:/home/james/Dropbox/zotero-library/AUTH/Garnier-Villarreal_Jorgensen/garnier-villarreal_jorgensen_2020_adapting_fit_indices_for_bayesian_structural_equation_modeling_-_comparison_to.pdf:application/pdf}
}

@article{Conti2014,
  title    = {Bayesian exploratory factor analysis},
  volume   = {183},
  issn     = {0304-4076},
  doi      = {10.1016/j.jeconom.2014.06.008},
  abstract = {This paper develops and applies a Bayesian approach to Exploratory Factor Analysis that improves on ad hoc classical approaches. Our framework relies on dedicated factor models and simultaneously determines the number of factors, the allocation of each measurement to a unique factor, and the corresponding factor loadings. Classical identification criteria are applied and integrated into our Bayesian procedure to generate models that are stable and clearly interpretable. A Monte Carlo study confirms the validity of the approach. The method is used to produce interpretable low dimensional aggregates from a high dimensional set of psychological measurements.},
  number   = {1},
  journal  = {Journal of Econometrics},
  author   = {Conti, Gabriella and Fr{\"u}hwirth-Schnatter, Sylvia and Heckman, James J and Piatek, R{\'e}mi},
  year     = {2014},
  keywords = {Bayesian factor models, Exploratory factor analysis, Identifiability, Marginal data augmentation, Model expansion, Model selection},
  pages    = {31--57}
}

@article{lee_bayesian_2007,
  title   = {Bayesian methods for analyzing structural equation models with covariates, interaction, and quadratic latent variables},
  volume  = {14},
  issn    = {1070-5511},
  doi     = {10.1080/10705510701301511},
  number  = {3},
  journal = {Structural Equation Modeling: A Multidisciplinary Journal},
  author  = {Lee, Sik Yum and Song, Xin Yuan and Tang, Nian Sheng},
  month   = jul,
  year    = {2007},
  note    = {Publisher: Routledge},
  pages   = {404--434},
  file    = {lee_et_al_2007_bayesian_methods_for_analyzing_structural_equation_models_with_covariates,.pdf:/home/james/Dropbox/zotero-library/AUTH/Lee et al/lee_et_al_2007_bayesian_methods_for_analyzing_structural_equation_models_with_covariates,.pdf:application/pdf}
}

@article{lemoine_moving_2019,
  title      = {Moving beyond noninformative priors: Why and how to choose weakly informative priors in {Bayesian} analyses},
  volume     = {128},
  issn       = {1600-0706},
  shorttitle = {Moving beyond noninformative priors},
  doi        = {10.1111/oik.05985},
  abstract   = {Throughout the last two decades, Bayesian statistical methods have proliferated throughout ecology and evolution. Numerous previous references established both philosophical and computational guidelines for implementing Bayesian methods. However, protocols for incorporating prior information, the defining characteristic of Bayesian philosophy, are nearly nonexistent in the ecological literature. Here, I hope to encourage the use of weakly informative priors in ecology and evolution by providing a â€˜consumer's guideâ€™ to weakly informative priors. The first section outlines three reasons why ecologists should abandon noninformative priors: 1) common flat priors are not always noninformative, 2) noninformative priors provide the same result as simpler frequentist methods, and 3) noninformative priors suffer from the same high type I and type M error rates as frequentist methods. The second section provides a guide for implementing informative priors, wherein I detail convenient â€˜referenceâ€™ prior distributions for common statistical models (i.e. regression, ANOVA, hierarchical models). I then use simulations to visually demonstrate how informative priors influence posterior parameter estimates. With the guidelines provided here, I hope to encourage the use of weakly informative priors for Bayesian analyses in ecology. Ecologists can and should debate the appropriate form of prior information, but should consider weakly informative priors as the new â€˜defaultâ€™ prior for any Bayesian model.},
  language   = {en},
  number     = {7},
  journal    = {Oikos},
  author     = {Lemoine, Nathan P.},
  year       = {2019},
  keywords   = {Bayesian statistics, frequentist statistics, Markov chain Monte Carlo, vague priors},
  pages      = {912--928},
  file       = {lemoine_2019_moving_beyond_noninformative_priors_-_why_and_how_to_choose_weakly_informative.pdf:/home/james/Dropbox/zotero-library/AUTH/Lemoine/lemoine_2019_moving_beyond_noninformative_priors_-_why_and_how_to_choose_weakly_informative.pdf:application/pdf;Full Text PDF:/home/james/zotero-system/storage/DSJ4GWSN/Lemoine - 2019 - Moving beyond noninformative priors why and how t.pdf:application/pdf}
}

@book{Bollen1989,
  address   = {Hoboken, NJ, USA},
  title     = {Structural equations with latent variables},
  isbn      = {978-1-118-61917-9},
  publisher = {John Wiley \& Sons, Inc.},
  author    = {Bollen, Kenneth A.},
  month     = apr,
  year      = {1989},
  doi       = {10.1002/9781118619179},
  note      = {Pages: 514},
  file      = {bollen_1989_structural_equations_with_latent_variables.pdf:/home/james/Dropbox/zotero-library/AUTH/Bollen/bollen_1989_structural_equations_with_latent_variables.pdf:application/pdf}
}

@article{ogasawara_standard_2001,
  title    = {Standard errors of fit indices using residuals in structural equation modeling},
  volume   = {66},
  issn     = {1860-0980},
  doi      = {10.1007/BF02294443},
  abstract = {The asymptotic standard errors of the correlation residuals and Bentler's standardized residuals in covariance structures are derived based on the asymptotic covariance matrix of raw covariance residuals. Using these results, approximations of the asymptotic standard errors of the root mean square residuals for unstandardized or standardized residuals are derived by the delta method. Further, in mean structures, approximations of the asymptotic standard errors of residuals, standardized residuals and their summary statistics are derived in a similar manner. Simulations are carried out, which show that the asymptotic standard errors of the various types of residuals and the root mean square residuals in covariance, correlation and mean structures are close to actual ones.},
  language = {en},
  number   = {3},
  urldate  = {2022-07-06},
  journal  = {Psychometrika},
  author   = {Ogasawara, Haruhiko},
  month    = sep,
  year     = {2001},
  keywords = {asymptotic standard errors, correlation residuals, covariance structures, mean structures, RMR, standardized residuals, structural means},
  pages    = {421--436},
  file     = {ogasawara_2001_standard_errors_of_fit_indices_using_residuals_in_structural_equation_modeling.pdf:/home/james/Dropbox/zotero-library/AUTH/Ogasawara/ogasawara_2001_standard_errors_of_fit_indices_using_residuals_in_structural_equation_modeling.pdf:application/pdf;Full Text PDF:/home/james/zotero-system/storage/9CZ5X6QZ/Ogasawara - 2001 - Standard errors of fit indices using residuals in .pdf:application/pdf}
}

@article{dunson_bayesian_2000,
  title    = {Bayesian latent variable models for clustered mixed outcomes},
  volume   = {62},
  issn     = {1467-9868},
  doi      = {10.1111/1467-9868.00236},
  abstract = {A general framework is proposed for modelling clustered mixed outcomes. A mixture of generalized linear models is used to describe the joint distribution of a set of underlying variables, and an arbitrary function relates the underlying variables to be observed outcomes. The model accommodates multilevel data structures, general covariate effects and distinct link functions and error distributions for each underlying variable. Within the framework proposed, novel models are developed for clustered multiple binary, unordered categorical and joint discrete and continuous outcomes. A Markov chain Monte Carlo sampling algorithm is described for estimating the posterior distributions of the parameters and latent variables. Because of the flexibility of the modelling framework and estimation procedure, extensions to ordered categorical outcomes and more complex data structures are straightforward. The methods are illustrated by using data from a reproductive toxicity study.},
  language = {en},
  number   = {2},
  urldate  = {2022-08-20},
  journal  = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  author   = {Dunson, D. B.},
  year     = {2000},
  keywords = {Gibbs sampler, Mixture model, Multihit model, Multiple outcomes, Reproductive applications},
  pages    = {355--366},
  file     = {dunson_2000_bayesian_latent_variable_models_for_clustered_mixed_outcomes.pdf:/home/james/Dropbox/zotero-library/AUTH/Dunson/dunson_2000_bayesian_latent_variable_models_for_clustered_mixed_outcomes.pdf:application/pdf;Full Text PDF:/home/james/zotero-system/storage/ZSK6P8I5/Dunson - 2000 - Bayesian latent variable models for clustered mixe.pdf:application/pdf}
}

@article{scheines_bayesian_1999,
  title    = {Bayesian estimation and testing of structural equation models},
  volume   = {64},
  issn     = {0033-3123, 1860-0980},
  doi      = {10.1007/BF02294318},
  abstract = {The Gibbs sampler can be used to obtain samples of arbitrary size from the posterior distribution over the parameters of a structural equation model (SEM) given covariance data and a prior distribution over the parameters. Point estimates, standard deviations and interval estimates for the parameters can be computed from these samples. If the prior distribution over the parameters is uninformative, the posterior is proportional to the likelihood, and asymptotically the inferences based on the Gibbs sample are the same as those based on the maximum likelihood solution, for example, output from LISREL or EQS. In small samples, however, the likelihood surface is not Gaussian and in some cases contains local maxima. Nevertheless, the Gibbs sample comes from the correct posterior distribution over the parameters regardless of the sample size and the shape of the likelihood surface. With an informative prior distribution over the parameters, the posterior can be used to make inferences about the parameters of underidentified models, as we illustrate on a simple errors-in-variables model.},
  language = {en},
  number   = {1},
  urldate  = {2022-08-20},
  journal  = {Psychometrika},
  author   = {Scheines, Richard and Hoijtink, Herbert and Boomsma, Anne},
  month    = mar,
  year     = {1999},
  pages    = {37--52},
  file     = {Scheines et al. - 1999 - Bayesian estimation and testing of structural equa.pdf:/home/james/zotero-system/storage/6AJUND3D/Scheines et al. - 1999 - Bayesian estimation and testing of structural equa.pdf:application/pdf;Bayesian estimation and testing of structural equation models:/home/james/zotero-system/storage/P38X3THS/scheines1999.pdf.pdf:application/pdf}
}

@article{levy_bayesian_2011,
  title    = {Bayesian Data-Model Fit Assessment for Structural Equation Modeling},
  volume   = {18},
  issn     = {1070-5511},
  doi      = {10.1080/10705511.2011.607723},
  abstract = {Bayesian approaches to modeling are receiving an increasing amount of attention in the areas of model construction and estimation in factor analysis, structural equation modeling (SEM), and related latent variable models. However, model diagnostics and model criticism remain relatively understudied aspects of Bayesian SEM. This article describes and illustrates key features of Bayesian approaches to model diagnostics and assessing dataâ€“model fit of structural equation models, discussing their merits relative to traditional procedures.},
  number   = {4},
  urldate  = {2022-04-17},
  journal  = {Structural Equation Modeling: A Multidisciplinary Journal},
  author   = {Levy, Roy},
  month    = oct,
  year     = {2011},
  keywords = {structural equation modeling, Bayesian model checking, dataâ€“model fit},
  pages    = {663--685},
  file     = {levy_2011_bayesian_data-model_fit_assessment_for_structural_equation_modeling.pdf:/home/james/Dropbox/zotero-library/AUTH/Levy/levy_2011_bayesian_data-model_fit_assessment_for_structural_equation_modeling.pdf:application/pdf}
}


@article{lai_creating_2019,
  title    = {Creating Misspecified Models in Moment Structure Analysis},
  volume   = {84},
  issn     = {1860-0980},
  doi      = {10.1007/s11336-018-09655-0},
  abstract = {To understand how SEM methods perform in practice where models always have misfit, simulation studies often involve incorrect models. To create a wrong model, traditionally one specifies a perfect model first and then removes some paths. This approach becomes difficult or even impossible to implement in moment structure analysis and fails to control the amounts of misfit separately and precisely for the mean and covariance parts. Most importantly, this approach assumes a perfect model exists and wrong models can eventually be made perfect, whereas in practice models are all implausible if taken literally and at best provide approximations of the real world. To improve the traditional approach, we propose a more realistic and flexible way to create model misfit for multiple group moment structure analysis. Given (a) the model \$\${\textbackslash}varvec\{\{\{{\textbackslash}upmu \}\}\} ({\textbackslash}cdot ) \$\$ and \$\${\textbackslash}varvec\{\{{\textbackslash}Sigma \}\} ({\textbackslash}cdot ) \$\$, (b) population model parameters \$\${\textbackslash}varvec\{\{\{{\textbackslash}uptheta \}\}\} \_0\$\$, and (c) \$\$F\_1\$\$ and \$\$F\_2\$\$ specified by the researcher, our method creates \$\${\textbackslash}varvec\{\{\{{\textbackslash}upmu \}\}\} {\textasciicircum}*\$\$ and \$\${\textbackslash}varvec\{\{{\textbackslash}Sigma \}\} {\textasciicircum}*\$\$ to simultaneously satisfy (a) \$\${\textbackslash}varvec\{\{\{{\textbackslash}uptheta \}\}\} \_0 = {\textbackslash}arg {\textbackslash}min F[{\textbackslash}varvec\{\{\{{\textbackslash}upmu \}\}\} {\textasciicircum}*, {\textbackslash}varvec\{\{{\textbackslash}Sigma \}\} {\textasciicircum}*; {\textbackslash}varvec\{\{\{{\textbackslash}upmu \}\}\} ({\textbackslash}cdot ), {\textbackslash}varvec\{\{{\textbackslash}Sigma \}\} ({\textbackslash}cdot )]\$\$, (b) the mean structureâ€™s misfit equals \$\$F\_1\$\$, and (c) the covariance structureâ€™s misfit equals \$\$F\_2\$\$.},
  language = {en},
  number   = {3},
  urldate  = {2022-04-18},
  journal  = {Psychometrika},
  author   = {Lai, Keke},
  month    = sep,
  year     = {2019},
  keywords = {model misspecification, moment structure analysis, Monte Carlo experiments, multiple group analysis},
  pages    = {781--801},
  file     = {lai_2019_creating_misspecified_models_in_moment_structure_analysis.pdf:/home/james/Dropbox/zotero-library/AUTH/Lai/lai_2019_creating_misspecified_models_in_moment_structure_analysis.pdf:application/pdf;Full Text PDF:/home/james/zotero-system/storage/24W7Z5IF/Lai - 2019 - Creating Misspecified Models in Moment Structure A.pdf:application/pdf}
}

@article{savalei_relationship_2012,
  title    = {The Relationship Between Root Mean Square Error of Approximation and Model Misspecification in Confirmatory Factor Analysis Models},
  volume   = {72},
  issn     = {0013-1644},
  doi      = {10.1177/0013164412452564},
  abstract = {The fit index root mean square error of approximation (RMSEA) is extremely popular in structural equation modeling. However, its behavior under different scenarios remains poorly understood. The present study generates continuous curves where possible to capture the full relationship between RMSEA and various â€œincidental parameters,â€ such as factor loadings and model size, for different types of misspecification. Population RMSEA is studied, removing the influence of sampling fluctuations and making the findings directly applicable to tests of close fit and not-close fit, which require the specification of a population cutoff value. Confirmatory factor analysis models are studied. The results introduce many new findings, including that RMSEA is often insensitive to multiple omitted cross-loadings and to clusters of correlated residuals, that it sometimes behaves counterintuitively as a function of model size, and that it is insensitive to the underlying number of latent factors when a model with one factor is fit.},
  language = {en},
  number   = {6},
  urldate  = {2022-08-25},
  journal  = {Educational and Psychological Measurement},
  author   = {Savalei, Victoria},
  month    = dec,
  year     = {2012},
  keywords = {fit indices, structural equation modeling (SEM), root mean square error of approximation (RMSEA)},
  pages    = {910--932},
  file     = {savalei_2012_the_relationship_between_root_mean_square_error_of_approximation_and_model.pdf:/home/james/Dropbox/zotero-library/AUTH/Savalei/savalei_2012_the_relationship_between_root_mean_square_error_of_approximation_and_model.pdf:application/pdf}
}

@article{chen_empirical_2008,
  title    = {An Empirical Evaluation of the Use of Fixed Cutoff Points in {RMSEA} Test Statistic in Structural Equation Models},
  volume   = {36},
  issn     = {0049-1241},
  doi      = {10.1177/0049124108314720},
  abstract = {This article is an empirical evaluation of the choice of fixed cutoff points in assessing the root mean square error of approximation (RMSEA) test statistic as a measure of goodness-of-fit in Structural Equation Models. Using simulation data, the authors first examine whether there is any empirical evidence for the use of a universal cutoff, and then compare the practice of using the point estimate of the RMSEA alone versus that of using it jointly with its related confidence interval. The results of the study demonstrate that there is little empirical support for the use of .05 or any other value as universal cutoff values to determine adequate model fit, regardless of whether the point estimate is used alone or jointly with the confidence interval. The authors' analyses suggest that to achieve a certain level of power or Type I error rate, the choice of cutoff values depends on model specifications, degrees of freedom, and sample size.},
  language = {en},
  number   = {4},
  urldate  = {2022-10-19},
  journal  = {Sociological Methods \& Research},
  author   = {Chen, Feinian and Curran, Patrick J. and Bollen, Kenneth A. and Kirby, James and Paxton, Pamela},
  month    = may,
  year     = {2008},
  pages    = {462--494},
  file     = {chen_et_al_2008_an_empirical_evaluation_of_the_use_of_fixed_cutoff_points_in_rmsea_test.pdf:/home/james/Dropbox/zotero-library/AUTH/Chen et al/chen_et_al_2008_an_empirical_evaluation_of_the_use_of_fixed_cutoff_points_in_rmsea_test.pdf:application/pdf;Full Text:/home/james/zotero-system/storage/AXLXQPM2/Chen et al. - 2008 - An Empirical Evaluation of the Use of Fixed Cutoff.pdf:application/pdf}
}

@article{Gelman2008,
  title    = {A weakly informative default prior distribution for logistic and other regression models},
  volume   = {2},
  issn     = {1932-6157},
  doi      = {10.1214/08-AOAS191},
  number   = {4},
  journal  = {The Annals of Applied Statistics},
  author   = {Gelman, Andrew and Jakulin, Aleks and Pittau, Maria Grazia and Su, Yu-Sung},
  month    = dec,
  year     = {2008},
  keywords = {logistic regression, Bayesian inference, hierarchical model, linear regression, multilevel model, generalized linear model, least squares, noninformative prior distribution, weakly informative prior distribution},
  pages    = {1360--1383},
  file     = {gelman_et_al_2008_a_weakly_informative_default_prior_distribution_for_logistic_and_other.pdf:/home/james/Dropbox/zotero-library/AUTH/Gelman et al/gelman_et_al_2008_a_weakly_informative_default_prior_distribution_for_logistic_and_other.pdf:application/pdf}
}

@article{Park2008,
  title    = {The {Bayesian} lasso},
  volume   = {103},
  issn     = {0162-1459},
  doi      = {10.1198/016214508000000337},
  abstract = {The Lasso estimate for linear regression parameters can be interpreted as a Bayesian posterior mode estimate when the regression parameters have independent Laplace (i.e., double-exponential) priors. Gibbs sampling from this posterior is possible using an expanded hierarchy with conjugate normal priors for the regression parameters and independent exponential priors on their variances. A connection with the inverse-Gaussian distribution provides tractable full conditional distributions. The Bayesian Lasso provides interval estimates (Bayesian credible intervals) that can guide variable selection. Moreover, the structure of the hierarchical model provides both Bayesian and likelihood methods for selecting the Lasso parameter. Slight modifications lead to Bayesian versions of other Lasso-related estimation methods, including bridge regression and a robust variant.},
  number   = {482},
  journal  = {Journal of the American Statistical Association},
  author   = {Park, Trevor and Casella, George},
  month    = jun,
  year     = {2008},
  keywords = {Linear regression, Empirical Bayes, Gibbs sampler, Hierarchical model, Inverse Gaussian, Penalized regression, Scale mixture of normals},
  pages    = {681--686},
  file     = {park_casella_2008_the_bayesian_lasso.pdf:/home/james/Dropbox/zotero-library/AUTH/Park_Casella/park_casella_2008_the_bayesian_lasso.pdf:application/pdf}
}

@inproceedings{Carvalho2009,
  title     = {Handling sparsity via the horseshoe},
  url       = {http://proceedings.mlr.press/v5/carvalho09a.html},
  abstract  = {This paper presents a general, fully Bayesian framework for sparse supervised-learning problems based on the horseshoe prior. The horseshoe prior is a member of the family of multivariate scale mixtures of normals, and is therefore closely related to widely used approaches for sparse Bayesian learning, including , among others, Laplacian priors (e.g. the LASSO) and Student-t priors (e.g. the relevance vector machine). The advantages of the horseshoe are its robustness at handling unknown sparsity and large outlying signals. These properties are justified theoretically via a representation theorem and accompanied by comprehensive empirical experiments that compare its performance to benchmark alternatives.},
  booktitle = {Proceedings of the twelth international conference on artificial intelligence and statistics},
  publisher = {PMLR},
  author    = {Carvalho, Carlos M and Polson, Nicholas G and Scott, James G},
  month     = apr,
  year      = {2009},
  note      = {ISSN: 1938-7228},
  pages     = {73--80}
}

@article{piironen_sparsity_2017,
  title    = {Sparsity information and regularization in the horseshoe and other shrinkage priors},
  volume   = {11},
  issn     = {1935-7524, 1935-7524},
  doi      = {10.1214/17-EJS1337SI},
  abstract = {The horseshoe prior has proven to be a noteworthy alternative for sparse Bayesian estimation, but has previously suffered from two problems. First, there has been no systematic way of specifying a prior for the global shrinkage hyperparameter based on the prior information about the degree of sparsity in the parameter vector. Second, the horseshoe prior has the undesired property that there is no possibility of specifying separately information about sparsity and the amount of regularization for the largest coefficients, which can be problematic with weakly identified parameters, such as the logistic regression coefficients in the case of data separation. This paper proposes solutions to both of these problems. We introduce a concept of effective number of nonzero parameters, show an intuitive way of formulating the prior for the global hyperparameter based on the sparsity assumptions, and argue that the previous default choices are dubious based on their tendency to favor solutions with more unshrunk parameters than we typically expect a priori. Moreover, we introduce a generalization to the horseshoe prior, called the regularized horseshoe, that allows us to specify a minimum level of regularization to the largest values. We show that the new prior can be considered as the continuous counterpart of the spike-and-slab prior with a finite slab width, whereas the original horseshoe resembles the spike-and-slab with an infinitely wide slab. Numerical experiments on synthetic and real world data illustrate the benefit of both of these theoretical advances.},
  number   = {2},
  urldate  = {2022-10-21},
  journal  = {Electronic Journal of Statistics},
  author   = {Piironen, Juho and Vehtari, Aki},
  month    = jan,
  year     = {2017},
  keywords = {62F15, Bayesian inference, horseshoe prior, shrinkage priors, Sparse estimation},
  pages    = {5018--5051},
  file     = {piironen_vehtari_2017_sparsity_information_and_regularization_in_the_horseshoe_and_other_shrinkage.pdf:/home/james/Dropbox/zotero-library/AUTH/Piironen_Vehtari/piironen_vehtari_2017_sparsity_information_and_regularization_in_the_horseshoe_and_other_shrinkage.pdf:application/pdf;Full Text PDF:/home/james/zotero-system/storage/VYLGPJMT/Piironen and Vehtari - 2017 - Sparsity information and regularization in the hor.pdf:application/pdf}
}

@article{maccallum_representing_1991,
  title      = {Representing sources of error in the common-factor model: {Implications} for theory and practice},
  volume     = {109},
  issn       = {1939-1455},
  shorttitle = {Representing sources of error in the common-factor model},
  doi        = {10.1037/0033-2909.109.3.502},
  abstract   = {In the traditional presentation of the common-factor model, measured variables are represented as exact linear combinations of common and unique factors. From the perspective that no mathematical model will fit real-world phenomena perfectly, it is suggested that this representation is problematic. It is not consistent with the phenomena it is intended to model, and it does not provide an adequate basis for understanding some issues inherent in factor analysis. An alternative representation of the model that incorporates a "lack-of-fit" term into the initial equation for the measured variables is proposed. Subsequent derivation of the covariance form of the model in the population and the sample yields a framework that allows for differentiation of various sources of error that arise in applications of the model. These developments provide a basis for study of some important issues such as model definition, parameter estimation, and sample size. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal    = {Psychological Bulletin},
  author     = {MacCallum, Robert C. and Tucker, Ledyard R.},
  year       = {1991},
  keywords   = {Common Factors, Error of Measurement, Factor Analysis, Mathematical Modeling},
  pages      = {502--511},
  file       = {maccallum_tucker_1991_representing_sources_of_error_in_the_common-factor_model_-_implications_for.pdf:/home/james/Dropbox/zotero-library/AUTH/MacCallum_Tucker/maccallum_tucker_1991_representing_sources_of_error_in_the_common-factor_model_-_implications_for.pdf:application/pdf}
}

@incollection{Palomo2007,
  title     = {Bayesian structural equation modeling},
  isbn      = {978-0-08-047126-6},
  booktitle = {Handbook of latent variable and related models},
  publisher = {Elsevier/North-Holland},
  author    = {Palomo, Jesus and Dunson, David B and Bollen, Ken},
  editor    = {Lee, Sik-Yum},
  year      = {2007},
  note      = {Section: 8},
  pages     = {163--188}
}

@article{Vehtari2017,
  title    = {Practical {Bayesian} model evaluation using leave-one-out cross-validation and {WAIC}},
  volume   = {27},
  issn     = {1573-1375},
  doi      = {10.1007/s11222-016-9696-4},
  number   = {5},
  journal  = {Statistics and Computing},
  author   = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year     = {2017},
  pages    = {1413--1432},
  file     = {vehtari_et_al_2017_practical_bayesian_model_evaluation_using_leave-one-out_cross-validation_and.pdf:/home/james/Dropbox/zotero-library/AUTH/Vehtari et al/vehtari_et_al_2017_practical_bayesian_model_evaluation_using_leave-one-out_cross-validation_and.pdf:application/pdf;vehtari_et_al_2017_practical_bayesian_model_evaluation_using_leave-one-out_cross-validation_and.pdf:/home/james/Dropbox/zotero-library/AUTH/Vehtari et al/vehtari_et_al_2017_practical_bayesian_model_evaluation_using_leave-one-out_cross-validation_and.pdf:application/pdf}
}

@article{burkner_ordinal_2019,
  title      = {Ordinal Regression Models in Psychology: A Tutorial},
  volume     = {2},
  issn       = {2515-2459},
  shorttitle = {Ordinal {Regression} {Models} in {Psychology}},
  doi        = {10.1177/2515245918823199},
  abstract   = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  language   = {en},
  number     = {1},
  urldate    = {2022-11-11},
  journal    = {Advances in Methods and Practices in Psychological Science},
  author     = {BÃ¼rkner, Paul-Christian and Vuorre, Matti},
  month      = mar,
  year       = {2019},
  note       = {Publisher: SAGE Publications Inc},
  pages      = {77--101},
  file       = {burkner_vuorre_2019_ordinal_regression_models_in_psychology_-_a_tutorial.pdf:/home/james/Dropbox/zotero-library/AUTH/BÃ¼rkner_Vuorre/burkner_vuorre_2019_ordinal_regression_models_in_psychology_-_a_tutorial.pdf:application/pdf;SAGE PDF Full Text:/home/james/zotero-system/storage/QTKWCZM2/BÃ¼rkner and Vuorre - 2019 - Ordinal Regression Models in Psychology A Tutoria.pdf:application/pdf}
}

@article{asparouhov_advances_2021,
  title    = {Advances in {Bayesian} Model Fit Evaluation for Structural Equation Models},
  volume   = {28},
  issn     = {1070-5511, 1532-8007},
  doi      = {10.1080/10705511.2020.1764360},
  abstract = {In this article, we discuss the Posterior Predictive P-value (PPP) method in the presence of missing data, the Bayesian adaptation of the approximate fit indices RMSEA, CFI and TLI, as well as the Bayesian adaptation of the Wald test for nested models. Simulation studies are presented. We also illustrate how these new methods can be used to build BSEM models.},
  language = {en},
  number   = {1},
  urldate  = {2022-04-17},
  journal  = {Structural Equation Modeling: A Multidisciplinary Journal},
  author   = {Asparouhov, Tihomir and MuthÃ©n, Bengt},
  month    = jan,
  year     = {2021},
  pages    = {1--14},
  file     = {Asparouhov and MuthÃ©n - 2021 - Advances in Bayesian Model Fit Evaluation for Stru.pdf:/home/james/zotero-system/storage/B93UWMWH/Asparouhov and MuthÃ©n - 2021 - Advances in Bayesian Model Fit Evaluation for Stru.pdf:application/pdf;Advances in Bayesian Model Fit Evaluation for Structural Equation Models:/home/james/zotero-system/storage/9Q954XT8/10.1080@10705511.2020.1764360.pdf.pdf:application/pdf}
}

@article{McNeish2016b,
  title    = {On using {Bayesian} methods to address small sample problems},
  volume   = {23},
  issn     = {15328007},
  doi      = {10.1080/10705511.2016.1186549},
  abstract = {ISSN: 1070-5511 (Print) 1532-8007 (Online) Journal homepage: http://www.tandfonline.com/loi/hsem20 As Bayesian methods continue to grow in accessibility and popularity, more empirical studies are turning to Bayesian methods to model small sample data. Bayesian methods do not rely on asympotics, a property that can be a hindrance when employing frequentist methods in small sample contexts. Although Bayesian methods are better equipped to model data with small sample sizes, estimates are highly sensitive to the specification of the prior distribution. If this aspect is not heeded, Bayesian estimates can actually be worse than frequentist methods, especially if frequentist small sample corrections are utilized. We show with illustrative simula-tions and applied examples that relying on software defaults or diffuse priors with small samples can yield more biased estimates than frequentist methods. We discuss conditions that need to be met if researchers want to responsibly harness the advantages that Bayesian methods offer for small sample problems as well as leading small sample frequentist methods. In the last decade or so, Bayesian methods have become vastly more popular in nearly all scientific fields (van de Schoot, 2016). In fact, based on a comprehensive review of Bayesian studies over the last 15 years, van de Schoot (2016) noted that the number of empirical papers in psy-chology using Bayesian methods increased nearly fivefold between 2010 and 2015. This rapid increase is partially attributable to the decrease in the cost of computational resources needed to estimate the increasingly complex mod-els applied researchers are fitting to their data as well as increased accessibility to Bayesian software (Dunson, 2001), Mplus in particular, whose Bayesian module was available beginning in Version 6, which, not coincidently, was introduced in 2010. In addition to greater ease of implementation, several recent methodological papers and Monte Carlo simulation studies have noted the potential advantages of Bayesian methods over frequentist maximum likelihood (ML) meth-ods with small samples (e.. As research-ers are certainly aware, sample sizes in a vast array of behavioral science fields are frequently quite small. For instance, two meta-analyses by Roberts and colleagues found that about 33\% of growth models investigating personality traits over time had fewer than 100 people, a review by Russell (2002) found that about 40\% of explora-tory factor analysis studies in psychology had samples less than 100, 18\% of structural equation modeling (SEM) applications in psychology had samples less than 100 in a review by MacCallum and Austin (2000), 50\% of meta-analyses in education had fewer than 40 studies (Ahn, Ames, \& Myers, 2012), and the average number of clusters in registered primary care randomized trials was 29 (Eldridge, Ashby, Feder, Rudnicka, \& Ukoumunne, 2004). The issue of small sample size is highly relevant and the promise of Bayesian methods to handle these},
  number   = {5},
  journal  = {Structural Equation Modeling},
  author   = {McNeish, Daniel},
  year     = {2016},
  file     = {mcneish_2016_on_using_bayesian_methods_to_address_small_sample_problems.pdf:/home/james/Dropbox/zotero-library/AUTH/McNeish/mcneish_2016_on_using_bayesian_methods_to_address_small_sample_problems.pdf:application/pdf}
}

@article{smid_dangers_2020,
  title    = {Dangers of the defaults: {A} tutorial on the impact of default priors when using {Bayesian} {SEM} with small samples},
  volume   = {11},
  issn     = {16641078},
  doi      = {10.3389/fpsyg.2020.611963},
  abstract = {When Bayesian estimation is used to analyze Structural Equation Models (SEMs), prior distributions need to be specified for all parameters in the model. Many popular software programs offer default prior distributions, which is helpful for novel users and makes Bayesian SEM accessible for a broad audience. However, when the sample size is small, those prior distributions are not always suitable and can lead to untrustworthy results. In this tutorial, we provide a non-technical discussion of the risks associated with the use of default priors in small sample contexts. We discuss how default priors can unintentionally behave as highly informative priors when samples are small. Also, we demonstrate an online educational Shiny app, in which users can explore the impact of varying prior distributions and sample sizes on model results. We discuss how the Shiny app can be used in teaching; provide a reading list with literature on how to specify suitable prior distributions; and discuss guidelines on how to recognize (mis)behaving priors. It is our hope that this tutorial helps to spread awareness of the importance of specifying suitable priors when Bayesian SEM is used with small samples.},
  journal  = {Frontiers in Psychology},
  author   = {Smid, Sanne C. and Winter, Sonja D.},
  month    = dec,
  year     = {2020},
  keywords = {Bayesian SEM, default priors, informative priors, Shiny app, small sample size},
  pages    = {611963},
  file     = {smid_winter_2020_dangers_of_the_defaults_-_a_tutorial_on_the_impact_of_default_priors_when_using.pdf:/home/james/Dropbox/zotero-library/AUTH/Smid_Winter/smid_winter_2020_dangers_of_the_defaults_-_a_tutorial_on_the_impact_of_default_priors_when_using.pdf:application/pdf;smid_winter_2020_dangers_of_the_defaults_-_a_tutorial_on_the_impact_of_default_priors_when_using.pdf:/home/james/Dropbox/zotero-library/AUTH/Smid_Winter/smid_winter_2020_dangers_of_the_defaults_-_a_tutorial_on_the_impact_of_default_priors_when_using2.pdf:application/pdf}
}


@article{browne_alternative_1992,
  title    = {Alternative Ways of Assessing Model Fit},
  volume   = {21},
  issn     = {0049-1241},
  doi      = {10.1177/0049124192021002005},
  abstract = {This article is concerned with measures of fit of a model. Two types of error involved in fitting a model are considered. The first is error of approximation which involves the fit of the model, with optimally chosen but unknown parameter values, to the population covariance matrix. The second is overall error which involves the fit of the model, with parameter values estimated from the sample, to the population covariance matrix. Measures of the two types of error are proposed and point and interval estimates of the measures are suggested. These measures take the number of parameters in the model into account in order to avoid penalizing parsimonious models. Practical difficulties associated with the usual tests of exact fit or a model are discussed and a test of â€œclose fitâ€ of a model is suggested.},
  language = {en},
  number   = {2},
  journal  = {Sociological Methods \& Research},
  author   = {Browne, Michael W. and Cudeck, Robert},
  month    = nov,
  year     = {1992},
  pages    = {230--258}
}


@article{bentler_comparative_1990,
  title    = {Comparative fit indexes in structural models},
  volume   = {107},
  issn     = {1939-1455},
  doi      = {10.1037/0033-2909.107.2.238},
  abstract = {Normed and nonnormed fit indexes are frequently used as adjuncts to chi-square statistics for evaluating the fit of a structural model. A drawback of existing indexes is that they estimate no known population parameters. A new coefficient is proposed to summarize the relative reduction in the noncentrality parameters of 2 nested models. Two estimators of the coefficient yield new normed (CFIN) and nonnormed (FIN) fit indexes. CFIN avoids the underestimation of fit often noted in small samples for P. M. Bentler and D. G. Bonett's (see record 1981-06898-001) normed fit index (NFIN). FIN is a linear function of Bentler and Bonett's nonnormed fit index (NNFIN) that avoids the extreme underestimation and overestimation often found in NNFIN. Asymptotically, CFIN, FIN, NFIN, and a new index developed by K. A. Bollen (1989) are equivalent measures of comparative fit, whereas NNFIN measures relative fit by comparing noncentrality per degree of freedom. All of the indexes are generalized to permit use of Wald and Lagrange multiplier statistics. An example illustrates the behavior of these indexes under conditions of correct specification and misspecification. The new fit indexes perform very well at all sample sizes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  journal  = {Psychological Bulletin},
  author   = {Bentler, P. M.},
  year     = {1990},
  keywords = {Goodness of Fit, Methodology, Models, Population (Statistics), Statistical Estimation, Statistical Norms},
  pages    = {238--246},
  file     = {bentler_1990_comparative_fit_indexes_in_structural_models.pdf:/home/james/Dropbox/zotero-library/AUTH/Bentler/bentler_1990_comparative_fit_indexes_in_structural_models.pdf:application/pdf}
}


@article{uanhoro_modeling_nodate,
  title    = {Modeling misspecification as a parameter in {Bayesian} structural equation},
  abstract = {Accounting for model misspecification in Bayesian structural equation models is an active area of research. We present a uniquely Bayesian approach to misspecification that models the degree of misspecification as a parameter â€“ a parameter akin to the correlation root mean squared residual. The misspecification parameter can be interpreted on its own terms as a measure of absolute model fit, and allows for comparing different models fit to the same data. By estimating the degree of misspecification simultaneously with structural parameters, the uncertainty about structural parameters reflect the degree of model misspecification. This results in a model that produces more reliable inference than extant Bayesian SEMs. Additionally, the approach estimates the residual covariance matrix which can be the basis for diagnosing misspecifications and updating a hypothesized model. These features are confirmed using simulation studies. Demonstrations with a variety of real world examples show additional properties of the approach.},
  language = {en},
  journal  = {Educational and Psychological Measurement},
  year     = {under review},
  author   = {Uanhoro, James Ohisei},
  file     = {Uanhoro - Modeling misspecification as a parameter in Bayesi.pdf:/home/james/zotero-system/storage/3569E3Q5/Uanhoro - Modeling misspecification as a parameter in Bayesi.pdf:application/pdf}
}

@manual{LAWBL,
  title  = {{LAWBL}: Latent (Variable) Analysis with {Bayesian} Learning},
  author = {Jinsong Chen},
  year   = {2022},
  note   = {R package version 1.5.0},
  url    = {https://CRAN.R-project.org/package=LAWBL}
}

@article{VanErp2018,
  title    = {Prior sensitivity analysis in default {Bayesian} structural equation modeling},
  volume   = {23},
  issn     = {1082989X},
  doi      = {10.1037/met0000162},
  abstract = {Bayesian structural equation modeling (BSEM) has recently gained popularity because it enables researchers to fit complex models and solve some of the issues often encountered in classical maximum likelihood estimation, such as nonconvergence and inadmissible solutions. An important component of any Bayesian analysis is the prior distribution of the unknown model parameters. Often, researchers rely on default priors, which are constructed in an automatic fashion without requiring substantive prior information. However, the prior can have a serious influence on the estimation of the model parameters, which affects the mean squared error, bias, coverage rates, and quantiles of the estimates. In this article, we investigate the performance of three different default priors: noninformative improper priors, vague proper priors, and empirical Bayes priors-with the latter being novel in the BSEM literature. Based on a simulation study, we find that these three default BSEM methods may perform very differently, especially with small samples. A careful prior sensitivity analysis is therefore needed when performing a default BSEM analysis. For this purpose, we provide a practical step-by-step guide for practitioners to conducting a prior sensitivity analysis in default BSEM. Our recommendations are illustrated using a well-known case study from the structural equation modeling literature, and all code for conducting the prior sensitivity analysis is available in the online supplemental materials.},
  number   = {2},
  journal  = {Psychological Methods},
  author   = {van Erp, Sara and Mulder, Joris and Oberski, Daniel L.},
  year     = {2018}
}

@article{Gelman1996,
  title    = {Posterior predictive assessment of model fitness via realized discrepancies},
  volume   = {6},
  issn     = {10170405, 19968507},
  url      = {http://www.jstor.org/stable/24306036},
  abstract = {This paper considers Bayesian counterparts of the classical tests for goodness of fit and their use in judging the fit of a single Bayesian model to the observed data. We focus on posterior predictive assessment, in a framework that also includes conditioning on auxiliary statistics. The Bayesian formulation facilitates the construction and calculation of a meaningful reference distribution not only for any (classical) statistic, but also for any parameter-dependent "statistic" or discrepancy. The latter allows us to propose the realized discrepancy assessment of model fitness, which directly measures the true discrepancy between data and the posited model, for any aspect of the model which we want to explore. The computation required for the realized discrepancy assessment is a straightforward byproduct of the posterior simulation used for the original Bayesian analysis. We illustrate with three applied examples. The first example, which serves mainly to motivate the work, illustrates the difficulty of classical tests in assessing the fitness of a Poisson model to a positron emission tomography image that is constrained to be nonnegative. The second and third examples illustrate the details of the posterior predictive approach in two problems: estimation in a model with inequality constraints on the parameters, and estimation in a mixture model. In all three examples, standard test statistics (either a \&\#x3c7;2 or a likelihood ratio) are not pivotal: the difficulty is not just how to compute the reference distribution for the test, but that in the classical framework no such distribution exists, independent of the unknown model parameters.},
  number   = {4},
  journal  = {Statistica Sinica},
  author   = {Gelman, Andrew and Meng, Xiao-Li and Stern, Hal},
  year     = {1996},
  pages    = {733--760},
  file     = {gelman_et_al_1996_posterior_predictive_assessment_of_model_fitness_via_realized_discrepancies.pdf:/home/james/Dropbox/zotero-library/AUTH/Gelman et al/gelman_et_al_1996_posterior_predictive_assessment_of_model_fitness_via_realized_discrepancies.pdf:application/pdf}
}

@article{Meng1994,
  title    = {Posterior predictive p-Values},
  volume   = {22},
  issn     = {0090-5364},
  doi      = {10.1214/aos/1176325622},
  abstract = {Extending work of Rubin, this paper explores a Bayesian counterpartthe classical p-value, namely, a tail-area probability of a "test" under a null hypothesis. The Bayesian formulation, usingpredictiveof the data, allows a "test statistic" to depend on bothand unknown (nuisance) parameters and thus permits a directof the discrepancy between sample and population quantities.tail-area probability for a "test statistic" is then found underjoint posterior distribution of replicate data and the (nuisance), both conditional on the null hypothesis. This posteriorp-value can also be viewed as the posterior mean of ap-value, averaging over the posterior distribution of (nuisance)under the null hypothesis, and thus it provides one generalfor dealing with nuisance parameters. Two classical examples,the Behrens-Fisher problem, are used to illustrate thepredictive p-value and some of its interesting properties,also reveal a new (Bayesian) interpretation for some classical-values. An application to multiple-imputation inference is also. A frequency evaluation shows that, in general, if theis defined by new (nuisance) parameters and new data,the Type I frequentist error of an a-level posterior predictiveis often close to but less than a and will never exceed 2a.},
  number   = {3},
  journal  = {The Annals of Statistics},
  author   = {Meng, Xiao-Li},
  month    = sep,
  year     = {1994},
  keywords = {Type I error, multiple imputation, p-value, Bayesian p-value, Behrens-Fisher problem, discrepancy, nuisance parameter, pivot, significance level, tail-area probability, test variable},
  pages    = {1142--1160},
  file     = {meng_1994_posterior_predictive_span_class=nocasep-span-values.pdf:/home/james/Dropbox/zotero-library/AUTH/Meng/meng_1994_posterior_predictive_span_class=nocasep-span-values.pdf:application/pdf}
}

@article{hoijtink_testing_2018,
  title    = {Testing small variance priors using prior-posterior predictive p values},
  volume   = {23},
  issn     = {1939-1463},
  doi      = {10.1037/met0000131},
  abstract = {MuthÃ©n and Asparouhov (2012) propose to evaluate model fit in structural equation models based on approximate (using small variance priors) instead of exact equality of (combinations of) parameters to zero. This is an important development that adequately addresses Cohenâ€™s (1994) The Earth is Round (p {\textless} .05), which stresses that point null-hypotheses are so precise that small and irrelevant differences from the null-hypothesis may lead to their rejection. It is tempting to evaluate small variance priors using readily available approaches like the posterior predictive p value and the DIC. However, as will be shown, both are not suited for the evaluation of models based on small variance priors. In this article, a well behaving alternative, the prior-posterior predictive p value, will be introduced. It will be shown that it is consistent, the distributions under the null and alternative hypotheses will be elaborated, and it will be applied to testing whether the difference between 2 means and the size of a correlation are relevantly different from zero. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  journal  = {Psychological Methods},
  author   = {Hoijtink, Herbert and van de Schoot, Rens},
  year     = {2018},
  note     = {Place: US
              Publisher: American Psychological Association},
  keywords = {Null Hypothesis Testing, Predictability (Measurement), Structural Equation Modeling},
  pages    = {561--569},
  file     = {hoijtink_van_de_schoot_2018_testing_small_variance_priors_using_prior-posterior_predictive_p_values.pdf:/home/james/Dropbox/zotero-library/AUTH/Hoijtink_van de Schoot/hoijtink_van_de_schoot_2018_testing_small_variance_priors_using_prior-posterior_predictive_p_values.pdf:application/pdf}
}

@Book{ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {https://ggplot2.tidyverse.org},
}

@Manual{kable_ex,
  title = {kableExtra: Construct Complex Table with 'kable' and Pipe Syntax},
  author = {Hao Zhu},
  year = {2021},
  note = {R package version 1.3.4},
  url = {https://CRAN.R-project.org/package=kableExtra},
}

@Misc{posterior,
  title = {posterior: Tools for Working with Posterior Distributions},
  author = {Paul-Christian BÃ¼rkner and Jonah Gabry and Matthew Kay and Aki Vehtari},
  year = {2023},
  note = {R package version 1.4.0},
  url = {https://mc-stan.org/posterior/},
}

@Article{rcpp,
  title = {{Rcpp}: Seamless {R} and {C++} Integration},
  author = {Dirk Eddelbuettel and Romain Fran\c{c}ois},
  journal = {Journal of Statistical Software},
  year = {2011},
  volume = {40},
  number = {8},
  pages = {1--18},
  doi = {10.18637/jss.v040.i08},
}

@Manual{cite_r,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2022},
  url = {https://www.R-project.org/},
}
@Manual{R-minorbsem,
  title = {minorbsem: Fit Bayesian structural equation models under the assumption
that minor factors exist},
  author = {James Uanhoro},
  year = {2023},
  note = {R package version 0.0.1},
}
